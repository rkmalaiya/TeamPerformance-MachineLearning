<!--
RSS generated by JIRA (6.1.5#6160-sha1:a61a0fc278117a0da0ec9b89167b8f29b6afdab2) at Mon Feb 03 15:46:03 UTC 2014

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/sr/jira.issueviews:searchrequest-xml/temp/SearchRequest.xml?jqlQuery=project+%3D+HADOOP&tempMax=100&field=key&field=summary
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&amp;jqlQuery=project+%3D+HADOOP</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="100" total="8400"/>
                <build-info>
            <version>6.1.5</version>
            <build-number>6160</build-number>
            <build-date>03-12-2013</build-date>
        </build-info>
<item>
            <title>[HADOOP-10322] Add ability to read principal names from a keytab</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10322</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;It will be useful to have an ability to enumerate the principals stored in a keytab.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692627">HADOOP-10322</key>
            <summary>Add ability to read principal names from a keytab</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="benoyantony">Benoy Antony</assignee>
                                    <reporter username="benoyantony">Benoy Antony</reporter>
                        <labels>
                    </labels>
                <created>Sat, 1 Feb 2014 00:30:11 +0000</created>
                <updated>Sat, 1 Feb 2014 07:20:04 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13888370" author="hadoopqa" created="Sat, 1 Feb 2014 01:02:00 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626433/HADOOP-10322.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626433/HADOOP-10322.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-auth.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3515//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3515//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3515//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3515//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888469" author="hadoopqa" created="Sat, 1 Feb 2014 06:21:30 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626455/HADOOP-10322.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626455/HADOOP-10322.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-auth.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3517//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3517//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3517//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3517//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888472" author="benoyantony" created="Sat, 1 Feb 2014 06:30:30 +0000"  >&lt;p&gt;Attaching a new patch. The patch has utility methods to&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;read keytab file and return the list of principals&lt;/li&gt;
	&lt;li&gt;return a list of principals whole first part matches a given string (eg. HTTP)&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13888477" author="hadoopqa" created="Sat, 1 Feb 2014 06:50:26 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626458/HADOOP-10322.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626458/HADOOP-10322.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-auth.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3518//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3518//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3518//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3518//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888479" author="hadoopqa" created="Sat, 1 Feb 2014 07:12:39 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626462/HADOOP-10322.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626462/HADOOP-10322.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-auth.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3519//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3519//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3519//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3519//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888481" author="hadoopqa" created="Sat, 1 Feb 2014 07:20:04 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626462/HADOOP-10322.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626462/HADOOP-10322.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-auth.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3520//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3520//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3520//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3520//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12682724">HADOOP-10158</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626462" name="HADOOP-10322.patch" size="8150" author="benoyantony" created="Sat, 1 Feb 2014 06:52:23 +0000"/>
                            <attachment id="12626461" name="HADOOP-10322.patch" size="8147" author="benoyantony" created="Sat, 1 Feb 2014 06:49:55 +0000"/>
                            <attachment id="12626458" name="HADOOP-10322.patch" size="8269" author="benoyantony" created="Sat, 1 Feb 2014 06:30:30 +0000"/>
                            <attachment id="12626455" name="HADOOP-10322.patch" size="5802" author="benoyantony" created="Sat, 1 Feb 2014 05:59:29 +0000"/>
                            <attachment id="12626433" name="HADOOP-10322.patch" size="5726" author="benoyantony" created="Sat, 1 Feb 2014 00:32:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 1 Feb 2014 01:02:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371228</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371214</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10321] TestCompositeService should cover all enumerations of adding a service to a parent service</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10321</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10085&quot; title=&quot;CompositeService should allow adding services while being inited&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10085&quot;&gt;&lt;del&gt;HADOOP-10085&lt;/del&gt;&lt;/a&gt; fixes some synchronization issues in CompositeService#addService(). The tests should cover all cases. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12692552">HADOOP-10321</key>
            <summary>TestCompositeService should cover all enumerations of adding a service to a parent service</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="kkambatl">Karthik Kambatla</assignee>
                                    <reporter username="kkambatl">Karthik Kambatla</reporter>
                        <labels>
                            <label>test</label>
                    </labels>
                <created>Fri, 31 Jan 2014 18:06:30 +0000</created>
                <updated>Fri, 31 Jan 2014 18:06:30 +0000</updated>
                                            <version>2.3.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371153</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371139</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326144</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10320] Javadoc in InterfaceStability.java lacks final &lt;/ul&gt;</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10320</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12692549">HADOOP-10320</key>
            <summary>Javadoc in InterfaceStability.java lacks final &lt;/ul&gt;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Ren&#233; Nyffenegger">Ren&#233; Nyffenegger</assignee>
                                    <reporter username="Ren&#233; Nyffenegger">Ren&#233; Nyffenegger</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Jan 2014 17:57:49 +0000</created>
                <updated>Sat, 1 Feb 2014 13:40:00 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 20:19:12 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13887948" author="ren&#233; nyffenegger" created="Fri, 31 Jan 2014 18:03:14 +0000"  >&lt;p&gt;Please excuse my ignorance, but I can&apos;t seem to cope with jira. I tried to upload a patch for this issue, but I was unable to do so.&lt;/p&gt;</comment>
                            <comment id="13887958" author="cnauroth" created="Fri, 31 Jan 2014 18:18:20 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Ren%C3%A9+Nyffenegger&quot; class=&quot;user-hover&quot; rel=&quot;Ren&#233; Nyffenegger&quot;&gt;Ren&#233; Nyffenegger&lt;/a&gt;.  You can attach your patch file by clicking the More button at the top and then clicking Attach Files.  That will take you to another dialog where you can select the file to upload.  After that, you can click the Submit Patch button.  This will trigger trigger an automatic run on our Jenkins continuous integration servers to download your patch, apply it to a working copy of the current trunk, and then build and run tests.&lt;/p&gt;

&lt;p&gt;If you don&apos;t the buttons I mentioned at the top yet, then we might need a jira admin to flag you as a contributor.  I&apos;m working on getting that done for your account.&lt;/p&gt;</comment>
                            <comment id="13887966" author="ren&#233; nyffenegger" created="Fri, 31 Jan 2014 18:30:19 +0000"  >&lt;p&gt;Here&apos;s the patch, finally.&lt;/p&gt;</comment>
                            <comment id="13887968" author="ren&#233; nyffenegger" created="Fri, 31 Jan 2014 18:31:17 +0000"  >&lt;p&gt;Thanks for the directions. I was now able to upload the patch.&lt;/p&gt;</comment>
                            <comment id="13888037" author="hadoopqa" created="Fri, 31 Jan 2014 19:21:31 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626344/InterfaceStability.java.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626344/InterfaceStability.java.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+0 tests included&lt;/font&gt;.  The patch appears to be a documentation patch that doesn&apos;t require tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-annotations.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3512//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3512//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3512//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3512//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888095" author="cnauroth" created="Fri, 31 Jan 2014 19:59:37 +0000"  >&lt;p&gt;+1 for the patch.  I&apos;ll commit this in a moment.&lt;/p&gt;</comment>
                            <comment id="13888118" author="hudson" created="Fri, 31 Jan 2014 20:17:37 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5084 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5084/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5084/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10320&quot; title=&quot;Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10320&quot;&gt;&lt;del&gt;HADOOP-10320&lt;/del&gt;&lt;/a&gt;. Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;. Contributed by Ren&#233; Nyffenegger. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-annotations/src/main/java/org/apache/hadoop/classification/InterfaceStability.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888120" author="cnauroth" created="Fri, 31 Jan 2014 20:19:12 +0000"  >&lt;p&gt;I committed this to trunk and branch-2.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Ren%C3%A9+Nyffenegger&quot; class=&quot;user-hover&quot; rel=&quot;Ren&#233; Nyffenegger&quot;&gt;Ren&#233; Nyffenegger&lt;/a&gt;, thank you for your contribution!&lt;/p&gt;</comment>
                            <comment id="13888527" author="hudson" created="Sat, 1 Feb 2014 11:04:49 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #468 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10320&quot; title=&quot;Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10320&quot;&gt;&lt;del&gt;HADOOP-10320&lt;/del&gt;&lt;/a&gt;. Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;. Contributed by Ren&#233; Nyffenegger. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-annotations/src/main/java/org/apache/hadoop/classification/InterfaceStability.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888577" author="hudson" created="Sat, 1 Feb 2014 13:29:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1685 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10320&quot; title=&quot;Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10320&quot;&gt;&lt;del&gt;HADOOP-10320&lt;/del&gt;&lt;/a&gt;. Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;. Contributed by Ren&#233; Nyffenegger. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-annotations/src/main/java/org/apache/hadoop/classification/InterfaceStability.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888591" author="hudson" created="Sat, 1 Feb 2014 13:40:00 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1660 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10320&quot; title=&quot;Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10320&quot;&gt;&lt;del&gt;HADOOP-10320&lt;/del&gt;&lt;/a&gt;. Javadoc in InterfaceStability.java lacks final &amp;lt;/ul&amp;gt;. Contributed by Ren&#233; Nyffenegger. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563237&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-annotations/src/main/java/org/apache/hadoop/classification/InterfaceStability.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626344" name="InterfaceStability.java.patch" size="775" author="Ren&#233; Nyffenegger" created="Fri, 31 Jan 2014 18:30:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 18:18:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371150</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371136</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320357</customfieldvalue>
    <customfieldvalue>12326144</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10319] Unable to run Hadoop (2.2.0) commands on Cygwin (2.831) on Windows XP 3</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10319</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Did Following on starting Shell&lt;/p&gt;

&lt;p&gt;1. ssh localhost&lt;br/&gt;
2. cd /cygdrive/e/hadoop-2.2.0&lt;br/&gt;
3. export JAVA_HOME=/cygdrive/e/JDK&lt;br/&gt;
4. export HADOOP_INSTALL=/cygdrive/e/hadoop-2.2.o&lt;br/&gt;
5. export PATH=$PATH:$JAVA_HOME:$HADOOP_INSTALL/bin:$HADOOP_INSTALL/sbin&lt;/p&gt;

&lt;p&gt;I have installed JDK1.7.0_51&lt;/p&gt;

&lt;p&gt;At $hadoop version (throws) Error: Could not find or load main class org.apache.hadoop.util.Versioninfo&lt;/p&gt;

&lt;p&gt;Similar errors are thrown for fs and jar. I have not made any changes to any environment variables or scripts.&lt;/p&gt;

&lt;p&gt;I am new to Hadoop-2.2.0 and following text Hadoop- The Definitive Guide by Tom white where it has been suggested that Cygwin can be used with Windows and Hadoop 2.&lt;/p&gt;

&lt;p&gt;Advise appreciated. Thanks&lt;/p&gt;

&lt;p&gt;Anand&lt;/p&gt;</description>
                <environment>&lt;p&gt;Running Cygwin 2.831 on Windows XP SP3&lt;/p&gt;</environment>
        <key id="12692489">HADOOP-10319</key>
            <summary>Unable to run Hadoop (2.2.0) commands on Cygwin (2.831) on Windows XP 3</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="anand_vihar">Anand Murali</reporter>
                        <labels>
                            <label>patch</label>
                    </labels>
                <created>Fri, 31 Jan 2014 11:11:28 +0000</created>
                <updated>Sat, 1 Feb 2014 12:58:58 +0000</updated>
                            <resolved>Sat, 1 Feb 2014 12:58:58 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                    <timeoriginalestimate seconds="86400">24h</timeoriginalestimate>
                            <timeestimate seconds="86400">24h</timeestimate>
                                        <comments>
                            <comment id="13887670" author="stevel@apache.org" created="Fri, 31 Jan 2014 11:47:45 +0000"  >&lt;p&gt;Tom&apos;s book does not cover Hadoop 2.2; ask on mailing lists&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://wiki.apache.org/hadoop/InvalidJiraIssues&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://wiki.apache.org/hadoop/InvalidJiraIssues&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13888486" author="anand_vihar" created="Sat, 1 Feb 2014 08:15:20 +0000"  >&lt;p&gt;Dear Whoever:&lt;/p&gt;

&lt;p&gt;I am interested in knowing if Hadoop2.2.0 will work on Cygwin 1.8x running Windows XP- SP3. This is the issue for which I need advise and resolution. Many thanks,&lt;/p&gt;

&lt;p&gt;Anand&lt;/p&gt;</comment>
                            <comment id="13888567" author="stevel@apache.org" created="Sat, 1 Feb 2014 12:58:58 +0000"  >&lt;p&gt;hadoop 2.2 works on windows without cygwin&lt;/p&gt;

&lt;p&gt;please follow the instructions in the link to get help, instead of filing jiras. &lt;/p&gt;

&lt;p&gt;closing as invalid: this is not a support channel&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 11:47:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371090</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371076</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325048</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10318] Incorrect reference to nodeFile in RumenToSLSConverter error message</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10318</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (! nodeFile.getParentFile().exists()
            &amp;amp;&amp;amp; ! nodeFile.getParentFile().mkdirs()) {
      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;ERROR: Cannot create output directory in path: &quot;&lt;/span&gt;
              + jsonFile.getParentFile().getAbsoluteFile());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;jsonFile on the last line should be nodeFile&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692443">HADOOP-10318</key>
            <summary>Incorrect reference to nodeFile in RumenToSLSConverter error message</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="ywskycn">Wei Yan</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Fri, 31 Jan 2014 05:30:53 +0000</created>
                <updated>Fri, 31 Jan 2014 06:36:05 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13887502" author="ywskycn" created="Fri, 31 Jan 2014 06:02:56 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuzhihong%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yuzhihong@gmail.com&quot;&gt;Ted Yu&lt;/a&gt;. Just upload a patch to fix that bug.&lt;/p&gt;</comment>
                            <comment id="13887510" author="hadoopqa" created="Fri, 31 Jan 2014 06:29:49 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626263/HADOOP-10318.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626263/HADOOP-10318.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-tools/hadoop-sls.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3510//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3510//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3510//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3510//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13887519" author="ajisakaa" created="Fri, 31 Jan 2014 06:35:55 +0000"  >&lt;p&gt;LGTM, +1.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626263" name="HADOOP-10318.patch" size="819" author="ywskycn" created="Fri, 31 Jan 2014 06:02:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 06:02:56 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371044</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371030</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10317] Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10317</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Right now the pom.xml&apos;s refer to 2.4 rather than 2.3 in branch-2.3. We need to update them.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692425">HADOOP-10317</key>
            <summary>Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="andrew.wang">Andrew Wang</assignee>
                                    <reporter username="andrew.wang">Andrew Wang</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Jan 2014 01:14:06 +0000</created>
                <updated>Fri, 31 Jan 2014 13:39:16 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 02:10:58 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13887342" author="andrew.wang" created="Fri, 31 Jan 2014 01:16:00 +0000"  >&lt;p&gt;Patch attached. I used &lt;tt&gt;mvn versions:set -DnewVersion=2.3.0-SNAPSHOT&lt;/tt&gt; and did a grep to make sure that there are no longer any references to 2.4.0-SNAPSHOT.&lt;/p&gt;</comment>
                            <comment id="13887345" author="hadoopqa" created="Fri, 31 Jan 2014 01:22:55 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626237/hadoop-10317.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626237/hadoop-10317.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3509//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3509//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13887368" author="tucu00" created="Fri, 31 Jan 2014 01:53:13 +0000"  >&lt;p&gt;+1. applied to branch-2.3 locally and did a full build, all JARs are 2.3.0-SNAPSHOT.&lt;/p&gt;

&lt;p&gt;Once you commit, you can take the release job for a spin:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/build?delay=0sec&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/build?delay=0sec&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And if works OK, please +1 &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10313&quot; title=&quot;Script and jenkins job to produce Hadoop release artifacts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10313&quot;&gt;&lt;del&gt;HADOOP-10313&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13887388" author="andrew.wang" created="Fri, 31 Jan 2014 02:10:58 +0000"  >&lt;p&gt;Thanks tucu, I just pushed this and updated CHANGES.txt in other branches. I&apos;ll take the jenkins job for a spin now.&lt;/p&gt;</comment>
                            <comment id="13887392" author="hudson" created="Fri, 31 Jan 2014 02:17:49 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5079 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5079/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5079/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10317&quot; title=&quot;Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10317&quot;&gt;&lt;del&gt;HADOOP-10317&lt;/del&gt;&lt;/a&gt;. Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887655" author="hudson" created="Fri, 31 Jan 2014 11:14:08 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #467 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10317&quot; title=&quot;Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10317&quot;&gt;&lt;del&gt;HADOOP-10317&lt;/del&gt;&lt;/a&gt;. Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887739" author="hudson" created="Fri, 31 Jan 2014 13:29:54 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1684 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10317&quot; title=&quot;Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10317&quot;&gt;&lt;del&gt;HADOOP-10317&lt;/del&gt;&lt;/a&gt;. Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887753" author="hudson" created="Fri, 31 Jan 2014 13:39:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1659 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10317&quot; title=&quot;Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10317&quot;&gt;&lt;del&gt;HADOOP-10317&lt;/del&gt;&lt;/a&gt;. Rename branch-2.3 release version from 2.4.0-SNAPSHOT to 2.3.0-SNAPSHOT. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563035&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626237" name="hadoop-10317.patch" size="44001" author="andrew.wang" created="Fri, 31 Jan 2014 01:16:00 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 01:22:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371026</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371012</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10316] HadoopArchives#HArchiveInputFormat#getSplits() should check reader against null before calling close()</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10316</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Around line 267:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; { 
        reader.close();
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;reader should be checked against null&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692409">HADOOP-10316</key>
            <summary>HadoopArchives#HArchiveInputFormat#getSplits() should check reader against null before calling close()</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 23:54:32 +0000</created>
                <updated>Thu, 30 Jan 2014 23:54:32 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371010</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370996</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10315] Log the original exception when getGroups() fail in UGI.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10315</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;In UserGroupInformation, getGroupNames() swallows the original exception. There have been many occasions that more information on the original exception could have helped.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] getGroupNames() {
    ensureInitialized();
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; result = groups.getGroups(getShortUserName());
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; result.toArray(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[result.size()]);
    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException ie) {
      LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;No groups available &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; user &quot;&lt;/span&gt; + getShortUserName());
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[0];
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12692393">HADOOP-10315</key>
            <summary>Log the original exception when getGroups() fail in UGI.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="kihwal">Kihwal Lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 22:20:35 +0000</created>
                <updated>Thu, 30 Jan 2014 22:20:35 +0000</updated>
                                            <version>0.23.10</version>
                    <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370994</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370980</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326144</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10314] The ls command help still shows outdated 0.16 format.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10314</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The description of output format is vastly outdated. It was changed after version 0.16.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ hadoop fs -help ls
-ls [-d] [-h] [-R] [&amp;lt;path&amp;gt; ...]:	List the contents that match the specified file pattern. If
		path is not specified, the contents of /user/&amp;lt;currentUser&amp;gt;
		will be listed. Directory entries are of the form 
			dirName (full path) &amp;lt;dir&amp;gt; 
		and file entries are of the form 
			fileName(full path) &amp;lt;r n&amp;gt; size 
		where n is the number of replicas specified for the file 
		and size is the size of the file, in bytes.
		  -d  Directories are listed as plain files.
		  -h  Formats the sizes of files in a human-readable fashion
		      rather than a number of bytes.
		  -R  Recursively list the contents of directories.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12692388">HADOOP-10314</key>
            <summary>The ls command help still shows outdated 0.16 format.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="kihwal">Kihwal Lee</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Thu, 30 Jan 2014 22:00:35 +0000</created>
                <updated>Thu, 30 Jan 2014 22:00:35 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370989</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370975</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326144</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10313] Script and jenkins job to produce Hadoop release artifacts</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10313</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;As discussed in the dev mailing lists, we should have a jenkins job to build the release artifacts.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692369">HADOOP-10313</key>
            <summary>Script and jenkins job to produce Hadoop release artifacts</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tucu00">Alejandro Abdelnur</assignee>
                                    <reporter username="tucu00">Alejandro Abdelnur</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 19:29:30 +0000</created>
                <updated>Fri, 31 Jan 2014 13:39:14 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 03:57:58 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13886959" author="tucu00" created="Thu, 30 Jan 2014 19:31:43 +0000"  >&lt;p&gt;a &lt;tt&gt;create-release.sh&lt;/tt&gt; script would produce the release artifacts. This script would be committed in the dev-support/ directory of the branch.&lt;/p&gt;

&lt;p&gt;A parameterized jenkins jobs would take the branch name and the RC label and it would produce the release artifacts.&lt;/p&gt;

&lt;p&gt;The SRC and BIN tarballs would be MD5 but not signed. The release manager should pick up the artifacts and sign them before pushing them to a public staging area.&lt;/p&gt;</comment>
                            <comment id="13886960" author="tucu00" created="Thu, 30 Jan 2014 19:32:10 +0000"  >&lt;p&gt;initial version of the create-release.sh script.&lt;/p&gt;</comment>
                            <comment id="13886971" author="tucu00" created="Thu, 30 Jan 2014 19:41:24 +0000"  >&lt;p&gt;Jenkins job that will run the script: &lt;a href=&quot;https://builds.apache.org/job/HADOOP2%20Release%20Artifacts%20Builder/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HADOOP2%20Release%20Artifacts%20Builder/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13887029" author="tucu00" created="Thu, 30 Jan 2014 20:43:09 +0000"  >&lt;p&gt;removing SVN and MVN clean up, not needed, fresh checkout&lt;/p&gt;</comment>
                            <comment id="13887263" author="stack" created="Thu, 30 Jan 2014 23:51:59 +0000"  >&lt;p&gt;Alejandro, you want to add a bit of a comment on the head of the script explaining what it does and in which context it is used (should you say how to use it since it takes a RC_LABEL)? &lt;/p&gt;

&lt;p&gt;I tried the below manually and it works nicely:&lt;/p&gt;

&lt;p&gt;HADOOP_VERSION=`cat pom.xml | grep &quot;&amp;lt;version&amp;gt;&quot; | head -1 | sed &apos;s|^ &lt;b&gt;&amp;lt;version&amp;gt;||&apos; | sed &apos;s|&amp;lt;/version&amp;gt;.&lt;/b&gt;$||&apos;`&lt;/p&gt;

&lt;p&gt;nit: remove the &apos;for&apos; in following if you are going to make an new version: &quot;version for to&quot; (from a comment).&lt;/p&gt;

&lt;p&gt;I suppose you have the md5 so can check when you download so you have some security about what it is that you are signing.&lt;/p&gt;

&lt;p&gt;Otherwise looks great &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tucu00&quot; class=&quot;user-hover&quot; rel=&quot;tucu00&quot;&gt;Alejandro Abdelnur&lt;/a&gt;.  We have scripts building a release.  We should try and do as you do here and hoist them up to jenkins too.&lt;/p&gt;</comment>
                            <comment id="13887268" author="tucu00" created="Thu, 30 Jan 2014 23:59:18 +0000"  >&lt;p&gt;getting site generation right.&lt;/p&gt;</comment>
                            <comment id="13887282" author="tucu00" created="Fri, 31 Jan 2014 00:09:28 +0000"  >&lt;p&gt;Integrating &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; comments.&lt;/p&gt;

&lt;p&gt;Regarding the md5 files. The idea is simply one thing less to do by the release manager, s/he would only have to sign the SRC and BIN tarball artifacts before staging them.&lt;/p&gt;

&lt;p&gt;Once the Jenkins build finishes (&lt;a href=&quot;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/&lt;/a&gt;) and I verify things are ok, I&apos;ll put the script in patch form. And after commit, I&apos;ll modify the jenkins configuration to consume it from the checked out source itself.&lt;/p&gt;</comment>
                            <comment id="13887314" author="tucu00" created="Fri, 31 Jan 2014 00:40:14 +0000"  >&lt;p&gt;OK,&lt;/p&gt;

&lt;p&gt;We have:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;A script, &lt;tt&gt;create-release.sh&lt;/tt&gt;, that creates release artifacts&lt;/li&gt;
	&lt;li&gt;An Apache Jenkins job that runs the script and produces the artifacts in Apache CI machines, thanks Yahoo! (or shouldn&#8217;t I say that?)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The Apache Jenkins job is:&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There you&#8217;ll see the output of an release build. When triggering the build, you can specify an RC_LABEL (RC0 in this case). If you do so all the artifact files will be postfixed with it.&lt;/p&gt;

&lt;p&gt;The job is currently producing:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;RAT report&lt;/li&gt;
	&lt;li&gt;SOURCE tarball and its MD5&lt;/li&gt;
	&lt;li&gt;BINARY tarball and its MD5&lt;/li&gt;
	&lt;li&gt;SITE tarball (ready to plaster in Apache Hadoop site)&lt;/li&gt;
	&lt;li&gt;CHANGES files&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&#8217;ve verified the produced SOURCE is correct and I can build a BINARY out of it.&lt;/p&gt;

&lt;p&gt;I&#8217;ve verified the produced BINARY tarball works (in pseudo-cluster mode).&lt;/p&gt;

&lt;p&gt;Running &lt;tt&gt;hadoop-version&lt;/tt&gt; from the BINARY a tarball reports:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ bin/hadoop version
Hadoop 2.4.0-SNAPSHOT
Subversion http:&lt;span class=&quot;code-comment&quot;&gt;//svn.apache.org/repos/asf/hadoop/common -r 1563020
&lt;/span&gt;Compiled by jenkins on 2014-01-31T00:03Z
Compiled with protoc 2.5.0
From source with checksum 37ccb6f84b23196f521243fd192070
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the JIRA is committed we have to modify the Jenkins job to use the script from &lt;tt&gt;dev-support/&lt;/tt&gt; directory.&lt;/p&gt;

&lt;p&gt;We could improve this script further to deploy the built JARs to the Maven repo. I don&#8217;t know how to do this, so it would be great if somebody that know how jumps on that. Maybe a s a follow up JIRA, so we have something going.&lt;/p&gt;</comment>
                            <comment id="13887327" author="hadoopqa" created="Fri, 31 Jan 2014 00:58:33 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626231/HADOOP-10313.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626231/HADOOP-10313.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3508//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3508//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3508//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3508//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13887414" author="andrew.wang" created="Fri, 31 Jan 2014 03:04:34 +0000"  >&lt;p&gt;+1, nice work tucu. I gave the bash script a quick review, but the proof is in the pudding. I tried the Jenkins job on the current branch-2.3, and the generated artifacts look good:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/16/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HADOOP2_Release_Artifacts_Builder/16/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Setting this up to build nightlies of the latest 2.x release branch (and branch-2 also) would be super cool. That, with automatic mvn deploy (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rvs&quot; class=&quot;user-hover&quot; rel=&quot;rvs&quot;&gt;Roman Shaposhnik&lt;/a&gt; implied that it should just work from Jenkins slaves), means we can get real CI with bigtop going!&lt;/p&gt;</comment>
                            <comment id="13887439" author="tucu00" created="Fri, 31 Jan 2014 03:57:58 +0000"  >&lt;p&gt;Committed to trunk, branch-2 and branch-2.3.&lt;/p&gt;</comment>
                            <comment id="13887457" author="hudson" created="Fri, 31 Jan 2014 04:33:57 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5080 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5080/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5080/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10313&quot; title=&quot;Script and jenkins job to produce Hadoop release artifacts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10313&quot;&gt;&lt;del&gt;HADOOP-10313&lt;/del&gt;&lt;/a&gt;. Script and jenkins job to produce Hadoop release artifacts. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/dev-support/create-release.sh&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887474" author="stack" created="Fri, 31 Jan 2014 05:08:28 +0000"  >&lt;p&gt;v2 lgtm&lt;/p&gt;</comment>
                            <comment id="13887645" author="hudson" created="Fri, 31 Jan 2014 11:14:07 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #467 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10313&quot; title=&quot;Script and jenkins job to produce Hadoop release artifacts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10313&quot;&gt;&lt;del&gt;HADOOP-10313&lt;/del&gt;&lt;/a&gt;. Script and jenkins job to produce Hadoop release artifacts. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/dev-support/create-release.sh&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887729" author="hudson" created="Fri, 31 Jan 2014 13:29:53 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1684 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10313&quot; title=&quot;Script and jenkins job to produce Hadoop release artifacts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10313&quot;&gt;&lt;del&gt;HADOOP-10313&lt;/del&gt;&lt;/a&gt;. Script and jenkins job to produce Hadoop release artifacts. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/dev-support/create-release.sh&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887743" author="hudson" created="Fri, 31 Jan 2014 13:39:14 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1659 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10313&quot; title=&quot;Script and jenkins job to produce Hadoop release artifacts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10313&quot;&gt;&lt;del&gt;HADOOP-10313&lt;/del&gt;&lt;/a&gt;. Script and jenkins job to produce Hadoop release artifacts. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563043&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/dev-support/create-release.sh&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12611279">HADOOP-8914</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626231" name="HADOOP-10313.patch" size="4658" author="tucu00" created="Fri, 31 Jan 2014 00:40:14 +0000"/>
                            <attachment id="12626221" name="create-release.sh" size="4124" author="tucu00" created="Fri, 31 Jan 2014 00:09:28 +0000"/>
                            <attachment id="12626215" name="create-release.sh" size="3976" author="tucu00" created="Thu, 30 Jan 2014 23:59:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 23:51:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370970</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370956</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10312] Shell.ExitCodeException to have more useful toString</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10312</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Shell&apos;s ExitCodeException doesn&apos;t include the exit code in the toString value, so isn&apos;t that useful in diagnosing container start failures in YARN&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692286">HADOOP-10312</key>
            <summary>Shell.ExitCodeException to have more useful toString</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stevel@apache.org">Steve Loughran</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 14:27:43 +0000</created>
                <updated>Fri, 31 Jan 2014 17:29:12 +0000</updated>
                                            <version>2.4.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13886610" author="stevel@apache.org" created="Thu, 30 Jan 2014 14:28:24 +0000"  >&lt;p&gt;Example&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2014-01-30 14:20:12,042 [AMRM Callback Handler &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;] INFO  HoyaAppMaster.yarn (HoyaAppMaster.java:onContainersCompleted(839)) - Container Completion &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; containerID=container_1391075472386_0004_01_000032, state=COMPLETE, exitStatus=1, diagnostics=Exception from container-launch: org.apache.hadoop.util.Shell$ExitCodeException: 
org.apache.hadoop.util.Shell$ExitCodeException: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:505)
	at org.apache.hadoop.util.Shell.run(Shell.java:418)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:650)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;it failed, but it&apos;s not obvious why&lt;/p&gt;</comment>
                            <comment id="13887921" author="cnauroth" created="Fri, 31 Jan 2014 17:29:12 +0000"  >&lt;p&gt;I&apos;ve always wanted it to be easier to capture stdout/stderr from failed external commands too.  It could be potentially spammy though, so maybe it would need to go behind debug log level somehow.&lt;/p&gt;

&lt;p&gt;If you want to keep the scope of this issue to just the exit code, please go ahead, and I&apos;ll file a separate issue related to capturing stdout/stderr.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12680758">YARN-1438</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12639965">YARN-522</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 17:29:12 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370887</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370873</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10311] Cleanup vendor names from the code base</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10311</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12692211">HADOOP-10311</key>
            <summary>Cleanup vendor names from the code base</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tucu00">Alejandro Abdelnur</assignee>
                                    <reporter username="sureshms">Suresh Srinivas</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 04:18:07 +0000</created>
                <updated>Sat, 1 Feb 2014 13:40:00 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 20:13:04 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="13886242" author="sureshms" created="Thu, 30 Jan 2014 04:22:05 +0000"  >&lt;p&gt;Following should be changed:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.job.working.dir&quot; : &quot;hdfs://a2115.halxg.cloudera.com:8020/user/jenkins&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;dfs.namenode.http-address&quot; : &quot;a2115.halxg.cloudera.com:20101&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.admin.address&quot; : &quot;a2115.halxg.cloudera.com:8033&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;dfs.namenode.https-address&quot; : &quot;a2115.halxg.cloudera.com:20102&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.jobhistory.address&quot; : &quot;a2115.halxg.cloudera.com:10020&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.job.submithostname&quot; : &quot;a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.address&quot; : &quot;a2115.halxg.cloudera.com:8032&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.output.fileoutputformat.outputdir&quot; : &quot;hdfs://a2115.halxg.cloudera.com:8020/user/jenkins/tera-gen-1&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.jobhistory.webapp.address&quot; : &quot;a2115.halxg.cloudera.com:19888&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;fs.defaultFS&quot; : &quot;hdfs://a2115.halxg.cloudera.com:8020&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.scheduler.address&quot; : &quot;a2115.halxg.cloudera.com:8030&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.resource-tracker.address&quot; : &quot;a2115.halxg.cloudera.com:8031&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.webapp.address&quot; : &quot;a2115.halxg.cloudera.com:8088&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2117.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2117.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2115.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2116.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2116.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:        &quot;layers&quot; : [ &quot;default-rack&quot;, &quot;a2118.halxg.cloudera.com&quot; ]
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:      &quot;hostName&quot; : &quot;/default-rack/a2118.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.job.working.dir&quot; : &quot;hdfs://a2115.halxg.cloudera.com:8020/user/jenkins&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;dfs.namenode.http-address&quot; : &quot;a2115.halxg.cloudera.com:20101&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.admin.address&quot; : &quot;a2115.halxg.cloudera.com:8033&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;dfs.namenode.https-address&quot; : &quot;a2115.halxg.cloudera.com:20102&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.jobhistory.address&quot; : &quot;a2115.halxg.cloudera.com:10020&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.job.submithostname&quot; : &quot;a2115.halxg.cloudera.com&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.address&quot; : &quot;a2115.halxg.cloudera.com:8032&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.output.fileoutputformat.outputdir&quot; : &quot;hdfs://a2115.halxg.cloudera.com:8020/user/jenkins/tera-gen-2&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;mapreduce.jobhistory.webapp.address&quot; : &quot;a2115.halxg.cloudera.com:19888&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;fs.defaultFS&quot; : &quot;hdfs://a2115.halxg.cloudera.com:8020&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.scheduler.address&quot; : &quot;a2115.halxg.cloudera.com:8030&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.resource-tracker.address&quot; : &quot;a2115.halxg.cloudera.com:8031&quot;,
./hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json:    &quot;yarn.resourcemanager.webapp.address&quot; : &quot;a2115.halxg.cloudera.com:8088&quot;,
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13886809" author="cutting" created="Thu, 30 Jan 2014 17:33:43 +0000"  >&lt;p&gt;+1 We should generally avoid vendor names in our products, as they might appear to be endorsements or otherwise meant to bias users.&lt;/p&gt;</comment>
                            <comment id="13887104" author="sandyr" created="Thu, 30 Jan 2014 21:43:45 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13887108" author="tucu00" created="Thu, 30 Jan 2014 21:45:39 +0000"  >&lt;p&gt;I should have caught this reference when doing the review, sorry about that. I&apos;ll commit after Jenkins +1s&lt;/p&gt;</comment>
                            <comment id="13887160" author="hadoopqa" created="Thu, 30 Jan 2014 22:12:28 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626184/HADOOP-10311.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626184/HADOOP-10311.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-tools/hadoop-sls.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3507//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3507//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3507//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3507//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888106" author="tucu00" created="Fri, 31 Jan 2014 20:13:04 +0000"  >&lt;p&gt;Committed to trunk, branch-2 and branch-2.3.&lt;/p&gt;</comment>
                            <comment id="13888129" author="hudson" created="Fri, 31 Jan 2014 20:30:58 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5085 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5085/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5085/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10311&quot; title=&quot;Cleanup vendor names from the code base&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10311&quot;&gt;&lt;del&gt;HADOOP-10311&lt;/del&gt;&lt;/a&gt;. Cleanup vendor names from the code base. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888524" author="hudson" created="Sat, 1 Feb 2014 11:04:48 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #468 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10311&quot; title=&quot;Cleanup vendor names from the code base&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10311&quot;&gt;&lt;del&gt;HADOOP-10311&lt;/del&gt;&lt;/a&gt;. Cleanup vendor names from the code base. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888574" author="hudson" created="Sat, 1 Feb 2014 13:29:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1685 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10311&quot; title=&quot;Cleanup vendor names from the code base&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10311&quot;&gt;&lt;del&gt;HADOOP-10311&lt;/del&gt;&lt;/a&gt;. Cleanup vendor names from the code base. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888588" author="hudson" created="Sat, 1 Feb 2014 13:40:00 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1660 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10311&quot; title=&quot;Cleanup vendor names from the code base&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10311&quot;&gt;&lt;del&gt;HADOOP-10311&lt;/del&gt;&lt;/a&gt;. Cleanup vendor names from the code base. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563239&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-sls/src/main/data/2jobs2min-rumen-jh.json&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12692193">HDFS-5852</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626184" name="HADOOP-10311.patch" size="100359" author="tucu00" created="Thu, 30 Jan 2014 21:42:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 17:33:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370811</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370797</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10310] SaslRpcServer should be initialized even when no secret manager present</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10310</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8783&quot; title=&quot;Improve RPC.Server&amp;#39;s digest auth&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8783&quot;&gt;&lt;del&gt;HADOOP-8783&lt;/del&gt;&lt;/a&gt; made a change which caused the SaslRpcServer not to be initialized if there is no secret manager present. This works fine for most Hadoop daemons because they need a secret manager to do their business, but JournalNodes do not. The result of this is that JournalNodes are broken and will not handle RPCs in a Kerberos-enabled environment, since the SaslRpcServer will not be initialized.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692181">HADOOP-10310</key>
            <summary>SaslRpcServer should be initialized even when no secret manager present</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="atm">Aaron T. Myers</assignee>
                                    <reporter username="atm">Aaron T. Myers</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 23:47:18 +0000</created>
                <updated>Fri, 31 Jan 2014 13:39:15 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 15:57:05 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="13886021" author="atm" created="Wed, 29 Jan 2014 23:50:41 +0000"  >&lt;p&gt;Here&apos;s a simple patch which addresses the issue by initializing the SaslRpcServer in the case that there is either a secret manager OR security is enabled.&lt;/p&gt;

&lt;p&gt;I tested this patch manually and confirmed that it works as expected. Without it, I cannot format JNs with security enabled. With the patch, the JNs can be formatted and work just fine.&lt;/p&gt;</comment>
                            <comment id="13886028" author="hadoopqa" created="Wed, 29 Jan 2014 23:55:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626017/HADOOP-10310.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626017/HADOOP-10310.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  Trunk compilation may be broken.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3502//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3502//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886033" author="apurtell" created="Wed, 29 Jan 2014 23:56:57 +0000"  >&lt;p&gt;Pretty sure &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8983&quot; title=&quot;Minor fixes to windows batch scripts to accept alternate config directory location&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8983&quot;&gt;&lt;del&gt;HADOOP-8983&lt;/del&gt;&lt;/a&gt; wasn&apos;t the breaking change&lt;/p&gt;</comment>
                            <comment id="13886034" author="atm" created="Wed, 29 Jan 2014 23:58:43 +0000"  >&lt;p&gt;You&apos;re right, my bad. It was &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8783&quot; title=&quot;Improve RPC.Server&amp;#39;s digest auth&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8783&quot;&gt;&lt;del&gt;HADOOP-8783&lt;/del&gt;&lt;/a&gt;. Updating description to suit.&lt;/p&gt;</comment>
                            <comment id="13886035" author="atm" created="Thu, 30 Jan 2014 00:00:12 +0000"  >&lt;p&gt;Updated patch rebased on trunk.&lt;/p&gt;</comment>
                            <comment id="13886037" author="apurtell" created="Thu, 30 Jan 2014 00:01:10 +0000"  >&lt;p&gt;Thanks ATM that helps out.&lt;/p&gt;</comment>
                            <comment id="13886090" author="hadoopqa" created="Thu, 30 Jan 2014 00:41:39 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626019/HADOOP-10310.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626019/HADOOP-10310.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3503//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3503//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3503//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3503//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886106" author="andrew.wang" created="Thu, 30 Jan 2014 00:56:03 +0000"  >&lt;p&gt;+1, thanks ATM.&lt;/p&gt;</comment>
                            <comment id="13886678" author="daryn" created="Thu, 30 Jan 2014 15:46:08 +0000"  >&lt;p&gt;Oops.  +1&lt;/p&gt;</comment>
                            <comment id="13886685" author="atm" created="Thu, 30 Jan 2014 15:48:07 +0000"  >&lt;p&gt;Thanks a lot for the reviews, Andrew and Daryn. I&apos;m going to commit this momentarily.&lt;/p&gt;</comment>
                            <comment id="13886692" author="hudson" created="Thu, 30 Jan 2014 15:56:36 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5068 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5068/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5068/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10310&quot; title=&quot;SaslRpcServer should be initialized even when no secret manager present&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10310&quot;&gt;&lt;del&gt;HADOOP-10310&lt;/del&gt;&lt;/a&gt;. SaslRpcServer should be initialized even when no secret manager present. Contributed by Aaron T. Myers. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886694" author="atm" created="Thu, 30 Jan 2014 15:57:05 +0000"  >&lt;p&gt;I&apos;ve just committed this to trunk, branch-2, and branch-2.3.&lt;/p&gt;

&lt;p&gt;Thanks again for the prompt reviews, gents. Much appreciated.&lt;/p&gt;</comment>
                            <comment id="13887646" author="hudson" created="Fri, 31 Jan 2014 11:14:07 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #467 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10310&quot; title=&quot;SaslRpcServer should be initialized even when no secret manager present&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10310&quot;&gt;&lt;del&gt;HADOOP-10310&lt;/del&gt;&lt;/a&gt;. SaslRpcServer should be initialized even when no secret manager present. Contributed by Aaron T. Myers. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887730" author="hudson" created="Fri, 31 Jan 2014 13:29:53 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1684 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10310&quot; title=&quot;SaslRpcServer should be initialized even when no secret manager present&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10310&quot;&gt;&lt;del&gt;HADOOP-10310&lt;/del&gt;&lt;/a&gt;. SaslRpcServer should be initialized even when no secret manager present. Contributed by Aaron T. Myers. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887744" author="hudson" created="Fri, 31 Jan 2014 13:39:15 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1659 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10310&quot; title=&quot;SaslRpcServer should be initialized even when no secret manager present&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10310&quot;&gt;&lt;del&gt;HADOOP-10310&lt;/del&gt;&lt;/a&gt;. SaslRpcServer should be initialized even when no secret manager present. Contributed by Aaron T. Myers. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562863&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626019" name="HADOOP-10310.patch" size="686" author="atm" created="Thu, 30 Jan 2014 00:00:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 29 Jan 2014 23:55:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370778</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370767</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10309] S3 block filesystem should more aggressively delete temporary files</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10309</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The S3 FileSystem reading implementation downloads block files into a configurable temporary directory. deleteOnExit() is called on these files, so they are deleted when the JVM exits.&lt;/p&gt;

&lt;p&gt;However, JVM reuse can lead to JVMs that stick around for a very long time. This can cause these temporary files to build up indefinitely and, in the worst case, fill up the local directory.&lt;/p&gt;

&lt;p&gt;After a block file has been read, there is no reason to keep it around. It should be deleted.&lt;/p&gt;

&lt;p&gt;Writing to the S3 FileSystem already has this behavior; after a temporary block file is written and uploaded to S3, it is deleted immediately; there is no need to wait for the JVM to exit.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692159">HADOOP-10309</key>
            <summary>S3 block filesystem should more aggressively delete temporary files</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="joefkelley">Joe Kelley</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 22:15:22 +0000</created>
                <updated>Thu, 30 Jan 2014 10:27:30 +0000</updated>
                                                                            <component>fs/s3</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13886448" author="stevel@apache.org" created="Thu, 30 Jan 2014 09:42:25 +0000"  >&lt;p&gt;submitting patch, though as jenkins doesn&apos;t run the S3 tests it&apos;ll need a manual run through. &lt;/p&gt;</comment>
                            <comment id="13886472" author="hadoopqa" created="Thu, 30 Jan 2014 10:27:30 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625989/HADOOP-10309.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625989/HADOOP-10309.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3505//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3505//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3505//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3505//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3505//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3505//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625989" name="HADOOP-10309.patch" size="697" author="joefkelley" created="Wed, 29 Jan 2014 22:16:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 09:42:25 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370756</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370745</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>fs s3</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10308] Remove from core-default.xml unsupported &apos;classic&apos; and add &apos;yarn-tez&apos; as value for mapreduce.framework.name property</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10308</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Classic mr-v1 is no more supported in trunk.&lt;br/&gt;
On the other hand, we will soon have yarn-tez implementation of mapreduce (tez layer allowing to have a single AM for all map-reduce jobs).&lt;/p&gt;

&lt;p&gt;core-default.xml must reflect this.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692116">HADOOP-10308</key>
            <summary>Remove from core-default.xml unsupported &apos;classic&apos; and add &apos;yarn-tez&apos; as value for mapreduce.framework.name property</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="eric@apache.org">Eric Charles</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 19:45:19 +0000</created>
                <updated>Fri, 31 Jan 2014 02:59:13 +0000</updated>
                                                                            <component>conf</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13885713" author="eric@apache.org" created="Wed, 29 Jan 2014 19:46:48 +0000"  >&lt;p&gt;Simple patch that change the description in core-default.xml. No value changed, so safe to commit.&lt;/p&gt;</comment>
                            <comment id="13887410" author="qwertymaniac" created="Fri, 31 Jan 2014 02:59:13 +0000"  >&lt;p&gt;We can remove &apos;classic&apos; as it brings no value today, agreed.&lt;/p&gt;

&lt;p&gt;Last I checked, we do not ship Tez as part of Apache Hadoop, so why add an option that needs to be in Tez&apos;s docs instead, one that will also need Tez to be fully present in order to work, if one makes the switch to it?&lt;/p&gt;

&lt;p&gt;We should instead alter the description to make it sound more generic instead, that the values are not limited to yarn and local, and can instead be set to IDs specified by other MR or MR-like runtimes.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625941" name="HADOOP-10308.patch" size="812" author="eric@apache.org" created="Wed, 29 Jan 2014 19:46:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 02:59:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370713</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370705</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10307] Support multiple Authentication mechanisms for HTTP</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10307</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Currently it is possible to specify a custom Authentication Handler  for HTTP authentication.  &lt;br/&gt;
We have a requirement to support multiple mechanisms  to authenticate HTTP access.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692115">HADOOP-10307</key>
            <summary>Support multiple Authentication mechanisms for HTTP</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="3" iconUrl="https://issues.apache.org/jira/images/icons/statuses/inprogress.png">In Progress</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="benoyantony">Benoy Antony</assignee>
                                    <reporter username="benoyantony">Benoy Antony</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 19:41:24 +0000</created>
                <updated>Fri, 31 Jan 2014 18:44:03 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13885711" author="benoyantony" created="Wed, 29 Jan 2014 19:45:46 +0000"  >&lt;p&gt;The requirement is implemented as below:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Modify AuthenticationFilter so that it accepts multiple &lt;em&gt;AuthenticationHandler&lt;/em&gt; via &lt;em&gt;type&lt;/em&gt; as a comma separated list.&lt;/li&gt;
	&lt;li&gt;First &lt;em&gt;AuthenticationHandler&lt;/em&gt; in the list is set as the default&lt;/li&gt;
	&lt;li&gt;To authenticate a user, AuthenticationFilter looks for &lt;em&gt;authtype&lt;/em&gt; url parameter.&lt;br/&gt;
If parameter is present, corresponding &lt;em&gt;AuthenticationHandler&lt;/em&gt; is looked up by matching &lt;em&gt;authtype&lt;/em&gt;  with &lt;em&gt;AuthenticationHandler&lt;/em&gt;&apos;s type value. Authentication is attempted using the matched &lt;em&gt;AuthenticationHandler&lt;/em&gt;&lt;br/&gt;
If the &lt;em&gt;authtype&lt;/em&gt; parameter is not present, default Authentication is used.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I believe , the behavior is backward compatible.&lt;br/&gt;
&lt;em&gt;Test AuthenticationFilter&lt;/em&gt;  is modified to include unit tests for multiple mechanisms.&lt;br/&gt;
This is tested in our clusters.&lt;/p&gt;</comment>
                            <comment id="13885768" author="rkanter" created="Wed, 29 Jan 2014 20:32:16 +0000"  >&lt;p&gt;This sounds similar to the &lt;tt&gt;AltKerberosAuthenticationHandler&lt;/tt&gt; added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9054&quot; title=&quot;Add AuthenticationHandler that uses Kerberos but allows for an alternate form of authentication for browsers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9054&quot;&gt;&lt;del&gt;HADOOP-9054&lt;/del&gt;&lt;/a&gt;.  The &lt;tt&gt;AltKerberosAuthenticationHandler&lt;/tt&gt; uses Kerberos or &lt;em&gt;some other AuthenticationHandler&lt;/em&gt; based on the user agent.  For example, you can have all CLI access use Kerberos (by falling back to the &lt;tt&gt;KerberosAuthenticationHandler&lt;/tt&gt; and all browsers use some custom authentication (by subclassing &lt;tt&gt;AltKerberosAuthenticationHandler&lt;/tt&gt; to implement the custom authentication handler).  You could have a chain of these authentication handlers to do more than two.  Would this sufficient for your needs?  &lt;/p&gt;</comment>
                            <comment id="13886775" author="benoyantony" created="Thu, 30 Jan 2014 16:55:14 +0000"  >&lt;p&gt;@rkanter,   Using )AltKerberosAuthenticationHandler_ seems like a way to introduce multiple mechanisms as if its a single mechanism. This will result in one implementation which knows about all mechanisms. Not sure if that&apos;s the standard/right pattern to plugin multiple implementations of an interface to a framework. &lt;/p&gt;

&lt;p&gt;The approach that we have used to specify the different &lt;em&gt;AuthenticationHandler&lt;/em&gt; implementations directly in the configuration. The default implementation can be specified by keeping it at the beginning of the list. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12682724">HADOOP-10158</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625940" name="HADOOP-10307.patch" size="15873" author="benoyantony" created="Wed, 29 Jan 2014 19:45:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 29 Jan 2014 20:32:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370712</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370704</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10306] Unnecessary weak reference map to cache classes in Configuration</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10306</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;In Configuration.getClassByNameOrNull():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (CACHE_CLASSES) {
      map = CACHE_CLASSES.get(classLoader);
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (map == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        map = Collections.synchronizedMap(
          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WeakHashMap&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, WeakReference&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;?&amp;gt;&amp;gt;&amp;gt;());
        CACHE_CLASSES.put(classLoader, map);
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Change &quot;new WeaHashMap&amp;lt;String, ...&amp;gt;()&quot; to &quot;new HashMap&amp;lt;String, ...&amp;gt;&quot; or something. Otherwise, even while the class is actively used, this may drop its class cache.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12691965">HADOOP-10306</key>
            <summary>Unnecessary weak reference map to cache classes in Configuration</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ikeda">Hiroshi Ikeda</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 06:22:09 +0000</created>
                <updated>Wed, 29 Jan 2014 06:22:09 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370561</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370553</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10305] Add &quot;rpc.metrics.quantile.enable&quot; and &quot;rpc.metrics.percentiles.intervals&quot; to core-default.xml</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10305</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&quot;rpc.metrics.quantile.enable&quot; and &quot;rpc.metrics.percentiles.intervals&quot; were added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9420&quot; title=&quot;Add percentile or max metric for rpcQueueTime, processing time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9420&quot;&gt;&lt;del&gt;HADOOP-9420&lt;/del&gt;&lt;/a&gt;, but these two parameters are not written in core-default.xml.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691964">HADOOP-10305</key>
            <summary>Add &quot;rpc.metrics.quantile.enable&quot; and &quot;rpc.metrics.percentiles.intervals&quot; to core-default.xml</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ajisakaa">Akira AJISAKA</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 06:18:29 +0000</created>
                <updated>Thu, 30 Jan 2014 13:49:12 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 01:08:19 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                    <component>metrics</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13885082" author="ajisakaa" created="Wed, 29 Jan 2014 06:57:07 +0000"  >&lt;p&gt;Attaching a patch.&lt;/p&gt;</comment>
                            <comment id="13885113" author="hadoopqa" created="Wed, 29 Jan 2014 07:38:35 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625805/HADOOP-10305.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625805/HADOOP-10305.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3499//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3499//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3499//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3499//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13885125" author="ajisakaa" created="Wed, 29 Jan 2014 08:07:11 +0000"  >&lt;p&gt;The patch is to add parameters to config file, so new test are not needed.&lt;/p&gt;</comment>
                            <comment id="13886112" author="andrew.wang" created="Thu, 30 Jan 2014 01:01:23 +0000"  >&lt;p&gt;+1, nice find and nice patch. Will commit shortly.&lt;/p&gt;</comment>
                            <comment id="13886118" author="andrew.wang" created="Thu, 30 Jan 2014 01:08:19 +0000"  >&lt;p&gt;Merged to trunk, branch-2, branch-2.3. Thanks for the contribution Akira!&lt;/p&gt;</comment>
                            <comment id="13886137" author="hudson" created="Thu, 30 Jan 2014 01:25:53 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5066 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5066/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5066/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10305&quot; title=&quot;Add &amp;quot;rpc.metrics.quantile.enable&amp;quot; and &amp;quot;rpc.metrics.percentiles.intervals&amp;quot; to core-default.xml&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10305&quot;&gt;&lt;del&gt;HADOOP-10305&lt;/del&gt;&lt;/a&gt;. Add rpc.metrics.quantile.enable and rpc.metrics.percentiles.intervals to core-default.xml. Contributed by Akira Ajisaka. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/CommonConfigurationKeys.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/metrics/RpcMetrics.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886503" author="hudson" created="Thu, 30 Jan 2014 11:13:32 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #466 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10305&quot; title=&quot;Add &amp;quot;rpc.metrics.quantile.enable&amp;quot; and &amp;quot;rpc.metrics.percentiles.intervals&amp;quot; to core-default.xml&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10305&quot;&gt;&lt;del&gt;HADOOP-10305&lt;/del&gt;&lt;/a&gt;. Add rpc.metrics.quantile.enable and rpc.metrics.percentiles.intervals to core-default.xml. Contributed by Akira Ajisaka. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/CommonConfigurationKeys.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/metrics/RpcMetrics.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886569" author="hudson" created="Thu, 30 Jan 2014 13:29:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1683 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10305&quot; title=&quot;Add &amp;quot;rpc.metrics.quantile.enable&amp;quot; and &amp;quot;rpc.metrics.percentiles.intervals&amp;quot; to core-default.xml&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10305&quot;&gt;&lt;del&gt;HADOOP-10305&lt;/del&gt;&lt;/a&gt;. Add rpc.metrics.quantile.enable and rpc.metrics.percentiles.intervals to core-default.xml. Contributed by Akira Ajisaka. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/CommonConfigurationKeys.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/metrics/RpcMetrics.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886587" author="hudson" created="Thu, 30 Jan 2014 13:49:12 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1658 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10305&quot; title=&quot;Add &amp;quot;rpc.metrics.quantile.enable&amp;quot; and &amp;quot;rpc.metrics.percentiles.intervals&amp;quot; to core-default.xml&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10305&quot;&gt;&lt;del&gt;HADOOP-10305&lt;/del&gt;&lt;/a&gt;. Add rpc.metrics.quantile.enable and rpc.metrics.percentiles.intervals to core-default.xml. Contributed by Akira Ajisaka. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562659&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/CommonConfigurationKeys.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/metrics/RpcMetrics.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12638020">HADOOP-9420</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625805" name="HADOOP-10305.patch" size="2960" author="ajisakaa" created="Wed, 29 Jan 2014 06:57:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 29 Jan 2014 07:38:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370560</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370552</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10304] Configuration should not expose its instance in constructors</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10304</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;org.apache.hadoop.conf.Configuration exposes a reference of its instance in constructors via its class variable REGISTRY, which means incomplete instances are accessible. For example addDefaultResource() may access incomplete instances (especially for subclasses of Configuration).&lt;/p&gt;

&lt;p&gt;Actually, static methods in Configuration are not needed to access its instances, and it is enough that each instance checks modification of class variables. This is also useful to avoid deadlock between locking instances and locking the class object, which may be happened when you will resolve race conditions yet existing in Configuration.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691961">HADOOP-10304</key>
            <summary>Configuration should not expose its instance in constructors</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ikeda">Hiroshi Ikeda</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 06:01:38 +0000</created>
                <updated>Wed, 29 Jan 2014 06:01:38 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370557</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370549</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10303] multi-supergroup supports</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10303</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Most operating system supports multiple groups of administrators.&#160;&lt;br/&gt;
For Hadoop, it only supports a single supergroup.&lt;br/&gt;
This Jira requires to enhance open source hadoop to support multiple group of administrators.&#160; &lt;br/&gt;
for example,we have data administrators to manage HDFS (supergroup A)&lt;br/&gt;
and application administrators(supergroup B) to manage Mapreduce.&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691958">HADOOP-10303</key>
            <summary>multi-supergroup supports</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="xujiqiu">Jiqiu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 05:42:00 +0000</created>
                <updated>Wed, 29 Jan 2014 05:42:00 +0000</updated>
                                            <version>1.2.1</version>
                    <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370554</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370546</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>multi supergroup</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12324147</customfieldvalue>
    <customfieldvalue>12325048</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10302] Allow CallQueue impls to be swapped at runtime (part 1: internals) Depends on: subtask1</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10302</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;We wish to swap the active call queue during runtime in order to do performance tuning without restarting the namenode.&lt;/p&gt;

&lt;p&gt;This patch adds only the internals necessary to swap. Part 2 will add a user interface so that it can be used.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691859">HADOOP-10302</key>
            <summary>Allow CallQueue impls to be swapped at runtime (part 1: internals) Depends on: subtask1</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jan 2014 22:07:59 +0000</created>
                <updated>Tue, 28 Jan 2014 22:57:55 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13884794" author="chrilisf" created="Tue, 28 Jan 2014 22:30:06 +0000"  >&lt;p&gt;Depends on subtask1&lt;/p&gt;

&lt;p&gt;Swapping is done through the reconfigure(CallQueue&amp;lt;E&amp;gt; newQ) method on custom CallQueue impls.  The old call queue is given the responsibility of swapping to the new queue, which it will either accept or reject.&lt;/p&gt;

&lt;p&gt;Both old and new queues are frozen during a swap, not accepting new takes or puts.&lt;/p&gt;

&lt;p&gt;When queues have been swapped (or not in case of failure), they are unfrozen. Producers and consumers waiting on the old queue are awoken and begin drawing from the new queue.&lt;/p&gt;

&lt;p&gt;CallQueueBase is modified in order to handle waiting() while frozen and drawing from the next queue after a successful swap.&lt;/p&gt;</comment>
                            <comment id="13884828" author="hadoopqa" created="Tue, 28 Jan 2014 22:57:55 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625691/subtask2_runtime_swap_internal.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625691/subtask2_runtime_swap_internal.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3490//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3490//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625691" name="subtask2_runtime_swap_internal.patch" size="20773" author="chrilisf" created="Tue, 28 Jan 2014 22:31:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 22:57:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370512</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370504</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10301] AuthenticationFilter should return Forbidden for failed authentication</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10301</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The hadoop-auth AuthenticationFilter returns a 401 Unauthorized without a WWW-Authenticate headers.  The is illegal per the HTTP RPC and causes a NPE in the HttpUrlConnection.&lt;/p&gt;

&lt;p&gt;This is half of a fix that affects webhdfs.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4564&quot; title=&quot;Webhdfs returns incorrect http response codes for denied operations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4564&quot;&gt;HDFS-4564&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691838">HADOOP-10301</key>
            <summary>AuthenticationFilter should return Forbidden for failed authentication</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="daryn">Daryn Sharp</assignee>
                                    <reporter username="daryn">Daryn Sharp</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jan 2014 21:28:02 +0000</created>
                <updated>Fri, 31 Jan 2014 21:06:06 +0000</updated>
                                            <version>0.23.0</version>
                    <version>2.0.0-alpha</version>
                    <version>3.0.0</version>
                                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13884740" author="hadoopqa" created="Tue, 28 Jan 2014 21:51:21 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625672/HADOOP-10301.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625672/HADOOP-10301.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 2 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-auth.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3489//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3489//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3489//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3489//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888166" author="daryn" created="Fri, 31 Jan 2014 21:06:06 +0000"  >&lt;p&gt;The 0.23 patch causes problems for oozie&apos;s use of auth cookies.  Oozie caches the cookies on the local fs until they are invalid and expects fallback to spnego to occur.&lt;/p&gt;

&lt;p&gt;Currently, an uncaught AuthenticationException in a servlet sends the client an illegal 401 with no WWW-Authenticate header.  The existing behavior:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;2.x catches and ignores AuthenticationException while validating auth cookies - expired, wrong secret, wrong type, etc.  A valid 401 + negotiate header is sent to trigger spnego.  No problem here.&lt;/li&gt;
	&lt;li&gt;0.23 does &lt;b&gt;not&lt;/b&gt; catch AuthenticationException while validating auth cookies.  Servlet returns an illegal 401 with no auth header causing a client NPE.&lt;/li&gt;
	&lt;li&gt;Neither 2.x nor 0.23 catch AuthenticationExceptions if spnego fails or proxy authorization fails.  Servlet returns an illegal 401.  Client NPE.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;These patches fix all these issues by converting uncaught AuthenticationExceptions from 401 to 403 Forbidden which is entirely appropriate for #3.  However, for 0.23 (#2), the client does not revert to spnego for invalid auth cookies.  I&apos;m studying AuthenticatedURL to see how the invalid 401 ever could have worked for oozie.  There&apos;s a tangle of issues with how webhdfs vs. oozie expects this to work that I&apos;m investigating.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12635802">HDFS-4564</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625671" name="HADOOP-10301.branch-23.patch" size="6910" author="daryn" created="Tue, 28 Jan 2014 21:30:09 +0000"/>
                            <attachment id="12625672" name="HADOOP-10301.patch" size="7787" author="daryn" created="Tue, 28 Jan 2014 21:30:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 21:51:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370491</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370483</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320357</customfieldvalue>
    <customfieldvalue>12324665</customfieldvalue>
    <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10300] Allowed deferred sending of call responses</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10300</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;RPC handlers currently do not return until the RPC call completes and response is sent, or a partially sent response has been queued for the responder.  It would be useful for a proxy method to notify the handler to not yet the send the call&apos;s response.&lt;/p&gt;

&lt;p&gt;An potential use case is a namespace handler in the NN might want to return before the edit log is synced so it can service more requests and allow increased batching of edits per sync.  Background syncing could later trigger the sending of the call response to the client.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691708">HADOOP-10300</key>
            <summary>Allowed deferred sending of call responses</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12668157">HADOOP-9953</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="daryn">Daryn Sharp</assignee>
                                    <reporter username="daryn">Daryn Sharp</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jan 2014 19:29:29 +0000</created>
                <updated>Tue, 28 Jan 2014 19:57:28 +0000</updated>
                                            <version>2.0.0-alpha</version>
                    <version>3.0.0</version>
                                                    <component>ipc</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13884525" author="sureshms" created="Tue, 28 Jan 2014 19:57:28 +0000"  >&lt;p&gt;Big +1 for this feature. This will be able to reduce the number of handlers we currently need. Only thing that we need to protect is accepting too many requests and responding to it becomes a bottleneck. That can be addressed as we continue to work on this issue.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 19:57:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370459</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370456</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320357</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10298] Clean up HttpServer2</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10298</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;after &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt; HttpServer2 is an internal class that is only used by HDFS and YARN. Therefore HttpServer2 can be cleaned up, and the deprecated methods can be removed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691577">HADOOP-10298</key>
            <summary>Clean up HttpServer2</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jan 2014 07:34:00 +0000</created>
                <updated>Tue, 28 Jan 2014 07:34:00 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370328</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370331</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10297] FileChecksum should provide getChecksumOpt method</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10297</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;o.a.h.f.FileSystem has several methods which accepts directly or indirectly a ChecksumOpt parameter to configure checksum options, but there&apos;s no generic way of querying checksum options used for a given file.&lt;/p&gt;

&lt;p&gt;MD5MD5CRC32FileChecksum used by DFSClient has a getChecksumOpt() but since not just DistributedFileSystem is accepting a ChecksumOpt argument, but any FileSystem subclass (although only DistributedFileSystem implements a specific behaviour), I suggest to make getChecksumOpt an abstract method of FileChecksum. This could be used by tools like DistCp to replicate checksum options for example.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691559">HADOOP-10297</key>
            <summary>FileChecksum should provide getChecksumOpt method</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="laurentgo">Laurent Goujon</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jan 2014 05:08:10 +0000</created>
                <updated>Fri, 31 Jan 2014 00:06:10 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 00:06:10 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13883763" author="laurentgo" created="Tue, 28 Jan 2014 05:14:03 +0000"  >&lt;p&gt;Please review attached patch&lt;/p&gt;</comment>
                            <comment id="13883799" author="hadoopqa" created="Tue, 28 Jan 2014 06:02:36 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625521/hadoop-10297.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625521/hadoop-10297.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-httpfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3486//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3486//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3486//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3486//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883866" author="laurentgo" created="Tue, 28 Jan 2014 07:42:38 +0000"  >&lt;p&gt;The patch doesn&apos;t include any new tests because it doesn&apos;t change any behavior.&lt;/p&gt;

&lt;p&gt;One caveat: the patch preserves binary compatibility but breaks source compatibility for people who implements their own FileChecksum subclasses. This could be solved by providing a default version returning null instead of the abstract method.&lt;/p&gt;</comment>
                            <comment id="13883870" author="jingzhao" created="Tue, 28 Jan 2014 07:50:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;This could be solved by providing a default version returning null instead of the abstract method.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Let&apos;s do this currently instead of breaking the compatibility. +1 once this is addressed.&lt;/p&gt;</comment>
                            <comment id="13887278" author="jingzhao" created="Fri, 31 Jan 2014 00:06:10 +0000"  >&lt;p&gt;The fix has been included in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10295&quot; title=&quot;Allow distcp to automatically identify the checksum type of source files and use it for the target&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10295&quot;&gt;&lt;del&gt;HADOOP-10295&lt;/del&gt;&lt;/a&gt;. Close this jira as duplicated. Thanks for the contribution, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=laurentgo&quot; class=&quot;user-hover&quot; rel=&quot;laurentgo&quot;&gt;Laurent Goujon&lt;/a&gt;!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625521" name="hadoop-10297.patch" size="2809" author="laurentgo" created="Tue, 28 Jan 2014 05:14:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 06:02:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370310</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370313</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10296] null check for requestContentLen is wrong in SwiftRestClient#buildException()</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10296</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (requestContentLen!=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          errorText.append(&lt;span class=&quot;code-quote&quot;&gt;&quot; available &quot;&lt;/span&gt;).append(availableContentRange.getValue());
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The null check should be for availableContentRange&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691514">HADOOP-10296</key>
            <summary>null check for requestContentLen is wrong in SwiftRestClient#buildException()</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jan 2014 00:12:47 +0000</created>
                <updated>Tue, 28 Jan 2014 00:12:47 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370265</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370268</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10295] Allow distcp to automatically identify the checksum type of source files and use it for the target</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10295</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Currently while doing distcp, users can use &quot;-Ddfs.checksum.type&quot; to specify the checksum type in the target FS. This works fine if all the source files are using the same checksum type. If files in the source cluster have mixed types of checksum, users have to either use &quot;-skipcrccheck&quot; or have checksum mismatching exception. Thus we may need to consider adding a new option to distcp so that it can automatically identify the original checksum type of each source file and use the same checksum type in the target FS. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12691495">HADOOP-10295</key>
            <summary>Allow distcp to automatically identify the checksum type of source files and use it for the target</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="jingzhao">Jing Zhao</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 22:43:52 +0000</created>
                <updated>Fri, 31 Jan 2014 13:39:15 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 00:01:18 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>tools/distcp</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13883471" author="jingzhao" created="Mon, 27 Jan 2014 22:51:14 +0000"  >&lt;p&gt;Initial patch for review. The patch adds a &quot;-preservechecksumtype&quot; option to distcp. If the option is set, it simply checks the checksum type for each source file and uses it for creating the corresponding temp file in the target FS.&lt;/p&gt;

&lt;p&gt;Still need to add unit tests and do some system tests.&lt;/p&gt;</comment>
                            <comment id="13883830" author="laurentgo" created="Tue, 28 Jan 2014 06:55:42 +0000"  >&lt;p&gt;Funny, I have been preparing a patch for this very same issue for a week.&lt;/p&gt;

&lt;p&gt;Some comments regarding your patch:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;instead of a new commandline option, it may be better to extend FileAttribute enum&lt;/li&gt;
	&lt;li&gt;MD5MD5CRC32GzipFileChecksum and MD5MD5CRC32CastagnoliFileChecksum are probably HDFS specific (although being available in hadoop-common). I opened &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10297&quot; title=&quot;FileChecksum should provide getChecksumOpt method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10297&quot;&gt;&lt;del&gt;HADOOP-10297&lt;/del&gt;&lt;/a&gt; for having &lt;tt&gt;FileChecksum.getChecksumOpt()&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Instead of doing two instanceof check, it is possible to use the super class MD5MD5CRC32FileChecksum&lt;/li&gt;
	&lt;li&gt;EnumSet.of(CreateFlag.OVERWRITE) is not equivalent of setting overwrite argument to true. From DistributedFileSystem, it is EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE)&lt;/li&gt;
	&lt;li&gt;Having a test to check if the option actually works would be a nice to have (according to me)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Since I also have a patch, I&apos;ll attach it to this ticket to, and let have a hadoop maintainer help us sorting them out &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                            <comment id="13883832" author="laurentgo" created="Tue, 28 Jan 2014 06:58:34 +0000"  >&lt;p&gt;Alternative patch to implement the requested feature. It extends the current list of file attributes option with a checksum attribute.&lt;/p&gt;

&lt;p&gt;It requires two other patches to be applied first in order to compile and tests to pass:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10294&quot; title=&quot;Using backtick &amp;quot;`&amp;quot; as delimiter for parsing file path disallows &amp;quot;`&amp;quot; in file path name&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10294&quot;&gt;HADOOP-10294&lt;/a&gt; : FileChecksum should provide getChecksumOpt method&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5843&quot; title=&quot;DFSClient.getFileChecksum() throws IOException if checksum is disabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5843&quot;&gt;&lt;del&gt;HDFS-5843&lt;/del&gt;&lt;/a&gt;: DFSClient.getFileChecksum() throws IOException if checksum is disabled&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13883835" author="laurentgo" created="Tue, 28 Jan 2014 07:05:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt; It seems you are actually a hadoop commiter, so it&apos;s just great. Hope you&apos;ll find my patch helpful and you&apos;ll be able to add this feature soon!&lt;/p&gt;</comment>
                            <comment id="13883852" author="jingzhao" created="Tue, 28 Jan 2014 07:27:36 +0000"  >&lt;p&gt;Thanks for the comment &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=laurentgo&quot; class=&quot;user-hover&quot; rel=&quot;laurentgo&quot;&gt;Laurent Goujon&lt;/a&gt;!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;EnumSet.of(CreateFlag.OVERWRITE) is not equivalent of setting overwrite argument to true. From DistributedFileSystem, it is EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s right. I also found this problem in my patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;MD5MD5CRC32GzipFileChecksum and MD5MD5CRC32CastagnoliFileChecksum are probably HDFS specific&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I personally like your idea in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10297&quot; title=&quot;FileChecksum should provide getChecksumOpt method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10297&quot;&gt;&lt;del&gt;HADOOP-10297&lt;/del&gt;&lt;/a&gt;. That can simplify the logic there. However, FileChecksum is a public API marked as stable, to add a new abstract method there may cause incompatibility (e.g., other ppl may have implemented their own FileChecksum). A workaround here can be adding getChecksumOpt() to FileChecksum and let it return null.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Having a test to check if the option actually works would be a nice to have&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Totally agree. Actually I&apos;ve added a new unit test in my 001 patch, and the new unit test is very similar to yours &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;it may be better to extend FileAttribute enum&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I thought about this problem. To me checksum type may be a little bit different from other file attributes, since other file attributes are all metadata stored in NN. Thus in my first patch I just add a new option. But now I think to put the checksum type in the FileAttribute enum should be more clear.&lt;/p&gt;

&lt;p&gt;Currently I have a 001 patch which fixes the CreateFlag bug and adds a unit test. My original plan is to post it after I finish system test in my local cluster. But since you&apos;ve worked on this issue for some time and already have a decent patch, I&apos;d like to review your patch and commit it when it is ready. &lt;/p&gt;
</comment>
                            <comment id="13883865" author="laurentgo" created="Tue, 28 Jan 2014 07:40:31 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I personally like your idea in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10297&quot; title=&quot;FileChecksum should provide getChecksumOpt method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10297&quot;&gt;&lt;del&gt;HADOOP-10297&lt;/del&gt;&lt;/a&gt;. That can simplify the logic there. However, FileChecksum is a public API marked as stable, to add a new abstract method there may cause incompatibility (e.g., other ppl may have implemented their own FileChecksum). A workaround here can be adding getChecksumOpt() to FileChecksum and let it return null.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, my patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10297&quot; title=&quot;FileChecksum should provide getChecksumOpt method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10297&quot;&gt;&lt;del&gt;HADOOP-10297&lt;/del&gt;&lt;/a&gt; breaks source compatibility (but not binary compatibility). It may be okay for next Hadoop major version, but probably not for a minor version. Waiting for some guidance here (and it&apos;s really easy to change)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I thought about this problem. To me checksum type may be a little bit different from other file attributes, since other file attributes are all metadata stored in NN. Thus in my first patch I just add a new option. But now I think to put the checksum type in the FileAttribute enum should be more clear.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;From the user point of view, block size, replication and checksum option are seen as the same kind of metadata. Only from the FileSystem API, it is seen as different kind of metadata because the information is not stored in the same place.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Currently I have a 001 patch which fixes the CreateFlag bug and adds a unit test. My original plan is to post it after I finish system test in my local cluster. But since you&apos;ve worked on this issue for some time and already have a decent patch, I&apos;d like to review your patch and commit it when it is ready. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;My patch is mostly ready I think, but it is blocked by the other tickets I mentioned. Hopefully they will be reviewed quickly.&lt;/p&gt;</comment>
                            <comment id="13883889" author="jingzhao" created="Tue, 28 Jan 2014 08:22:27 +0000"  >&lt;p&gt;Besides the concern on FileChecksum, some other comments on the current patch:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;We may want to change &quot;checksum&quot; to &quot;checksumtype&quot; in the changes of PRESERVE_STATUS and FileAttribute.&lt;/li&gt;
	&lt;li&gt;We actually do not need to pass a FileChecksum to RetriableFileCopyCommand. In RetriableFileCopyCommand#doCopy, if we need to preserve the checksum type, we get the checksum type of the source file and we reuse this checksum in compareCheckSums(). In that case we only need to call sourceFS.getFileChecksum once (note that getFileChecksum is very costly).&lt;/li&gt;
	&lt;li&gt;We should use &quot;FsPermission.getFileDefault().applyUMask(FsPermission.getUMask(getConf()))&quot; in the following change (see FileSystem#create(Path, boolean, int, short, long, Progressable))
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-            tmpTargetPath, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, BUFFER_SIZE,
+            tmpTargetPath, FsPermission.getFileDefault(), 
+            EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE), BUFFER_SIZE,
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;The new added unit test does not cover there scenario where source files have different REAL checksum types (CRC32 and CRC32C), in which case copy with preserving checksum type should succeed and the original checksum types should be preserved in the target FS. We should add unit tests for this.&lt;/li&gt;
	&lt;li&gt;There are some unnecessary whilespace and blank line changes.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13884206" author="laurentgo" created="Tue, 28 Jan 2014 14:49:10 +0000"  >&lt;p&gt;For point 3, I was using &lt;tt&gt;getFileDefault()&lt;/tt&gt; because it was the previous behavior, and in &lt;tt&gt;CopyMapper.map(...)}, once copy succeed, a call is made to {{DistCpUtils.preserve(...)&lt;/tt&gt; which sets the owner, group, replication and permissions. Should it be refactored?&lt;/p&gt;</comment>
                            <comment id="13884212" author="kihwal" created="Tue, 28 Jan 2014 14:55:04 +0000"  >&lt;p&gt;Thanks for working on this, Jing.  One thing to note is that the block size needs to be identical in addition to the checksum parameters in order for the checksums to match. So it might make more sense to introduce an option to preserve the two together.&lt;/p&gt;</comment>
                            <comment id="13884301" author="sjlee0" created="Tue, 28 Jan 2014 16:30:46 +0000"  >&lt;p&gt;Agree the option needs to mean that the checksum algorithm &lt;b&gt;and&lt;/b&gt; the blocksize are preserved.&lt;/p&gt;</comment>
                            <comment id="13884953" author="jingzhao" created="Wed, 29 Jan 2014 03:12:31 +0000"  >&lt;p&gt;Thanks for the comments, Kihwal and Sangjin! So this 002 patch is based on my 001 patch and Laurent&apos;s patch, and it also preserve the block size when processing the preserving checksum type option. &lt;/p&gt;

&lt;p&gt;I&apos;ve tested in my local cluster with the patch. In my test I simply generate some files with different checksum types, and run distcp with/without &quot;-pc&quot;. The distcp succeeded when -pc is enabled.&lt;/p&gt;</comment>
                            <comment id="13884984" author="hadoopqa" created="Wed, 29 Jan 2014 04:24:27 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625778/HADOOP-10295.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625778/HADOOP-10295.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 2 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-tools/hadoop-distcp.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3498//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3498//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3498//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3498//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886718" author="szetszwo" created="Thu, 30 Jan 2014 16:15:10 +0000"  >&lt;p&gt;+1 patch looks good.&lt;/p&gt;</comment>
                            <comment id="13886894" author="sjlee0" created="Thu, 30 Jan 2014 18:42:40 +0000"  >&lt;p&gt;The patch looks good.&lt;/p&gt;

&lt;p&gt;Just one question. I see now there is an explicit call to create the permission in copyToTmpFile(). What is the nature of this change? Was the same thing being done implicitly and it is just made explicit, or is there another reason?&lt;/p&gt;</comment>
                            <comment id="13886903" author="jingzhao" created="Thu, 30 Jan 2014 18:49:30 +0000"  >&lt;p&gt;Thanks for the review, Nicholas and Sangjin!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sjlee0&quot; class=&quot;user-hover&quot; rel=&quot;sjlee0&quot;&gt;Sangjin Lee&lt;/a&gt;, that is originally implicitly contained in the FileSystem#create call (see FileSystem#create(Path, boolean, int, short, long, Progressable)). I just pulled it out to make the code not too long.&lt;/p&gt;</comment>
                            <comment id="13886975" author="jingzhao" created="Thu, 30 Jan 2014 19:42:22 +0000"  >&lt;p&gt;I will commit this patch later today if there is no more comment.&lt;/p&gt;</comment>
                            <comment id="13887270" author="jingzhao" created="Fri, 31 Jan 2014 00:01:18 +0000"  >&lt;p&gt;I&apos;ve committed this to trunk and branch-2. Thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=laurentgo&quot; class=&quot;user-hover&quot; rel=&quot;laurentgo&quot;&gt;Laurent Goujon&lt;/a&gt; for the contribution! Thanks to Kihwal, Sangjin and Nicholas for the review!&lt;/p&gt;</comment>
                            <comment id="13887280" author="hudson" created="Fri, 31 Jan 2014 00:07:36 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5077 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5077/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5077/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10295&quot; title=&quot;Allow distcp to automatically identify the checksum type of source files and use it for the target&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10295&quot;&gt;&lt;del&gt;HADOOP-10295&lt;/del&gt;&lt;/a&gt;. Allow distcp to automatically identify the checksum type of source files and use it for the target. Contributed by Jing Zhao and Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/MD5MD5CRC32FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptionSwitch.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptions.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/OptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyMapper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestOptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887651" author="hudson" created="Fri, 31 Jan 2014 11:14:08 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #467 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10295&quot; title=&quot;Allow distcp to automatically identify the checksum type of source files and use it for the target&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10295&quot;&gt;&lt;del&gt;HADOOP-10295&lt;/del&gt;&lt;/a&gt;. Allow distcp to automatically identify the checksum type of source files and use it for the target. Contributed by Jing Zhao and Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/MD5MD5CRC32FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptionSwitch.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptions.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/OptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyMapper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestOptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887735" author="hudson" created="Fri, 31 Jan 2014 13:29:54 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1684 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10295&quot; title=&quot;Allow distcp to automatically identify the checksum type of source files and use it for the target&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10295&quot;&gt;&lt;del&gt;HADOOP-10295&lt;/del&gt;&lt;/a&gt;. Allow distcp to automatically identify the checksum type of source files and use it for the target. Contributed by Jing Zhao and Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/MD5MD5CRC32FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptionSwitch.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptions.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/OptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyMapper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestOptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887749" author="hudson" created="Fri, 31 Jan 2014 13:39:15 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1659 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10295&quot; title=&quot;Allow distcp to automatically identify the checksum type of source files and use it for the target&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10295&quot;&gt;&lt;del&gt;HADOOP-10295&lt;/del&gt;&lt;/a&gt;. Allow distcp to automatically identify the checksum type of source files and use it for the target. Contributed by Jing Zhao and Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563019&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/MD5MD5CRC32FileChecksum.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptionSwitch.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCpOptions.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/OptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyMapper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/DistCpUtils.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestOptionsParser.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/mapred/TestCopyMapper.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625464" name="HADOOP-10295.000.patch" size="18323" author="jingzhao" created="Mon, 27 Jan 2014 22:51:14 +0000"/>
                            <attachment id="12625778" name="HADOOP-10295.002.patch" size="34865" author="jingzhao" created="Wed, 29 Jan 2014 03:12:31 +0000"/>
                            <attachment id="12625535" name="hadoop-10295.patch" size="18809" author="laurentgo" created="Tue, 28 Jan 2014 06:58:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 06:55:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370246</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370249</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10294] Using backtick &quot;`&quot; as delimiter for parsing file path disallows &quot;`&quot; in file path name</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10294</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;This is the second issue reported in bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10293&quot; title=&quot;Though symlink is disabled by default,  related code interprets path to be link incorrectly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10293&quot;&gt;&lt;del&gt;HADOOP-10293&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When symlink code is enabled, it uses backtick &quot;`&quot; as delimiter when interpreting a path and to tell whether it&apos;s a link or not. This disallows &quot;`&quot; to appear in file pathname that&apos;s not a link.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12691485">HADOOP-10294</key>
            <summary>Using backtick &quot;`&quot; as delimiter for parsing file path disallows &quot;`&quot; in file path name</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12672269">HADOOP-10019</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yzhangal">Yongjun Zhang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 22:25:08 +0000</created>
                <updated>Sat, 1 Feb 2014 01:22:59 +0000</updated>
                                            <version>2.3.0</version>
                                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13883502" author="andrew.wang" created="Mon, 27 Jan 2014 23:16:14 +0000"  >&lt;p&gt;Hi Yongjun,&lt;/p&gt;

&lt;p&gt;I tried a quick test with trunk and backticks via the fs shell, and things looked okay. Do you have a small test case that reproduces this error?&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;-&amp;gt; % hadoop fs -mkdir /tickdir\`
-&amp;gt; % hadoop fs -touchz /tickdir\`/myfile
-&amp;gt; % hadoop fs -put ~/testfiles/4K.temp /tickdir\`/tickfile\`
-&amp;gt; % hadoop fs -ls /
Found 1 items
drwxr-xr-x   - andrew supergroup          0 2014-01-27 15:10 /tickdir`
-&amp;gt; % hadoop fs -ls /tickdir\`
Found 2 items
-rw-r--r--   3 andrew supergroup          0 2014-01-27 15:10 /tickdir`/myfile
-rw-r--r--   3 andrew supergroup       4096 2014-01-27 15:10 /tickdir`/tickfile`
-&amp;gt; % hadoop fs -ls file:///tmp/tickfile\`
Found 1 items
-rw-r--r--   1 andrew andrew       4096 2014-01-27 15:11 file:///tmp/tickfile`
-&amp;gt; % hadoop fs -cat /tickdir\`/tickfile\` &amp;gt; /dev/null
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13883532" author="yzhangal" created="Mon, 27 Jan 2014 23:45:55 +0000"  >&lt;p&gt;Hi Andrew,&lt;/p&gt;

&lt;p&gt;When we call Stat on non-link local files that has ` in the path, the problem is demonstrated. I created a unit test for &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10293&quot; title=&quot;Though symlink is disabled by default,  related code interprets path to be link incorrectly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10293&quot;&gt;&lt;del&gt;HADOOP-10293&lt;/del&gt;&lt;/a&gt; &lt;br/&gt;
that shows the problem.  Will upload when I&apos;m ready.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

</comment>
                            <comment id="13888379" author="yzhangal" created="Sat, 1 Feb 2014 01:22:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10294&quot; title=&quot;Using backtick &amp;quot;`&amp;quot; as delimiter for parsing file path disallows &amp;quot;`&amp;quot; in file path name&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10294&quot;&gt;HADOOP-10294&lt;/a&gt; is now a subtask of &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10019&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-10019&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12691484">HADOOP-10293</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Jan 2014 23:16:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370236</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370239</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10293] Though symlink is disabled by default,  related code interprets path to be link incorrectly</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10293</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;File path ...xyz/abc`/tfile is interpreted as a link, due to the existence of backtick in the file path. &quot;abc`&quot; is a directory name here.&lt;/p&gt;

&lt;p&gt;There are two issues here, &lt;/p&gt;

&lt;p&gt;1. When symlink is disabled, the code that interprets symlink should be disabled too. This is the issue to resolve in this jira.&lt;/p&gt;

&lt;p&gt;2. When symlink is enabled, using of backtick ` as delimiter to interpret whether a path is link need to be revisited, will file a different JIRA.&lt;/p&gt;

</description>
                <environment></environment>
        <key id="12691484">HADOOP-10293</key>
            <summary>Though symlink is disabled by default,  related code interprets path to be link incorrectly</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yzhangal">Yongjun Zhang</assignee>
                                    <reporter username="yzhangal">Yongjun Zhang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 22:19:06 +0000</created>
                <updated>Sat, 1 Feb 2014 01:04:51 +0000</updated>
                            <resolved>Sat, 1 Feb 2014 01:04:38 +0000</resolved>
                                    <version>2.3.0</version>
                                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13883435" author="yzhangal" created="Mon, 27 Jan 2014 22:25:47 +0000"  >&lt;p&gt;Filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10294&quot; title=&quot;Using backtick &amp;quot;`&amp;quot; as delimiter for parsing file path disallows &amp;quot;`&amp;quot; in file path name&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10294&quot;&gt;HADOOP-10294&lt;/a&gt; for issue #2.&lt;/p&gt;</comment>
                            <comment id="13888372" author="yzhangal" created="Sat, 1 Feb 2014 01:04:38 +0000"  >&lt;p&gt;See commit log for &lt;br/&gt;
Addendum patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9652&quot; title=&quot;Allow RawLocalFs#getFileLinkStatus to fill in the link owner and mode if requested&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9652&quot;&gt;&lt;del&gt;HADOOP-9652&lt;/del&gt;&lt;/a&gt; to fix performance problems. Contributed by Andrew Wang&lt;/p&gt;</comment>
                            <comment id="13888373" author="yzhangal" created="Sat, 1 Feb 2014 01:04:51 +0000"  >&lt;p&gt;Andrew&apos;s Addendum patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9652&quot; title=&quot;Allow RawLocalFs#getFileLinkStatus to fill in the link owner and mode if requested&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9652&quot;&gt;&lt;del&gt;HADOOP-9652&lt;/del&gt;&lt;/a&gt; solved the problem, thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrew.wang&quot; class=&quot;user-hover&quot; rel=&quot;andrew.wang&quot;&gt;Andrew Wang&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12691485">HADOOP-10294</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370235</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370238</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10292] Restore HttpServer from branch-2.2 in branch-2</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10292</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;This jira is a follow-up jira of &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. It brings in the HttpServer in branch-2.2 directly into branch-2 to restore the compatibility of HBase.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691476">HADOOP-10292</key>
            <summary>Restore HttpServer from branch-2.2 in branch-2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 21:38:52 +0000</created>
                <updated>Wed, 29 Jan 2014 22:35:45 +0000</updated>
                            <resolved>Tue, 28 Jan 2014 07:57:48 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13883444" author="wheat9" created="Mon, 27 Jan 2014 22:30:43 +0000"  >&lt;p&gt;Based on the discussion in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt;, here is the proposed fix for the compatibility issues for HBase:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Fork &lt;tt&gt;HttpServer2&lt;/tt&gt; from &lt;tt&gt;HttpServer&lt;/tt&gt; in trunk. HDFS and YARN will only use &lt;tt&gt;HttpServer2&lt;/tt&gt;. Hadoop will continue to maintain &lt;tt&gt;HttpServer2&lt;/tt&gt;. &lt;tt&gt;HttpServer&lt;/tt&gt; does not exist in trunk.&lt;/li&gt;
	&lt;li&gt;Bring &lt;tt&gt;HttpServer&lt;/tt&gt; directly into branch-2 from branch-2.2. This allows HBase to work seamlessly between Hadoop 2.x and future releases that based on branch-2. The class can be tailored to make sure that HBase works with Hadoop 2.x releases. Once &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt; is resolved, the class can be removed from branch-2.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13883445" author="wheat9" created="Mon, 27 Jan 2014 22:30:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, can you please quickly verify that &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10292&quot; title=&quot;Restore HttpServer from branch-2.2 in branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10292&quot;&gt;&lt;del&gt;HADOOP-10292&lt;/del&gt;&lt;/a&gt; solve the compatibility issue for HBase? Thanks.&lt;/p&gt;</comment>
                            <comment id="13883561" author="stack" created="Tue, 28 Jan 2014 00:27:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; I am on it now.&lt;/p&gt;</comment>
                            <comment id="13883635" author="sureshms" created="Tue, 28 Jan 2014 01:54:58 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; for the help. Once you confirm that it is working, I will commit the change. &lt;/p&gt;</comment>
                            <comment id="13883646" author="stack" created="Tue, 28 Jan 2014 01:59:55 +0000"  >&lt;p&gt;Putting in place a hadoop-common jar made from the tip of branch-2.3 with these &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10292&quot; title=&quot;Restore HttpServer from branch-2.2 in branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10292&quot;&gt;&lt;del&gt;HADOOP-10292&lt;/del&gt;&lt;/a&gt; applied works for me.  I am cluster-challenged at the moment so this was standalone test only (I tried a hadoop-common jar w/o the patches and got ClassNotFound for HttpServer... as expected).  I&apos;d be +1 on commit of this and hadoop-10255 (Let me know if you want me commit them).  I will try and cluster test more this evening if I get my cluster back to see if that alters anything but do not expect it too. Thanks.&lt;/p&gt;
</comment>
                            <comment id="13883844" author="sureshms" created="Tue, 28 Jan 2014 07:13:48 +0000"  >&lt;p&gt;+1 for the patch.&lt;/p&gt;

&lt;p&gt;I am going to commit these changes soon. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, if you do any more tests or find issues, please comment on this jira. We can have a separate follow up.&lt;/p&gt;</comment>
                            <comment id="13883874" author="sureshms" created="Tue, 28 Jan 2014 07:57:48 +0000"  >&lt;p&gt;I have committed this change to branch-2. Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;. Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; for testing and review.&lt;/p&gt;

&lt;p&gt;HttpServer needs to be removed in branch-2 once HBase stops using it from Hadoop Common.&lt;/p&gt;</comment>
                            <comment id="13885925" author="andrew.wang" created="Wed, 29 Jan 2014 22:35:45 +0000"  >&lt;p&gt;FYI with the reswizzle of branch-2.3, I think this was missed. I just merged it to the new branch-2.3.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12690418">HADOOP-10255</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625456" name="HADOOP-10292.000.patch" size="42592" author="wheat9" created="Mon, 27 Jan 2014 22:24:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 00:27:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370227</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370230</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10291] TestSecurityUtil#testSocketAddrWithIP fails</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10291</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;testSocketAddrWithIP fails with Assertion Error&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Running org.apache.hadoop.security.TestSecurityUtil
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.389 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
testSocketAddrWithIP(org.apache.hadoop.security.TestSecurityUtil)  Time elapsed: 275 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;127.0.0.1:123&amp;gt; but was:&amp;lt;localhost:123&amp;gt;
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:147)
	at org.apache.hadoop.security.TestSecurityUtil.verifyTokenService(TestSecurityUtil.java:271)
	at org.apache.hadoop.security.TestSecurityUtil.verifyAddress(TestSecurityUtil.java:290)
	at org.apache.hadoop.security.TestSecurityUtil.verifyServiceAddr(TestSecurityUtil.java:306)
	at org.apache.hadoop.security.TestSecurityUtil.testSocketAddrWithIP(TestSecurityUtil.java:334)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:242)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:137)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)


Results :

Failed tests:   testSocketAddrWithIP(org.apache.hadoop.security.TestSecurityUtil): expected:&amp;lt;127.0.0.1:123&amp;gt; but was:&amp;lt;localhost:123&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691415">HADOOP-10291</key>
            <summary>TestSecurityUtil#testSocketAddrWithIP fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mitdesai">Mit Desai</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                            <label>java7</label>
                    </labels>
                <created>Mon, 27 Jan 2014 17:04:03 +0000</created>
                <updated>Wed, 29 Jan 2014 13:30:20 +0000</updated>
                            <resolved>Wed, 29 Jan 2014 04:44:35 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13882975" author="mitdesai" created="Mon, 27 Jan 2014 17:16:31 +0000"  >&lt;p&gt;The root cause is that s property used by some test cases has a side effect. The tests set (NetUtils.addStaticResolution)&lt;/p&gt;

&lt;p&gt;The broken test case assumed that it will be set when other tests are invoked. The fix is to explicitly set the property instead of depending on the execution order.&lt;/p&gt;</comment>
                            <comment id="13883012" author="hadoopqa" created="Mon, 27 Jan 2014 17:55:07 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625380/HADOOP-10291.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625380/HADOOP-10291.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3478//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3478//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3478//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3478//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13884994" author="arpitagarwal" created="Wed, 29 Jan 2014 04:44:35 +0000"  >&lt;p&gt;+1 for the patch. Committed to trunk, branch-2 and branch-2.3.&lt;/p&gt;

&lt;p&gt;Thanks for the contribution &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mitdesai&quot; class=&quot;user-hover&quot; rel=&quot;mitdesai&quot;&gt;Mit Desai&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13884995" author="hudson" created="Wed, 29 Jan 2014 04:46:36 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5056 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5056/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5056/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10291&quot; title=&quot;TestSecurityUtil#testSocketAddrWithIP fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10291&quot;&gt;&lt;del&gt;HADOOP-10291&lt;/del&gt;&lt;/a&gt;. TestSecurityUtil#testSocketAddrWithIP fails due to test order dependency. (Contributed by Mit Desai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestSecurityUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885237" author="hudson" created="Wed, 29 Jan 2014 11:13:45 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #465 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/465/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/465/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10291&quot; title=&quot;TestSecurityUtil#testSocketAddrWithIP fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10291&quot;&gt;&lt;del&gt;HADOOP-10291&lt;/del&gt;&lt;/a&gt;. TestSecurityUtil#testSocketAddrWithIP fails due to test order dependency. (Contributed by Mit Desai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestSecurityUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885328" author="hudson" created="Wed, 29 Jan 2014 13:29:37 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1682 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1682/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1682/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10291&quot; title=&quot;TestSecurityUtil#testSocketAddrWithIP fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10291&quot;&gt;&lt;del&gt;HADOOP-10291&lt;/del&gt;&lt;/a&gt;. TestSecurityUtil#testSocketAddrWithIP fails due to test order dependency. (Contributed by Mit Desai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestSecurityUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885333" author="hudson" created="Wed, 29 Jan 2014 13:30:20 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1657 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1657/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1657/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10291&quot; title=&quot;TestSecurityUtil#testSocketAddrWithIP fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10291&quot;&gt;&lt;del&gt;HADOOP-10291&lt;/del&gt;&lt;/a&gt;. TestSecurityUtil#testSocketAddrWithIP fails due to test order dependency. (Contributed by Mit Desai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562353&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestSecurityUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625380" name="HADOOP-10291.patch" size="768" author="mitdesai" created="Mon, 27 Jan 2014 17:16:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Jan 2014 17:55:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370166</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370169</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10290] Surefire steals focus on MacOS</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10290</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;When running tests on MacOS X, surefire plugin keeps stealing focus from current application.&lt;/p&gt;

&lt;p&gt;This can be avoided by adding &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;-Djava.awt.headless=true&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to the surefire commandline&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691243">HADOOP-10290</key>
            <summary>Surefire steals focus on MacOS</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="laurentgo">Laurent Goujon</reporter>
                        <labels>
                    </labels>
                <created>Sun, 26 Jan 2014 03:18:41 +0000</created>
                <updated>Mon, 27 Jan 2014 17:58:14 +0000</updated>
                                                            <fixVersion>3.0.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13882161" author="laurentgo" created="Sun, 26 Jan 2014 03:30:34 +0000"  >&lt;p&gt;Please reviewed attached patch&lt;/p&gt;</comment>
                            <comment id="13882194" author="hadoopqa" created="Sun, 26 Jan 2014 06:14:47 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625238/hadoop-10290.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625238/hadoop-10290.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3475//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3475//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3475//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3475//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13882712" author="stevel@apache.org" created="Mon, 27 Jan 2014 09:47:26 +0000"  >&lt;p&gt;Which version of Java are you running? &lt;/p&gt;</comment>
                            <comment id="13882713" author="stevel@apache.org" created="Mon, 27 Jan 2014 09:49:58 +0000"  >&lt;p&gt;w.r.t the patch, it should be done via a new &lt;tt&gt;&amp;lt;systemPropertyVariables&amp;gt;&lt;/tt&gt; rather than the command line, which is for non sysprop settings&lt;/p&gt;</comment>
                            <comment id="13882858" author="laurentgo" created="Mon, 27 Jan 2014 14:59:12 +0000"  >&lt;p&gt;Using Java 6 (1.6.0_65-b14-462)&lt;/p&gt;

&lt;p&gt;Using &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;systemPropertyVariables&amp;gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;, property was not visible on the surefire commandline, so I was afraid it wouldn&apos;t work, but running the tests again, it does indeed! I will upload a new patch (much simpler)&lt;/p&gt;</comment>
                            <comment id="13882861" author="laurentgo" created="Mon, 27 Jan 2014 15:01:18 +0000"  >&lt;p&gt;New version of the patch using &lt;tt&gt;&amp;lt;systemVariableProperties&amp;gt;&lt;/tt&gt;. Only set in &lt;tt&gt;hadoop-project/pom.xml&lt;/tt&gt; since it is the common parent of all other maven modules.&lt;/p&gt;

&lt;p&gt;Thanks for reviewing&lt;/p&gt;</comment>
                            <comment id="13882863" author="tucu00" created="Mon, 27 Jan 2014 15:04:59 +0000"  >&lt;p&gt;Alternatively, you can have the following env VARD defined in your shell: &lt;tt&gt;_JAVA_OPTIONS=-Djava.awt.headless=true&lt;/tt&gt;. This solves the problem. The only issue is if you are starting any app, Java based from the shell, you&apos;ll have to &lt;tt&gt;export -n _JAVA_OPTIONS&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;This started happening a while ago in JDK6, AFAIK it isa JDK bug.&lt;/p&gt;</comment>
                            <comment id="13882876" author="hadoopqa" created="Mon, 27 Jan 2014 15:18:29 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625365/hadoop-10290.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625365/hadoop-10290.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3477//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3477//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3477//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3477//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883019" author="stevel@apache.org" created="Mon, 27 Jan 2014 17:58:14 +0000"  >&lt;p&gt;FWIW, switching to Java 7 will make this go away for good (and on java apps started in YARN containers)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625365" name="hadoop-10290.patch" size="614" author="laurentgo" created="Mon, 27 Jan 2014 15:01:18 +0000"/>
                            <attachment id="12625238" name="hadoop-10290.patch" size="2829" author="laurentgo" created="Sun, 26 Jan 2014 03:30:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 26 Jan 2014 06:14:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369994</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369997</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10289] o.a.h.u.ReflectionUtils.printThreadInfo() causes deadlock in TestHttpServer</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10289</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;This bug is a followup on &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9964&quot; title=&quot;O.A.H.U.ReflectionUtils.printThreadInfo() is not thread-safe which cause TestHttpServer pending 10 minutes or longer.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9964&quot;&gt;&lt;del&gt;HADOOP-9964&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ReflectionUtils.printThreadInfo is now a synchronized method. This change creates sometimes deadlock situation in TestHttpServer if one servlet thread calling this method is waiting on client to consume output.&lt;/p&gt;

&lt;p&gt;In TestHttpServer, several tests connect to the http server only to check the status code but without reading the full inputstream. Depending on HttpURLConnection, the deadlock scenario may be triggered or not.&lt;/p&gt;

&lt;p&gt;Note that in the original ticket, it is not explained why synchronized fixed the issue. According to the attached stacktrace, test was blocked on HttpServer.stop(), waiting on worker threads to stop, which didn&apos;t happen because those threads were waiting for their output to be consumed, so the original issue looks very similar to what I&apos;m experiencing.&lt;/p&gt;

&lt;p&gt;My proposed fix is to remove synchronized (as it seems to make the issue worse) but configure HttpServer.stop() to forcibly kill threads after a configurable period of time&lt;/p&gt;</description>
                <environment>&lt;p&gt;MacOS X 10.9/Java 6 1.6.0_65-b14-462&lt;/p&gt;</environment>
        <key id="12691227">HADOOP-10289</key>
            <summary>o.a.h.u.ReflectionUtils.printThreadInfo() causes deadlock in TestHttpServer</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="laurentgo">Laurent Goujon</reporter>
                        <labels>
                    </labels>
                <created>Sat, 25 Jan 2014 20:05:04 +0000</created>
                <updated>Tue, 28 Jan 2014 23:37:11 +0000</updated>
                                            <version>3.0.0</version>
                    <version>2.3.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>util</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13882052" author="laurentgo" created="Sat, 25 Jan 2014 21:15:30 +0000"  >&lt;p&gt;Patch for trunk. Please review&lt;/p&gt;</comment>
                            <comment id="13882141" author="hadoopqa" created="Sun, 26 Jan 2014 02:04:03 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625220/hadoop-10289.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625220/hadoop-10289.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3473//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3473//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3473//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3473//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12668727">HADOOP-9964</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625211" name="TestHttpServer.jstack" size="92879" author="laurentgo" created="Sat, 25 Jan 2014 20:15:51 +0000"/>
                            <attachment id="12625220" name="hadoop-10289.patch" size="4102" author="laurentgo" created="Sat, 25 Jan 2014 21:15:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 26 Jan 2014 02:04:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369976</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369979</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10288] Explicit reference to Log4JLogger breaks non-log4j users</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10288</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;In HttpRequestLog, we make an explicit reference to the Log4JLogger class for an instanceof check. If the log4j implementation isn&apos;t actually on the classpath, the instanceof check throws NoClassDefFoundError instead of returning false. This means that dependent projects that don&apos;t use log4j can no longer embed HttpServer &amp;#8211; typically this is an issue when they use MiniDFSCluster as part of their testing.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691225">HADOOP-10288</key>
            <summary>Explicit reference to Log4JLogger breaks non-log4j users</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tlipcon">Todd Lipcon</assignee>
                                    <reporter username="tlipcon">Todd Lipcon</reporter>
                        <labels>
                    </labels>
                <created>Sat, 25 Jan 2014 19:51:52 +0000</created>
                <updated>Wed, 29 Jan 2014 22:42:24 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 22:15:11 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>util</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13882017" author="tlipcon" created="Sat, 25 Jan 2014 19:53:50 +0000"  >&lt;p&gt;Here&apos;s a candidate patch. It&apos;s not possible to unit test this beyond the existing unit tests which cover this path. I&apos;m awaiting confirmation from the downstream consumer that had the build issue that this fixes their issue.&lt;/p&gt;</comment>
                            <comment id="13882038" author="hadoopqa" created="Sat, 25 Jan 2014 20:37:11 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625206/hadoop-10288.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625206/hadoop-10288.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3472//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3472//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3472//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3472//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13882908" author="atm" created="Mon, 27 Jan 2014 15:56:11 +0000"  >&lt;p&gt;+1, the patch looks good to me, assuming that manual testing confirms that the fix works.&lt;/p&gt;</comment>
                            <comment id="13883424" author="tlipcon" created="Mon, 27 Jan 2014 22:12:47 +0000"  >&lt;p&gt;I got word from the affected project that this patch fixed their test build. I&apos;ll commit it momentarily.&lt;/p&gt;</comment>
                            <comment id="13883468" author="hudson" created="Mon, 27 Jan 2014 22:49:14 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5048 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5048/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5048/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10288&quot; title=&quot;Explicit reference to Log4JLogger breaks non-log4j users&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10288&quot;&gt;&lt;del&gt;HADOOP-10288&lt;/del&gt;&lt;/a&gt;. Explicit reference to Log4JLogger breaks non-log4j users. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpRequestLog.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884021" author="hudson" created="Tue, 28 Jan 2014 11:09:06 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10288&quot; title=&quot;Explicit reference to Log4JLogger breaks non-log4j users&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10288&quot;&gt;&lt;del&gt;HADOOP-10288&lt;/del&gt;&lt;/a&gt;. Explicit reference to Log4JLogger breaks non-log4j users. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpRequestLog.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884127" author="hudson" created="Tue, 28 Jan 2014 13:29:58 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10288&quot; title=&quot;Explicit reference to Log4JLogger breaks non-log4j users&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10288&quot;&gt;&lt;del&gt;HADOOP-10288&lt;/del&gt;&lt;/a&gt;. Explicit reference to Log4JLogger breaks non-log4j users. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpRequestLog.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884144" author="hudson" created="Tue, 28 Jan 2014 13:40:19 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10288&quot; title=&quot;Explicit reference to Log4JLogger breaks non-log4j users&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10288&quot;&gt;&lt;del&gt;HADOOP-10288&lt;/del&gt;&lt;/a&gt;. Explicit reference to Log4JLogger breaks non-log4j users. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561882&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpRequestLog.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885934" author="andrew.wang" created="Wed, 29 Jan 2014 22:42:24 +0000"  >&lt;p&gt;I merged this to the post-reswizzle branch-2.3 as well since it was missing.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625206" name="hadoop-10288.txt" size="1420" author="tlipcon" created="Sat, 25 Jan 2014 19:53:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 25 Jan 2014 20:37:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369974</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369977</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10287] FSOutputSummer should support any checksum size</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10287</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9114&quot; title=&quot;After defined the dfs.checksum.type as the NULL, write file and hflush will through java.lang.ArrayIndexOutOfBoundsException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9114&quot;&gt;&lt;del&gt;HADOOP-9114&lt;/del&gt;&lt;/a&gt; only fixes if checksum size is 0, but doesn&apos;t handle the generic case.&lt;/p&gt;

&lt;p&gt;FSOutputSummer should work with any checksum size (between 0 and 8 since Checksum.getValue() returns a long)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691189">HADOOP-10287</key>
            <summary>FSOutputSummer should support any checksum size</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="laurentgo">Laurent Goujon</reporter>
                        <labels>
                    </labels>
                <created>Sat, 25 Jan 2014 06:36:15 +0000</created>
                <updated>Sun, 26 Jan 2014 05:39:49 +0000</updated>
                                            <version>3.0.0</version>
                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13882157" author="laurentgo" created="Sun, 26 Jan 2014 03:02:04 +0000"  >&lt;p&gt;Please review attached patch&lt;/p&gt;</comment>
                            <comment id="13882188" author="hadoopqa" created="Sun, 26 Jan 2014 05:39:49 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625237/hadoop-10287.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625237/hadoop-10287.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3474//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3474//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3474//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3474//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625237" name="hadoop-10287.patch" size="5916" author="laurentgo" created="Sun, 26 Jan 2014 03:02:04 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 26 Jan 2014 05:39:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369938</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369941</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10286] Allow RPCCallBenchmark to benchmark calls by different users</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10286</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12691159">HADOOP-10286</key>
            <summary>Allow RPCCallBenchmark to benchmark calls by different users</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:25:59 +0000</created>
                <updated>Fri, 24 Jan 2014 23:25:59 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369908</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369911</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10285] Allow CallQueue impls to be swapped at runtime (part 2: admin interface) Depends on: subtask2</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10285</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;We wish to swap the active call queue during runtime in order to do performance tuning without restarting the namenode.&lt;br/&gt;
This patch adds the ability to refresh the call queue on the namenode, through dfsadmin -refreshCallQueue&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12691158">HADOOP-10285</key>
            <summary>Allow CallQueue impls to be swapped at runtime (part 2: admin interface) Depends on: subtask2</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:23:16 +0000</created>
                <updated>Tue, 28 Jan 2014 23:14:11 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13884833" author="chrilisf" created="Tue, 28 Jan 2014 23:02:53 +0000"  >&lt;p&gt;Users can swap the queue by running&lt;/p&gt;

&lt;p&gt;hadoop dfsadmin -refreshCallQueue&lt;/p&gt;

&lt;p&gt;The code touches a lot of places, but is effectively a mirror of what refreshServiceAcl does to accomplish the same thing.&lt;/p&gt;</comment>
                            <comment id="13884884" author="hadoopqa" created="Tue, 28 Jan 2014 23:14:11 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625700/subtask3_admin_interface.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625700/subtask3_admin_interface.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3491//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3491//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625700" name="subtask3_admin_interface.patch" size="32907" author="chrilisf" created="Tue, 28 Jan 2014 23:02:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 23:14:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369907</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369910</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10284] Add metrics to the HistoryRpcScheduler</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10284</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12691157">HADOOP-10284</key>
            <summary>Add metrics to the HistoryRpcScheduler</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:22:41 +0000</created>
                <updated>Fri, 24 Jan 2014 23:22:41 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369906</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369909</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10283] Add metrics to the FairCallQueue</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10283</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12691156">HADOOP-10283</key>
            <summary>Add metrics to the FairCallQueue</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:22:28 +0000</created>
                <updated>Fri, 24 Jan 2014 23:22:28 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369905</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369908</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10282] Create a FairCallQueue: a multi-level call queue which schedules incoming calls and multiplexes outgoing calls</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10282</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12691155">HADOOP-10282</key>
            <summary>Create a FairCallQueue: a multi-level call queue which schedules incoming calls and multiplexes outgoing calls</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:21:14 +0000</created>
                <updated>Fri, 24 Jan 2014 23:21:14 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369904</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369907</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10281] Create a scheduler, which assigns schedulables a priority level</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10281</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12691154">HADOOP-10281</key>
            <summary>Create a scheduler, which assigns schedulables a priority level</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:20:13 +0000</created>
                <updated>Sat, 25 Jan 2014 00:13:04 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13881551" author="chrilisf" created="Sat, 25 Jan 2014 00:13:04 +0000"  >&lt;p&gt;The scheduler assigns schedulables a priority level based the past history of requests.&lt;/p&gt;

&lt;p&gt;It can be configured as follows:&lt;/p&gt;

&lt;p&gt;ipc.8020.history-scheduler.history-length = 1000 &lt;/p&gt;

&lt;p&gt;The number of past requests to remember and compare&lt;/p&gt;

&lt;p&gt;ipc.8020.history-scheduler.thresholds = 33, 66&lt;/p&gt;

&lt;p&gt;Dependent on the history-length and the number of priority levels: defines the thresholds that separate each priority level. In this example, we have 3 priority levels and a history length of 100, so we assign thusly:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Queue 2 if count &amp;gt; 66&lt;/li&gt;
	&lt;li&gt;Queue 1 if count &amp;gt; 33&lt;/li&gt;
	&lt;li&gt;Queue 0 otherwise&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625155" name="subtask4_scheduler.patch" size="24449" author="chrilisf" created="Sat, 25 Jan 2014 00:13:04 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369903</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369906</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10280] Make Schedulables return a configurable identity of user or group</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10280</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12691153">HADOOP-10280</key>
            <summary>Make Schedulables return a configurable identity of user or group</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:19:40 +0000</created>
                <updated>Fri, 24 Jan 2014 23:48:28 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13881542" author="chrilisf" created="Fri, 24 Jan 2014 23:48:28 +0000"  >&lt;p&gt;Allow Schedulables to be queried for identity, which can be configured as follows:&lt;/p&gt;

&lt;p&gt;ipc.8020.call.identity&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625153" name="subtask3_schedulable_identities.patch" size="3994" author="chrilisf" created="Fri, 24 Jan 2014 23:48:28 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369902</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369905</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10279] Create multiplexer, a requirement for the fair queue</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10279</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12691151">HADOOP-10279</key>
            <summary>Create multiplexer, a requirement for the fair queue</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 23:18:03 +0000</created>
                <updated>Sat, 25 Jan 2014 05:50:09 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13881533" author="chrilisf" created="Fri, 24 Jan 2014 23:31:27 +0000"  >&lt;p&gt;Depends on subtask1: This multiplexer enables takers of the FairCallQueue to withdraw in a weighted round-robin fashion to combat starvation of low-priority Schedulables.&lt;/p&gt;

&lt;p&gt;Weights are configurable as follows:&lt;br/&gt;
ipc.8020.wrr-multiplexer.weights = 30, 20, 5&lt;/p&gt;

&lt;p&gt;Means queue0 will be drawn from thirty times, queue1 twenty times, queue2 five times, and repeat.&lt;/p&gt;</comment>
                            <comment id="13881688" author="hadoopqa" created="Sat, 25 Jan 2014 05:50:09 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625146/subtask2_add_mux.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625146/subtask2_add_mux.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3466//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3466//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625146" name="subtask2_add_mux.patch" size="11597" author="chrilisf" created="Fri, 24 Jan 2014 23:31:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 25 Jan 2014 05:50:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369900</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369903</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10278] Refactor to make CallQueue pluggable</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10278</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;ul&gt;
	&lt;li&gt;Refactor CallQueue into an interface, base, and default implementation that matches today&apos;s behavior&lt;/li&gt;
	&lt;li&gt;Make the call queue impl configurable, keyed on port so that we minimize coupling&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12691135">HADOOP-10278</key>
            <summary>Refactor to make CallQueue pluggable</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12652288">HADOOP-9640</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chrilisf">Chris Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 22:09:02 +0000</created>
                <updated>Sun, 2 Feb 2014 00:22:55 +0000</updated>
                                                                            <component>ipc</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13881510" author="chrilisf" created="Fri, 24 Jan 2014 22:51:03 +0000"  >&lt;p&gt;This version has the unit tests&lt;/p&gt;</comment>
                            <comment id="13881513" author="chrilisf" created="Fri, 24 Jan 2014 22:54:05 +0000"  >&lt;p&gt;This version has the unit tests and doesn&apos;t accidentally delete a different file.&lt;/p&gt;</comment>
                            <comment id="13881537" author="chrilisf" created="Fri, 24 Jan 2014 23:35:52 +0000"  >&lt;p&gt;This version doesn&apos;t include an irrelevant test&lt;/p&gt;</comment>
                            <comment id="13881612" author="chrilisf" created="Sat, 25 Jan 2014 02:23:33 +0000"  >&lt;p&gt;As per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=daryn&quot; class=&quot;user-hover&quot; rel=&quot;daryn&quot;&gt;Daryn Sharp&lt;/a&gt;&apos;s suggestions, this patch retains the original interface of the callQueue in Server.&lt;/p&gt;

&lt;p&gt;This patch allows the Server to use a custom implementation of BlockingQueue if the user defines ipc.8020.callqueue.impl&lt;/p&gt;

&lt;p&gt;It includes one such implementation, the FIFOCallQueue, which simply imitates the LinkedBlockingQueue (and uses the same 2-lock algorithm used in the JDK&apos;s implementation). Though it seems redundant, the FIFOCallQueue will have greater flexibility in that it can be swapped out at runtime (coming in a later patch).&lt;/p&gt;</comment>
                            <comment id="13881772" author="hadoopqa" created="Sat, 25 Jan 2014 09:14:58 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625168/subtask1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625168/subtask1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;      &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 1559 javac compiler warnings (more than the trunk&apos;s current 1546 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3469//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3469//testReport/&lt;/a&gt;&lt;br/&gt;
Javac warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3469//artifact/trunk/patchprocess/diffJavacWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3469//artifact/trunk/patchprocess/diffJavacWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3469//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3469//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883519" author="chrilisf" created="Mon, 27 Jan 2014 23:34:25 +0000"  >&lt;p&gt;Update tests to fix javac warnings&lt;/p&gt;</comment>
                            <comment id="13883545" author="hadoopqa" created="Tue, 28 Jan 2014 00:10:21 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625474/subtask1.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625474/subtask1.2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;      &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 1555 javac compiler warnings (more than the trunk&apos;s current 1546 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3482//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3482//testReport/&lt;/a&gt;&lt;br/&gt;
Javac warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3482//artifact/trunk/patchprocess/diffJavacWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3482//artifact/trunk/patchprocess/diffJavacWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3482//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3482//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883623" author="hadoopqa" created="Tue, 28 Jan 2014 01:34:57 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625491/subtask1.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625491/subtask1.3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3484//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3484//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3484//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3484//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13884494" author="chrilisf" created="Tue, 28 Jan 2014 19:40:18 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=daryn&quot; class=&quot;user-hover&quot; rel=&quot;daryn&quot;&gt;Daryn Sharp&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Could you take a look please?&lt;/p&gt;

&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Chris&lt;/p&gt;</comment>
                            <comment id="13884698" author="daryn" created="Tue, 28 Jan 2014 21:18:12 +0000"  >&lt;p&gt;Upon quick glance it looks much cleaner.  Questions:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;What advantage will the custom fifo call queue offer over a standard java queue?&lt;/li&gt;
	&lt;li&gt;Instead of the new base class providing a concrete queue implementation (locking and all), is it possible for the custom queues to using a containing relationship with a standard java queue?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13884720" author="chrilisf" created="Tue, 28 Jan 2014 21:31:47 +0000"  >&lt;p&gt;Thanks for checking it out.&lt;/p&gt;

&lt;p&gt;1. In a later patch I&apos;ll be introducing the ability to swap the call queue at runtime, which is essential for performance tuning without restarting the namenode. The FIFOCallQueue responds to methods needed to accomplish this transparently to the server.&lt;/p&gt;

&lt;p&gt;2. I would have preferred this myself (and earlier versions did this), but we will need control of the locks to do runtime queue swapping. In any case, the FairCallQueue (which should be coming in subtask5) will use this same locking code, so refactoring it into the base makes things cleaner.&lt;/p&gt;

&lt;p&gt;I will start uploading the other subtask patches&lt;/p&gt;</comment>
                            <comment id="13884803" author="chrilisf" created="Tue, 28 Jan 2014 22:41:21 +0000"  >&lt;p&gt;I&apos;ve uploaded a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10302&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-10302&lt;/a&gt; which should make some of the design decisions in this patch more clear.&lt;/p&gt;</comment>
                            <comment id="13888293" author="benoyantony" created="Fri, 31 Jan 2014 23:17:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chrili&quot; class=&quot;user-hover&quot; rel=&quot;chrili&quot;&gt;Chris Li&lt;/a&gt; All the methods in &lt;em&gt;CallQueue&lt;/em&gt; are already in &lt;em&gt;BlockingQueue&lt;/em&gt;. Do we really need to define a new interface -&lt;em&gt;CallQueue&lt;/em&gt;  ?&lt;/p&gt;</comment>
                            <comment id="13888305" author="chrilisf" created="Fri, 31 Jan 2014 23:31:22 +0000"  >&lt;p&gt;I&apos;ve done so for flexibility&#8211;the later patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10302&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-10302&lt;/a&gt; adds methods to CallQueue necessary for swapping a queue at runtime.&lt;/p&gt;

&lt;p&gt;It&apos;s also convenient to be able to check if a call queue is a custom call queue vs a LinkedBlockingQueue, without requiring the callqueue to extend BaseCallQueue&lt;/p&gt;</comment>
                            <comment id="13888352" author="benoyantony" created="Sat, 1 Feb 2014 00:25:26 +0000"  >&lt;p&gt;If it is a marker interface for now, then can we remove the redudant methods from CallQueue ?&lt;/p&gt;</comment>
                            <comment id="13888374" author="chrilisf" created="Sat, 1 Feb 2014 01:07:38 +0000"  >&lt;p&gt;Sounds good, I&apos;ll update the patch&lt;/p&gt;</comment>
                            <comment id="13888382" author="chrilisf" created="Sat, 1 Feb 2014 01:29:00 +0000"  >&lt;p&gt;Removed redundant methods on CallQueue&lt;/p&gt;</comment>
                            <comment id="13888390" author="hadoopqa" created="Sat, 1 Feb 2014 02:06:10 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626436/subtask1.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626436/subtask1.4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3516//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3516//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3516//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3516//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888764" author="benoyantony" created="Sat, 1 Feb 2014 22:24:02 +0000"  >&lt;p&gt;Could you please generate the patch with  --no-prefix  ?&lt;br/&gt;
There are a few additional white spaces in the patch.&lt;/p&gt;</comment>
                            <comment id="13888782" author="chrilisf" created="Sun, 2 Feb 2014 00:15:29 +0000"  >&lt;p&gt;Patch generated with &lt;/p&gt;

&lt;p&gt;git format-patch trunk --stdout --no-prefix --ignore-space-change &amp;gt; subtask1.5.patch&lt;/p&gt;</comment>
                            <comment id="13888785" author="hadoopqa" created="Sun, 2 Feb 2014 00:22:55 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626501/subtask1.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626501/subtask1.5.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3522//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3522//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625491" name="subtask1.3.patch" size="22221" author="chrilisf" created="Tue, 28 Jan 2014 00:58:33 +0000"/>
                            <attachment id="12626436" name="subtask1.4.patch" size="21618" author="chrilisf" created="Sat, 1 Feb 2014 01:29:00 +0000"/>
                            <attachment id="12626501" name="subtask1.5.patch" size="21568" author="chrilisf" created="Sun, 2 Feb 2014 00:15:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 25 Jan 2014 09:14:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369884</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369887</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>callqueue</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10277] setfacl -x fails to parse ACL spec if trying to remove the mask entry.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10277</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;You should be able to use setfacl -x to remove the mask entry (if also removing all other extended ACL entries).  Right now, this causes a failure to parse the ACL spec due to a bug in &lt;tt&gt;AclEntry#parseAclSpec&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691127">HADOOP-10277</key>
            <summary>setfacl -x fails to parse ACL spec if trying to remove the mask entry.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vinayrpet">Vinay</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 21:41:46 +0000</created>
                <updated>Mon, 27 Jan 2014 18:06:24 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 18:06:24 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13881462" author="cnauroth" created="Fri, 24 Jan 2014 21:57:37 +0000"  >&lt;p&gt;Thank you to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sachinjose2007%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;sachinjose2007@gmail.com&quot;&gt;Sachin Jose&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=renil.joseph&quot; class=&quot;user-hover&quot; rel=&quot;renil.joseph&quot;&gt;Renil J&lt;/a&gt; for reporting this bug.&lt;/p&gt;</comment>
                            <comment id="13882181" author="vinayrpet" created="Sun, 26 Jan 2014 05:10:41 +0000"  >&lt;p&gt;Hi Chris,&lt;br/&gt;
I got the issue. &lt;br/&gt;
Issue was &lt;tt&gt;String.split()&lt;/tt&gt; will not add empty trailing strings to parsed array. &lt;br/&gt;
This can be fixed.&lt;/p&gt;

&lt;p&gt;But my doubt is, whether removing the mask is allowed ?&lt;/p&gt;

&lt;p&gt;My setfacl throws error when I try to remove mask entry in my suse linux box&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;vinay@host-10-18-40-99:~&amp;gt; setfacl -x mask:: testAcl/
setfacl: testAcl/: Malformed access ACL `user::rwx,user:vinay:r--,group::r-x,group:users:r-x,other::r-x&apos;: Missing or wrong entry at entry 5
vinay@host-10-18-40-99:~&amp;gt; setfacl -x mask testAcl/
setfacl: testAcl/: Malformed access ACL `user::rwx,user:vinay:r--,group::r-x,group:users:r-x,other::r-x&apos;: Missing or wrong entry at entry 5&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Please validate whether this is correct behaviour or whether we need to support removal of mask entries&lt;/p&gt;</comment>
                            <comment id="13882358" author="cnauroth" created="Sun, 26 Jan 2014 17:16:24 +0000"  >&lt;p&gt;Thanks for volunteering to take this, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vinayrpet&quot; class=&quot;user-hover&quot; rel=&quot;vinayrpet&quot;&gt;Vinay&lt;/a&gt;.  I did have a patch in progress, so I&apos;ll just attach the work I&apos;ve done so far and ask you if you want to do anything more with this.&lt;/p&gt;

&lt;p&gt;As part of this patch, I also wanted to refactor &lt;tt&gt;AclEntry#parseAclSpec&lt;/tt&gt; so that the logic of parsing a single entry is in a separate public static method: &lt;tt&gt;AclEntry#parseAclEntry&lt;/tt&gt;.  That&apos;s going to be helpful for the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5608&quot; title=&quot;WebHDFS: implement ACL APIs.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5608&quot;&gt;&lt;del&gt;HDFS-5608&lt;/del&gt;&lt;/a&gt; WebHDFS patch.  I didn&apos;t get the refactoring done yet in this version of the patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;But my doubt is, whether removing the mask is allowed ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually, you are correct.  I was incorrect when I said earlier that you can remove the mask to trigger automatic recalculation.  It is invalid to attempt to remove the mask from an ACL that needs it, however, the error should get reported from the server side instead of a failure to parse the ACL spec.  We already have the code to do this in the NameNode in &lt;tt&gt;AclTransformation#buildAndValidateAcl&lt;/tt&gt;.  The parsing still needs to be able to parse a mask entry with no permission, because it is valid to remove the mask entry if you&apos;re also removing all other extended ACL entries (reducing it from an extended ACL back to a minimal ACL).  See below for an example on Linux.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[cnauroth@ubuntu:pts/0] acltest                                                                                     
&amp;gt; getfacl file1
# file: file1
# owner: cnauroth
# group: cnauroth
user::rw-
user:bruce:rwx			#effective:r--
group::rw-			#effective:r--
mask::r--
other::r--

[cnauroth@ubuntu:pts/0] acltest                                                                                     
&amp;gt; setfacl -x mask:: file1
setfacl: file1: Malformed access ACL `user::rw-,user:bruce:rwx,group::rw-,other::r--&apos;: Missing or wrong entry at entry 4

[cnauroth@ubuntu:pts/0] acltest                                                                                     
&amp;gt; setfacl -x mask::,user:bruce: file1

[cnauroth@ubuntu:pts/0] acltest                                                                                     
&amp;gt; getfacl file1
# file: file1
# owner: cnauroth
# group: cnauroth
user::rw-
group::rw-
other::r--
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13882560" author="vinayrpet" created="Mon, 27 Jan 2014 04:23:33 +0000"  >&lt;p&gt;Thanks Chris for clearing the doubt. I will post a patch soon for refactoring as well as the fix.&lt;/p&gt;</comment>
                            <comment id="13882585" author="vinayrpet" created="Mon, 27 Jan 2014 05:33:06 +0000"  >&lt;p&gt;Hi Chris, Attaching the refractored patch. &lt;br/&gt;
Its almost same as your initial work. &lt;br/&gt;
Please review.&lt;/p&gt;</comment>
                            <comment id="13883031" author="cnauroth" created="Mon, 27 Jan 2014 18:06:24 +0000"  >&lt;p&gt;+1.  I committed this to the feature branch.  Vinay, thank you for the patch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12682466">HADOOP-10187</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12686476">HADOOP-10184</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625278" name="HADOOP-10277.1.patch" size="4815" author="cnauroth" created="Sun, 26 Jan 2014 17:16:24 +0000"/>
                            <attachment id="12625323" name="HADOOP-10277.patch" size="8139" author="vinayrpet" created="Mon, 27 Jan 2014 05:33:06 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 26 Jan 2014 05:10:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369876</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369879</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325672</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10276] RawLocalFs#getFileLinkStatus does not fill in the link owner and mode by default</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10276</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&lt;tt&gt;RawLocalFs#getFileLinkStatus&lt;/tt&gt; does not actually get the owner and mode of the symlink, but instead uses the owner and mode of the symlink target.  If the target can&apos;t be found, it fills in bogus values (the empty string and FsPermission.getDefault) for these.&lt;/p&gt;

&lt;p&gt;Symlinks have an owner distinct from the owner of the target they point to, and getFileLinkStatus ought to expose this.&lt;/p&gt;

&lt;p&gt;In some operating systems, symlinks can have a permission other than 0777.  We ought to expose this in RawLocalFilesystem and other places, although we don&apos;t necessarily have to support this behavior in HDFS.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691048">HADOOP-10276</key>
            <summary>RawLocalFs#getFileLinkStatus does not fill in the link owner and mode by default</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cmccabe">Colin Patrick McCabe</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 14:54:18 +0000</created>
                <updated>Fri, 24 Jan 2014 14:59:23 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>18</watches>
                                                                <comments>
                            <comment id="13881020" author="jlowe" created="Fri, 24 Jan 2014 14:57:15 +0000"  >&lt;p&gt;Cloned from &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9652&quot; title=&quot;Allow RawLocalFs#getFileLinkStatus to fill in the link owner and mode if requested&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9652&quot;&gt;&lt;del&gt;HADOOP-9652&lt;/del&gt;&lt;/a&gt;, as that JIRA lays the groundwork but does not completely fix the originally reported issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10020">
                    <name>Cloners</name>
                                            <outwardlinks description="is cloned as">
                                        <issuelink>
            <issuekey id="12653594">HADOOP-9652</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jan 2014 14:57:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369797</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369800</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10275] Serialization should remove its type parameter</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10275</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;org.apache.hadoop.io.serializer.Serialization is defined as:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; Serialization&amp;lt;T&amp;gt; {
...
Serializer&amp;lt;T&amp;gt; getSerializer(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;T&amp;gt; c);
Deserializer&amp;lt;T&amp;gt; getDeserializer(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;T&amp;gt; c);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but the type parameter &amp;lt;T&amp;gt; is semantically invalid, and type mismatchings in the code are suppressed by explicit cast and annotations.&lt;/p&gt;

&lt;p&gt;This interface should be defined as follows:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; Serialization {
...
&amp;lt;T&amp;gt; Serializer&amp;lt;T&amp;gt; getSerializer(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;T&amp;gt; c);
&amp;lt;T&amp;gt; Deserializer&amp;lt;T&amp;gt; getDeserializer(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;T&amp;gt; c);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12690988">HADOOP-10275</key>
            <summary>Serialization should remove its type parameter</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ikeda">Hiroshi Ikeda</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 08:53:56 +0000</created>
                <updated>Fri, 24 Jan 2014 08:58:29 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13880836" author="ikeda" created="Fri, 24 Jan 2014 08:58:29 +0000"  >&lt;p&gt;Added a patch for 2.2.0&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625016" name="HADOOP-10275.patch" size="36375" author="ikeda" created="Fri, 24 Jan 2014 08:58:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369737</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369738</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10274] Lower the logging level from ERROR to WARN for UGI.doAs method</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10274</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Recently we got the error msg &quot;Request is a replay (34) - PROCESS_TGS&quot; while we are using the HBase client API to put data into HBase-0.94.16 with krb5-1.6.1 enabled. The related msg as follows...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2014-01-15 09:40:38,452][hbase-tablepool-1-thread-3][ERROR][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1124)): PriviledgedActionException as:takeshi_miao@LAB cause:javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Request is a replay (34) - PROCESS_TGS)]
[2014-01-15 09:40:38,453][hbase-tablepool-1-thread-3][DEBUG][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation.logPriviledgedAction(UserGroupInformation.java:1143)): PriviledgedAction as:takeshi_miao@LAB from:sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                                          
[2014-01-15 09:40:38,453][hbase-tablepool-1-thread-3][DEBUG][org.apache.hadoop.ipc.SecureClient](org.apache.hadoop.hbase.ipc.SecureClient$SecureConnection$1.run(SecureClient.java:213)): Exception encountered &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Request is a replay (34) - PROCESS_TGS)]
[2014-01-15 09:40:38,454][hbase-tablepool-1-thread-3][INFO ][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation.reloginFromTicketCache(UserGroupInformation.java:657)): Initiating logout &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; takeshi_miao@LAB
[2014-01-15 09:40:38,454][hbase-tablepool-1-thread-3][DEBUG][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.logout(UserGroupInformation.java:154)): hadoop logout
[2014-01-15 09:40:38,454][hbase-tablepool-1-thread-3][INFO ][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation.reloginFromTicketCache(UserGroupInformation.java:667)): Initiating re-login &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; takeshi_miao@LAB
[2014-01-15 09:40:38,455][hbase-tablepool-1-thread-3][DEBUG][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.login(UserGroupInformation.java:146)): hadoop login
[2014-01-15 09:40:38,456][hbase-tablepool-1-thread-3][DEBUG][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:95)): hadoop login commit
[2014-01-15 09:40:38,456][hbase-tablepool-1-thread-3][DEBUG][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:100)): using existing subject:[takeshi_miao@LAB, UnixPrincipal: takeshi_miao, UnixNumericUserPrincipal: 501, UnixNumericGroupPrincipal [Primary Group]: 501, UnixNumericGroupPrincipal [Supplementary Group]: 502, takeshi_miao@LAB]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, we found that the HBase would doing the retry (5 * 10 times) and recovery this &lt;em&gt;&apos;request is a replay (34)&apos;&lt;/em&gt; issue, but based on the HBase user viewpoint, the error msg at first line may be frightful, as we were afraid there was any data loss occurring at the first sight...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2014-01-15 09:40:38,452][hbase-tablepool-1-thread-3][ERROR][org.apache.hadoop.security.UserGroupInformation](org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1124)): PriviledgedActionException as:takeshi_miao@LAB cause:javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Request is a replay (34) - PROCESS_TGS)]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So I&apos;d like to suggest to change the logging level from &apos;&lt;em&gt;ERROR&lt;/em&gt;&apos; to &apos;&lt;em&gt;WARN&lt;/em&gt;&apos; for &lt;em&gt;o.a.hadoop.security.UserGroupInformation#doAs(PrivilegedExceptionAction&amp;lt;T&amp;gt;)&lt;/em&gt; method&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &amp;lt;T&amp;gt; T doAs(PrivilegedExceptionAction&amp;lt;T&amp;gt; action
                    ) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException, InterruptedException {
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      &lt;span class=&quot;code-comment&quot;&gt;// ...
&lt;/span&gt;    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (PrivilegedActionException pae) {
      Throwable cause = pae.getCause();
      LOG.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;PriviledgedActionException as:&quot;&lt;/span&gt;+&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;+&lt;span class=&quot;code-quote&quot;&gt;&quot; cause:&quot;&lt;/span&gt;+cause); &lt;span class=&quot;code-comment&quot;&gt;// I mean here
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// ...
&lt;/span&gt;    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Due to this method already throws _checked exception_s which can be handled by the client code, so the error may not really be an error if client  code can handle it...such as this case.&lt;/p&gt;

&lt;p&gt;For more details pls refer to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10379&quot; title=&quot;Lower the msg &amp;quot;Request is a replay (34) - PROCESS_TGS&amp;quot; from logging level ERROR to WARN&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10379&quot;&gt;HBASE-10379&lt;/a&gt;&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop-1.0.4, hbase-0.94.16, krb5-server-1.6.1-31.el5_3.3, CentOS release 5.3 (Final)&lt;/p&gt;</environment>
        <key id="12690959">HADOOP-10274</key>
            <summary>Lower the logging level from ERROR to WARN for UGI.doAs method</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="takeshi.miao">takeshi.miao</assignee>
                                    <reporter username="takeshi.miao">takeshi.miao</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 02:54:32 +0000</created>
                <updated>Wed, 29 Jan 2014 03:00:24 +0000</updated>
                            <resolved>Tue, 28 Jan 2014 05:03:21 +0000</resolved>
                                    <version>1.0.4</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13880689" author="takeshi.miao" created="Fri, 24 Jan 2014 03:06:57 +0000"  >&lt;p&gt;add a patch for review&lt;/p&gt;</comment>
                            <comment id="13882074" author="stack" created="Sat, 25 Jan 2014 21:55:54 +0000"  >&lt;p&gt;+1 from me.  Will commit in next day or so.&lt;/p&gt;</comment>
                            <comment id="13883127" author="wheat9" created="Mon, 27 Jan 2014 19:08:04 +0000"  >&lt;p&gt;This should be the same issue reported in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10015&quot; title=&quot;UserGroupInformation prints out excessive ERROR warnings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10015&quot;&gt;HADOOP-10015&lt;/a&gt;. Since the other one has more progress, I&apos;m closing this one as a duplicate.&lt;/p&gt;</comment>
                            <comment id="13883132" author="wheat9" created="Mon, 27 Jan 2014 19:10:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, when you commit the patch, can you please close this jira and &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10015&quot; title=&quot;UserGroupInformation prints out excessive ERROR warnings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10015&quot;&gt;HADOOP-10015&lt;/a&gt; and mark one of them as duplicate? Thanks.&lt;/p&gt;</comment>
                            <comment id="13883753" author="stack" created="Tue, 28 Jan 2014 05:03:21 +0000"  >&lt;p&gt;Committed to trunk, branch-2, and branch-2.3.   Thanks for the patch Takeshi Miao.&lt;/p&gt;


&lt;p&gt;(I am not administrator in these parts so can&apos;t add takeshi.miao as a contributor to assign him his issue.)&lt;/p&gt;</comment>
                            <comment id="13883769" author="hudson" created="Tue, 28 Jan 2014 05:16:23 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5049 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5049/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5049/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10274&quot; title=&quot;Lower the logging level from ERROR to WARN for UGI.doAs method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10274&quot;&gt;&lt;del&gt;HADOOP-10274&lt;/del&gt;&lt;/a&gt; Lower the logging level from ERROR to WARN for UGI.doAs method (Takeshi Miao via stack) (stack: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884014" author="hudson" created="Tue, 28 Jan 2014 11:09:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10274&quot; title=&quot;Lower the logging level from ERROR to WARN for UGI.doAs method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10274&quot;&gt;&lt;del&gt;HADOOP-10274&lt;/del&gt;&lt;/a&gt; Lower the logging level from ERROR to WARN for UGI.doAs method (Takeshi Miao via stack) (stack: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884034" author="umamaheswararao" created="Tue, 28 Jan 2014 11:23:57 +0000"  >&lt;p&gt;I have added Takeshi Miao to contributors list and assigned this JIRA to him.&lt;/p&gt;</comment>
                            <comment id="13884120" author="hudson" created="Tue, 28 Jan 2014 13:29:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10274&quot; title=&quot;Lower the logging level from ERROR to WARN for UGI.doAs method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10274&quot;&gt;&lt;del&gt;HADOOP-10274&lt;/del&gt;&lt;/a&gt; Lower the logging level from ERROR to WARN for UGI.doAs method (Takeshi Miao via stack) (stack: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884137" author="hudson" created="Tue, 28 Jan 2014 13:40:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10274&quot; title=&quot;Lower the logging level from ERROR to WARN for UGI.doAs method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10274&quot;&gt;&lt;del&gt;HADOOP-10274&lt;/del&gt;&lt;/a&gt; Lower the logging level from ERROR to WARN for UGI.doAs method (Takeshi Miao via stack) (stack: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561934&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884745" author="stack" created="Tue, 28 Jan 2014 21:56:43 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=umamaheswararao&quot; class=&quot;user-hover&quot; rel=&quot;umamaheswararao&quot;&gt;Uma Maheswara Rao G&lt;/a&gt; for the bit of admin interjection.&lt;/p&gt;</comment>
                            <comment id="13884945" author="takeshi.miao" created="Wed, 29 Jan 2014 03:00:24 +0000"  >&lt;p&gt;stack &amp;amp; Uma Maheswara Rao G&lt;br/&gt;
Thanks for you guys review &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12672191">HADOOP-10015</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12689746">HBASE-10379</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624987" name="HADOOP-10274-trunk-v01.patch" size="925" author="takeshi.miao" created="Fri, 24 Jan 2014 03:06:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 25 Jan 2014 21:55:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369705</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369706</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10273] Fix &apos;mvn site&apos;</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10273</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&apos;mvn site&apos; fails with&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.0:site (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-site) on project hadoop-main: Execution &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-site of goal org.apache.maven.plugins:maven-site-plugin:3.0:site failed: A required class was missing &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; executing org.apache.maven.plugins:maven-site-plugin:3.0:site: org/sonatype/aether/graph/DependencyFilter

[ERROR] [Help 1] http:&lt;span class=&quot;code-comment&quot;&gt;//cwiki.apache.org/confluence/display/MAVEN/AetherClassNotFound&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Looks related to &lt;a href=&quot;https://cwiki.apache.org/confluence/display/MAVEN/AetherClassNotFound&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/MAVEN/AetherClassNotFound&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bumping the maven-site-plugin version should fix it.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Maven 3.1.x&lt;/p&gt;</environment>
        <key id="12690956">HADOOP-10273</key>
            <summary>Fix &apos;mvn site&apos;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="arpitagarwal">Arpit Agarwal</assignee>
                                    <reporter username="arpitagarwal">Arpit Agarwal</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 02:20:44 +0000</created>
                <updated>Fri, 24 Jan 2014 08:25:51 +0000</updated>
                                            <version>3.0.0</version>
                    <version>2.2.0</version>
                                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13880649" author="arpitagarwal" created="Fri, 24 Jan 2014 02:27:31 +0000"  >&lt;p&gt;Verified that the change fixes the above build break.&lt;/p&gt;</comment>
                            <comment id="13880808" author="ajisakaa" created="Fri, 24 Jan 2014 08:23:43 +0000"  >&lt;p&gt;I reproduced this issue with Maven 3.1.1.&lt;br/&gt;
+1, I verified the patch fixes the build break both on trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13880809" author="ajisakaa" created="Fri, 24 Jan 2014 08:24:52 +0000"  >&lt;p&gt;Starting Jenkins.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624980" name="HADOOP-10273.patch" size="853" author="arpitagarwal" created="Fri, 24 Jan 2014 02:27:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jan 2014 08:23:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369702</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369703</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10272] Hadoop 2 &quot;-copyFromLocal&quot; fail when source is a folder and there are spaces in the path</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10272</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Repro steps:&lt;br/&gt;
with folder structure like: /ab/c d/ef.txt&lt;br/&gt;
hadoop command (hadoop fs -copyFromLocal /ab/ /) or (hadoop fs -copyFromLocal &quot;/ab/c d/&quot; /) fail with error:&lt;br/&gt;
copyFromLocal: File &lt;a href=&quot;file:/ab/c%20d/ef.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/ab/c%20d/ef.txt&lt;/a&gt; does not exist&lt;/p&gt;

&lt;p&gt;However command (hadoop fs -copyFromLocal &quot;/ab/c d/ef.txt&quot; /) success.&lt;/p&gt;

&lt;p&gt;Seems like hadoop treat file and directory differently when &quot;copyFromLocal&quot;.&lt;br/&gt;
This only happens in Hadoop 2 and causing 2 Hive unit test failures (external_table_with_space_in_location_path.q and load_hdfs_file_with_space_in_the_name.q).&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690948">HADOOP-10272</key>
            <summary>Hadoop 2 &quot;-copyFromLocal&quot; fail when source is a folder and there are spaces in the path</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="chuanliu">Chuan Liu</assignee>
                                    <reporter username="shuainie">Shuaishuai Nie</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 01:19:37 +0000</created>
                <updated>Tue, 28 Jan 2014 19:02:01 +0000</updated>
                            <resolved>Tue, 28 Jan 2014 19:02:01 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>2.2.0</version>
                                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13881351" author="chuanliu" created="Fri, 24 Jan 2014 19:34:42 +0000"  >&lt;p&gt;I can take a look at the root cause.&lt;/p&gt;</comment>
                            <comment id="13884405" author="chuanliu" created="Tue, 28 Jan 2014 18:41:33 +0000"  >&lt;p&gt;The root cause is that &lt;tt&gt;PathData.getStringForChildPath()&lt;/tt&gt; will return a path string that is encoded, i.e. &apos; &apos; will be encoded as &apos;%20&apos;. This path string will later be used again in the Path constructor to pass to URI constructor, and lead to double encoding. The wrongly encoded path will later lead to a copy failure, because the wrongly encoded path is on longer the original user input path. I suspect Unix/Linux also has this problem unless the Java URI implementation is different on Unix/Linux platform. Attaching a patch that address the issue. &lt;/p&gt;</comment>
                            <comment id="13884422" author="hadoopqa" created="Tue, 28 Jan 2014 18:53:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625621/HADOOP-10272.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625621/HADOOP-10272.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3488//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3488//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13884436" author="chuanliu" created="Tue, 28 Jan 2014 19:02:01 +0000"  >&lt;p&gt;OK. I just found out this is a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4329&quot; title=&quot;DFSShell issues with directories with spaces in name&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4329&quot;&gt;&lt;del&gt;HDFS-4329&lt;/del&gt;&lt;/a&gt; when trying to rebase my patch to trunk. Resolving as duplicated.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12624877">HDFS-4329</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625621" name="HADOOP-10272.patch" size="2048" author="chuanliu" created="Tue, 28 Jan 2014 18:41:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jan 2014 19:34:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369694</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369695</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10270] getfacl does not display effective permissions of masked entries.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10270</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The mask entry of an ACL can be changed to restrict permissions that would be otherwise granted via named user and group entries.  In these cases, the typical implementation of getfacl also displays the effective permissions after applying the mask.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690850">HADOOP-10270</key>
            <summary>getfacl does not display effective permissions of masked entries.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 19:07:21 +0000</created>
                <updated>Fri, 31 Jan 2014 18:59:59 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 18:59:59 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13880247" author="cnauroth" created="Thu, 23 Jan 2014 19:18:28 +0000"  >&lt;p&gt;See below for example output from getfacl on Linux.  The logic for this would be:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Find the mask entry within the scope, either access or &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.
Go back and iterate through all entries.
If entry is named user, named group, or unnamed group
  Calculate effective permissions by applying the mask from the same scope using {{FsAction#and}}.
  If effective permissions are different from actual permissions
    Also display effective permissions.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The effective permissions are not displayed if the mask doesn&apos;t turn any permissions off.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;gt; getfacl dir1
# file: dir1
# owner: cnauroth
# group: cnauroth
user::rw-
user:bruce:rwx                  #effective:r--
user:diana:r--
group::rw-                      #effective:r--
mask::r--
other::r--
user::rw-
&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;:user:bruce:rwx          #effective:r--
&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;:user:diana:r--
&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;:group::rw-              #effective:r--
&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;:mask::r--
&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;:other::r--
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13886944" author="cnauroth" created="Thu, 30 Jan 2014 19:19:49 +0000"  >&lt;p&gt;I&apos;m attaching a patch to display effective permissions from getfacl as needed.  While I was in here, I also fixed a bug that caused getfacl to print the group entry with &quot;mask&quot; as the label when the file has only a default ACL (no access ACL).  I&apos;ve also added 2 new tests to testAclCli.xml to cover both of those fixes.&lt;/p&gt;</comment>
                            <comment id="13888004" author="arpitagarwal" created="Fri, 31 Jan 2014 18:52:18 +0000"  >&lt;p&gt;+1 for the patch.&lt;/p&gt;</comment>
                            <comment id="13888017" author="cnauroth" created="Fri, 31 Jan 2014 18:59:59 +0000"  >&lt;p&gt;Thanks for another code review, Arpit.  I committed this to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; feature branch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12686476">HADOOP-10184</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626152" name="HADOOP-10270.1.patch" size="8686" author="cnauroth" created="Thu, 30 Jan 2014 19:19:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 18:52:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369595</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369598</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325672</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10269] SaslException is completely ignored</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10269</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;In &quot;org/apache/hadoop/security/SaslOutputStream.java&quot;, there is the following code pattern:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;172    try {
173      if (saslServer != null) { // using saslServer
174        saslToken = saslServer.wrap(inBuf, off, len);
175      } else { // using saslClient
176        saslToken = saslClient.wrap(inBuf, off, len);
177      }
178    } catch (SaslException se) {
179      try {
180       disposeSasl();
181      } catch (SaslException ignored) {
182      }
183      throw se;
184    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On line 181, the exception thrown by disposeSasl(), which can be from SaslServer.dispose() or SaslClient.dispose(), is ignored completely without even logging it. Maybe at least log it?&lt;/p&gt;

&lt;p&gt;Ding&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690751">HADOOP-10269</key>
            <summary>SaslException is completely ignored</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="d.yuan">Ding Yuan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 11:37:34 +0000</created>
                <updated>Thu, 23 Jan 2014 17:05:22 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13880042" author="daryn" created="Thu, 23 Jan 2014 16:29:49 +0000"  >&lt;p&gt;If the sasl wrapping fails then it really doesn&apos;t matter if disposing of the sasl object fails.  Disposing shouldn&apos;t fail because it&apos;s clearing internal state but even if it does it&apos;s likely related to the wrap failure.  The original/rethrown exception from the wrap failure is what really matters.&lt;/p&gt;

&lt;p&gt;If that makes sense, I think this jira should be marked invalid.&lt;/p&gt;</comment>
                            <comment id="13880083" author="d.yuan" created="Thu, 23 Jan 2014 17:05:22 +0000"  >&lt;p&gt;Thanks for the response. It makes sense. I don&apos;t want to sound like a pest but in this case this &quot;ignored&quot; is a different exception from se, and since the code completely ignores it, later no one will ever know that there were another exception &quot;ignored&quot; thrown by the dispose. Although &apos;dispose&apos; shouldn&apos;t fail in most cases, the purpose of an error handler is exactly to prepare for those extremely rare cases where some failure modes are not anticipated. So in this case maybe it&apos;s worthwhile to at least log this &quot;ignored&quot; exception?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Jan 2014 16:29:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369495</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369498</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10268] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10268</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;


&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690550">HADOOP-10268</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:14:36 +0000</created>
                <updated>Thu, 23 Jan 2014 03:14:36 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369407</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369408</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10267] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10267</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690549">HADOOP-10267</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:13:25 +0000</created>
                <updated>Thu, 23 Jan 2014 03:13:25 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369408</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369409</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10266] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10266</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690547">HADOOP-10266</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:13:08 +0000</created>
                <updated>Thu, 23 Jan 2014 03:13:08 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369409</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369410</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10265] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10265</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690546">HADOOP-10265</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:12:50 +0000</created>
                <updated>Thu, 23 Jan 2014 03:12:50 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369410</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369411</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10264] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10264</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690545">HADOOP-10264</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:12:46 +0000</created>
                <updated>Thu, 23 Jan 2014 03:12:46 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369411</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369412</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10263] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10263</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690544">HADOOP-10263</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:12:40 +0000</created>
                <updated>Thu, 23 Jan 2014 03:12:40 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369412</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369413</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10262] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10262</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690543">HADOOP-10262</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:12:32 +0000</created>
                <updated>Thu, 23 Jan 2014 03:12:32 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369413</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369414</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10261] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10261</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>
&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690542">HADOOP-10261</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:12:22 +0000</created>
                <updated>Thu, 23 Jan 2014 03:12:22 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369414</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369415</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10260] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10260</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>
&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690540">HADOOP-10260</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:12:02 +0000</created>
                <updated>Thu, 23 Jan 2014 03:12:02 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369415</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369416</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10259] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10259</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>
&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690539">HADOOP-10259</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:10:58 +0000</created>
                <updated>Thu, 23 Jan 2014 03:10:58 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369416</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369417</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10258] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10258</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>
&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690538">HADOOP-10258</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:10:24 +0000</created>
                <updated>Thu, 23 Jan 2014 03:10:24 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369417</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369418</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10257] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10257</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>
&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690537">HADOOP-10257</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:10:01 +0000</created>
                <updated>Thu, 23 Jan 2014 03:10:01 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369418</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369419</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10256] hadoop2.2 building error</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10256</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>
&lt;p&gt;while running: &lt;br/&gt;
mvn clean install -DskipTests&lt;/p&gt;

&lt;p&gt;i got these errors&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure: Compilation failure:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;32,48&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;33,48&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,4&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;55,33&amp;#93;&lt;/span&gt; OutputFormat is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,4&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/XmlEditsVisitor.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;59,35&amp;#93;&lt;/span&gt; XMLSerializer is internal proprietary API and may be removed in a future release&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; /var/software/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java:&lt;span class=&quot;error&quot;&gt;&amp;#91;93,0&amp;#93;&lt;/span&gt; error: error while writing FsDatasetImpl: No space left on device&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;i google for a long time, and have no idea how to resole it. can someone help me? thank you very much&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop2.2&lt;br/&gt;
centos6.3 x64&lt;br/&gt;
jdk-7u51-linux-x64&lt;br/&gt;
protobuf-2.5.0&lt;br/&gt;
apache-maven-3.1.1&lt;/p&gt;</environment>
        <key id="12690536">HADOOP-10256</key>
            <summary>hadoop2.2 building error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="davidhhuan">david lee</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:09:28 +0000</created>
                <updated>Thu, 23 Jan 2014 03:09:28 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369419</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369420</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10255] Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10255</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;As suggested in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10253&quot; title=&quot;Remove deprecated methods in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10253&quot;&gt;&lt;del&gt;HADOOP-10253&lt;/del&gt;&lt;/a&gt;, HBase needs a temporary copy of &lt;tt&gt;HttpServer&lt;/tt&gt; from branch-2.2 to make sure it works across multiple 2.x releases.&lt;/p&gt;

&lt;p&gt;This patch renames the current &lt;tt&gt;HttpServer&lt;/tt&gt; into &lt;tt&gt;HttpServer2&lt;/tt&gt;, and bring  the &lt;tt&gt;HttpServer&lt;/tt&gt; in branch-2.2 into the repository.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690418">HADOOP-10255</key>
            <summary>Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jan 2014 22:31:02 +0000</created>
                <updated>Wed, 29 Jan 2014 22:35:31 +0000</updated>
                            <resolved>Tue, 28 Jan 2014 07:52:43 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                <comments>
                            <comment id="13879321" author="hadoopqa" created="Wed, 22 Jan 2014 22:59:19 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624454/HADOOP-10255.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624454/HADOOP-10255.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 17 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;&lt;/font&gt;-1 javac&lt;font color=&quot;red&quot;&gt;&lt;/font&gt;.  The patch appears to cause the build to fail.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3464//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3464//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13879331" author="hadoopqa" created="Wed, 22 Jan 2014 23:16:41 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624454/HADOOP-10255.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624454/HADOOP-10255.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 17 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;&lt;/font&gt;-1 javac&lt;font color=&quot;red&quot;&gt;&lt;/font&gt;.  The patch appears to cause the build to fail.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3465//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3465//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13880023" author="stack" created="Thu, 23 Jan 2014 16:14:57 +0000"  >&lt;p&gt;A few minor comments.  (Is failure because patch build is against trunk and not branch2, the target for this patch?)&lt;/p&gt;

&lt;p&gt;nit: Should you leave the -  @Deprecated in place?&lt;/p&gt;

&lt;p&gt;nit: Do you want to explain in class comment why there is a class named HttpServer2: i.e. &apos;this class exists because hbasers were whining when their httpserver was taken away&quot;?  Folks may wonder expecially in h3 when HttpServer is gone.  Do you want to add &apos;yarn&apos; to the list of LimitedPrivate or is mapreduce suficient proxy for yarn?&lt;/p&gt;

&lt;p&gt;Else looks good on quick review.  +1  Above could be addressed on commit.  Thanks for doing this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13880025" author="stack" created="Thu, 23 Jan 2014 16:15:49 +0000"  >&lt;p&gt;I marked this a blocker on 2.4 since without it downstreamers will be incompatible w/ 2.4.  Please recalibrate it if I have it wrong.&lt;/p&gt;</comment>
                            <comment id="13880201" author="stack" created="Thu, 23 Jan 2014 18:40:47 +0000"  >&lt;p&gt;Patch does not apply to branch-2.  Any chance of fixing it &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13880333" author="wheat9" created="Thu, 23 Jan 2014 20:49:25 +0000"  >&lt;p&gt;Rebased the v2 patch on the current trunk.&lt;/p&gt;</comment>
                            <comment id="13880339" author="wheat9" created="Thu, 23 Jan 2014 20:51:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;nit: Should you leave the - @Deprecated in place?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;tt&gt;HttpServer2&lt;/tt&gt; is used by HDFS / YARN only. It is safe to remove all the deprecated methods.&lt;/p&gt;

&lt;p&gt;I would prefer to landing this patch on trunk before porting it to branch-2.&lt;/p&gt;</comment>
                            <comment id="13880344" author="wheat9" created="Thu, 23 Jan 2014 20:55:20 +0000"  >&lt;p&gt;The v3 patch is for trunk only. It does not include the HttpServer in branch-2.2.&lt;/p&gt;

&lt;p&gt;The patch for branch-2 should include the class from branch-2.2.&lt;/p&gt;</comment>
                            <comment id="13880728" author="stack" created="Fri, 24 Jan 2014 05:20:50 +0000"  >&lt;p&gt;+1 pending what hadoopqa says.&lt;/p&gt;

&lt;p&gt;I can test a branch-2 patch when you put it up.&lt;/p&gt;</comment>
                            <comment id="13881445" author="stack" created="Fri, 24 Jan 2014 21:32:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; Any luck w/ a branch-2 patch?  Any ETA?  Would be good all around getting this 2.4 blocker behind us.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13881449" author="wheat9" created="Fri, 24 Jan 2014 21:42:58 +0000"  >&lt;p&gt;Still waiting for Jenkins to come up.&lt;/p&gt;

&lt;p&gt;My plan is to apply this patch to branch-2, then directly pull in the HttpServer in branch-2.2 into branch-2. How does it sound?&lt;/p&gt;</comment>
                            <comment id="13881490" author="stack" created="Fri, 24 Jan 2014 22:25:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; Sounds great.  Thank you.&lt;/p&gt;</comment>
                            <comment id="13881847" author="hadoopqa" created="Sat, 25 Jan 2014 12:43:49 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624908/HADOOP-10255.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624908/HADOOP-10255.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 18 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3470//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3470//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3470//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3470//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883038" author="stack" created="Mon, 27 Jan 2014 18:13:44 +0000"  >&lt;p&gt;Now 2.3.0 will be taken from the tip of the branch, this becomes a 2.3.0 blocker.  Without this fix, downstream projects, HBase in particular, that work fine on 2.2.x cannot start on a 2.3.0.&lt;/p&gt;</comment>
                            <comment id="13883241" author="tucu00" created="Mon, 27 Jan 2014 20:28:28 +0000"  >&lt;p&gt;Are we going to end up having 2 copies of HttpServer in 2.2 now? If so, I don&apos;t think it is a good idea from a maintenance perspective. Can we get back the old one (the one that works with Hbase) and retrofitted to support the required stuff by Hadoop? The new one as not been shipped as part of a release, so we could easily revert that, right?&lt;/p&gt;</comment>
                            <comment id="13883326" author="sureshms" created="Mon, 27 Jan 2014 21:22:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;Are we going to end up having 2 copies of HttpServer in 2.2 now? If so, I don&apos;t think it is a good idea from a maintenance perspective.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As agreed upon in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10253&quot; title=&quot;Remove deprecated methods in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10253&quot;&gt;&lt;del&gt;HADOOP-10253&lt;/del&gt;&lt;/a&gt;, we will maintain two copies of HttpServer. One deprecated and retained for backward compatibility reasons. The other cleaned up version to be used only with in Hadoop. Undoing the cleanup is a lot of work and a step in the backward direction.&lt;/p&gt;</comment>
                            <comment id="13883353" author="tucu00" created="Mon, 27 Jan 2014 21:32:35 +0000"  >&lt;p&gt;Is there the intention of keeping, fixes-wise, both versions in sync until the old one is gone? If so, how do we facilitate that?&lt;/p&gt;</comment>
                            <comment id="13883356" author="stack" created="Mon, 27 Jan 2014 21:34:44 +0000"  >&lt;p&gt;Two copies is ugly but agree it is probably easiest way of undoing the breakage.  The restored old httpserver(1) can have deprecated sprayed all over it.  Our &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; tried restoring old behaviors atop the refactored httpserver and ran into issues around https; having one-server only might not be too straight-forward.&lt;/p&gt;</comment>
                            <comment id="13883367" author="wheat9" created="Mon, 27 Jan 2014 21:40:15 +0000"  >&lt;p&gt;Splitting the task of bringing in HttpServer in branch-2.2 into &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10292&quot; title=&quot;Restore HttpServer from branch-2.2 in branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10292&quot;&gt;&lt;del&gt;HADOOP-10292&lt;/del&gt;&lt;/a&gt;. This jira and &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10292&quot; title=&quot;Restore HttpServer from branch-2.2 in branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10292&quot;&gt;&lt;del&gt;HADOOP-10292&lt;/del&gt;&lt;/a&gt; will be committed together.&lt;/p&gt;</comment>
                            <comment id="13883406" author="hadoopqa" created="Mon, 27 Jan 2014 22:05:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624908/HADOOP-10255.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624908/HADOOP-10255.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 18 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestLargeBlock&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3479//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3479//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3479//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3479//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883410" author="wheat9" created="Mon, 27 Jan 2014 22:06:12 +0000"  >&lt;p&gt;The branch2 version of this patch. The original HttpServer in branch-2.2 will be introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10292&quot; title=&quot;Restore HttpServer from branch-2.2 in branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10292&quot;&gt;&lt;del&gt;HADOOP-10292&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13883425" author="jxiang" created="Mon, 27 Jan 2014 22:14:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, the https issue we met was some configuration issue related to the new HttpServer, just FYI.&lt;/p&gt;</comment>
                            <comment id="13883430" author="wheat9" created="Mon, 27 Jan 2014 22:17:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt;, can you please elaborate on this? The new &lt;tt&gt;HttpServer&lt;/tt&gt; uses &lt;tt&gt;HttpPolicy&lt;/tt&gt; to control whether to start a SSL server. The code is supposed to be backward-compatible. It seems to be a bug if it can&apos;t work with the old configuration.&lt;/p&gt;</comment>
                            <comment id="13883467" author="jxiang" created="Mon, 27 Jan 2014 22:48:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;, we found we need to add the following to mapred-site.xml in order for resourcemanagers and nodemanagers to start in a secure cluster:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    mapreduce.jobhistory.webapp.spnego-principal
    mapreduce.jobhistory.webapp.spnego-keytab-file
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="13883475" author="wheat9" created="Mon, 27 Jan 2014 22:52:57 +0000"  >&lt;p&gt;This should be fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-1600&quot; title=&quot;RM does not startup when security is enabled without spnego configured&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-1600&quot;&gt;&lt;del&gt;YARN-1600&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13883516" author="hadoopqa" created="Mon, 27 Jan 2014 23:31:14 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625452/HADOOP-10255-branch2.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625452/HADOOP-10255-branch2.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3481//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3481//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883638" author="stack" created="Tue, 28 Jan 2014 01:56:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tucu00&quot; class=&quot;user-hover&quot; rel=&quot;tucu00&quot;&gt;Alejandro Abdelnur&lt;/a&gt; To answer your question, httpserver will now have deprecated all over it and LimitedPrivate(&apos;HBASE&apos;) only, rather than (&apos;HDFS, &apos;MAPREDUCE&apos;, &apos;HBASE&apos;).  It also has this note in class comment:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+ * This class comes from the HttpServer in branch-2.2. HDFS and YARN have
+ * moved to use HttpServer2. This class exists &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; compatibility reasons, it
+ * stays in hadoop-common to allow HBase working with both Hadoop 2.2
+ * and Hadoop 2.3. See HBASE-10336 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more details.
+ */
+@InterfaceAudience.LimitedPrivate({&lt;span class=&quot;code-quote&quot;&gt;&quot;HBase&quot;&lt;/span&gt;})
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; If fixes, other than critical security holes, only make it to httpserver2 and not to httpserver, I think it ok.  The httpserver instance that hbase is using can be let rot.  Meantime over on our end we are undoing our dependency on this hadoop class.  So, yeah, two instances is less than ideal but ok if the old one is let go.&lt;/p&gt;</comment>
                            <comment id="13883647" author="stack" created="Tue, 28 Jan 2014 02:01:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; What you think of the trunk failures?  Let me retry your patch.&lt;/p&gt;</comment>
                            <comment id="13883748" author="hadoopqa" created="Tue, 28 Jan 2014 04:52:21 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625501/HADOOP-10255.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625501/HADOOP-10255.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 18 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3485//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3485//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3485//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3485//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883757" author="wheat9" created="Tue, 28 Jan 2014 05:07:33 +0000"  >&lt;p&gt;Looking at the test report, I believe that failure is irrelevant. &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5719&quot; title=&quot;Potential null pointer access in AbstractYarnScheduler#getTransferredContainers()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5719&quot;&gt;MAPREDUCE-5719&lt;/a&gt; tracks the failed unit test.&lt;/p&gt;</comment>
                            <comment id="13883776" author="stack" created="Tue, 28 Jan 2014 05:25:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; Ok.  I can commit this in morning unless objection.&lt;/p&gt;</comment>
                            <comment id="13883849" author="sureshms" created="Tue, 28 Jan 2014 07:22:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;, please file a jira if you have further cleanup of HttpServer2. One thing we could do in that jira to remove deprecated method. I see one such method - #getPort().&lt;/p&gt;

&lt;p&gt;+1 for the patch.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, once the copy of HttpServer is made in HBase, we can delete it from future 2.x release. This is an incompatible. However given this removal is breaking compatibility only for HBase and HBase will no longer use this class, such an incompatible change should be fine. Do you agree? We need to agree upon a release to align this change.&lt;/p&gt;</comment>
                            <comment id="13883869" author="hudson" created="Tue, 28 Jan 2014 07:50:20 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5051 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5051/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5051/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Adding missed CHANGES.txt from change 1561959. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility. Contributed by Haohui Mai. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ConfServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/AdminAuthorizedServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/jmx/JMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/log/LogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics/MetricsServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/AuthenticationFilterInitializer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/HttpServerFunctionalTest.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestGlobalFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHtmlQuoting.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerLifecycle.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerWebapps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestPathFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestSSLHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestServletFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/jmx/TestJMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/log/TestLogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestAuthenticationFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestGetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestTransferFsImage.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotTestHelper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApp.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxy.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/test/java/org/apache/hadoop/yarn/server/webproxy/TestWebAppProxyServlet.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13883872" author="sureshms" created="Tue, 28 Jan 2014 07:52:43 +0000"  >&lt;p&gt;I have committed this to branch-2 and trunk. Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;. Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; for review and testing.&lt;/p&gt;</comment>
                            <comment id="13884017" author="hudson" created="Tue, 28 Jan 2014 11:09:05 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Adding missed CHANGES.txt from change 1561959. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility. Contributed by Haohui Mai. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ConfServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/AdminAuthorizedServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/jmx/JMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/log/LogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics/MetricsServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/AuthenticationFilterInitializer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/HttpServerFunctionalTest.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestGlobalFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHtmlQuoting.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerLifecycle.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerWebapps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestPathFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestSSLHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestServletFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/jmx/TestJMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/log/TestLogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestAuthenticationFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestGetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestTransferFsImage.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotTestHelper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApp.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxy.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/test/java/org/apache/hadoop/yarn/server/webproxy/TestWebAppProxyServlet.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884123" author="hudson" created="Tue, 28 Jan 2014 13:29:57 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Adding missed CHANGES.txt from change 1561959. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility. Contributed by Haohui Mai. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ConfServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/AdminAuthorizedServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/jmx/JMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/log/LogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics/MetricsServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/AuthenticationFilterInitializer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/HttpServerFunctionalTest.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestGlobalFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHtmlQuoting.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerLifecycle.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerWebapps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestPathFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestSSLHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestServletFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/jmx/TestJMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/log/TestLogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestAuthenticationFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestGetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestTransferFsImage.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotTestHelper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApp.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxy.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/test/java/org/apache/hadoop/yarn/server/webproxy/TestWebAppProxyServlet.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884140" author="hudson" created="Tue, 28 Jan 2014 13:40:18 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Adding missed CHANGES.txt from change 1561959. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561961&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility. Contributed by Haohui Mai. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561959&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ConfServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/AdminAuthorizedServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/jmx/JMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/log/LogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics/MetricsServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/AuthenticationFilterInitializer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/HttpServerFunctionalTest.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestGlobalFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHtmlQuoting.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerLifecycle.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServerWebapps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestPathFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestSSLHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestServletFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/jmx/TestJMXJsonServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/log/TestLogLevel.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestAuthenticationFilter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/GetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeHttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestGetImageServlet.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestTransferFsImage.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotTestHelper.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobEndNotifier.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApp.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/WebApps.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/WebAppProxy.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/test/java/org/apache/hadoop/yarn/server/webproxy/TestWebAppProxyServlet.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884262" author="stack" created="Tue, 28 Jan 2014 15:44:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt; Thanks for committing.  On &apos;We need to agree upon a release to align this change.&apos;, lets align on hadoop3 (hbase 0.96/0.98 depend on httpserver and should be able to run on any 2.x hadoops).  Thanks.&lt;/p&gt;</comment>
                            <comment id="13885924" author="andrew.wang" created="Wed, 29 Jan 2014 22:35:31 +0000"  >&lt;p&gt;FYI with the reswizzle of branch-2.3, I think this was missed. I just merged it to the new branch-2.3.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12688732">HBASE-10336</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12691476">HADOOP-10292</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625452" name="HADOOP-10255-branch2.000.patch" size="161736" author="wheat9" created="Mon, 27 Jan 2014 22:06:12 +0000"/>
                            <attachment id="12624452" name="HADOOP-10255.000.patch" size="131481" author="wheat9" created="Wed, 22 Jan 2014 22:31:26 +0000"/>
                            <attachment id="12624454" name="HADOOP-10255.001.patch" size="140422" author="wheat9" created="Wed, 22 Jan 2014 22:38:17 +0000"/>
                            <attachment id="12624903" name="HADOOP-10255.002.patch" size="143953" author="wheat9" created="Thu, 23 Jan 2014 20:49:25 +0000"/>
                            <attachment id="12625501" name="HADOOP-10255.003.patch" size="161993" author="stack" created="Tue, 28 Jan 2014 02:04:24 +0000"/>
                            <attachment id="12624908" name="HADOOP-10255.003.patch" size="161993" author="wheat9" created="Thu, 23 Jan 2014 20:55:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 22:59:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369376</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369377</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10254] HttpServer doesn&apos;t load listeners</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10254</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;With &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10252&quot; title=&quot;HttpServer can&amp;#39;t start if hostname is not specified&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10252&quot;&gt;&lt;del&gt;HADOOP-10252&lt;/del&gt;&lt;/a&gt;, we fixed the IAE issue. However, the server isn&apos;t starting properly since listeners are not loaded.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690365">HADOOP-10254</key>
            <summary>HttpServer doesn&apos;t load listeners</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="jxiang">Jimmy Xiang</assignee>
                                    <reporter username="jxiang">Jimmy Xiang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jan 2014 20:00:49 +0000</created>
                <updated>Thu, 23 Jan 2014 05:03:34 +0000</updated>
                            <resolved>Wed, 22 Jan 2014 22:18:20 +0000</resolved>
                                    <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13879112" author="jxiang" created="Wed, 22 Jan 2014 20:06:33 +0000"  >&lt;p&gt;The patch added the listeners. With this patch. HBase TestInfoServer works fine now.&lt;/p&gt;</comment>
                            <comment id="13879135" author="wheat9" created="Wed, 22 Jan 2014 20:21:57 +0000"  >&lt;p&gt;The clean way to do so is to manipulate the builder object instead of copying code into the constructor.&lt;/p&gt;

&lt;p&gt;And can you elaborate what does the unit test cover?&lt;/p&gt;</comment>
                            <comment id="13879155" author="jxiang" created="Wed, 22 Jan 2014 20:39:05 +0000"  >&lt;p&gt;I thought about refractory the builder. However, we don&apos;t need all the functionality in the builder. This way is much simpler.  My HBase cluster with the patch works.  As to the unit test, I want to make sure the connector address is not null, since we see NPE in HBase unit tests. Thanks.&lt;/p&gt;</comment>
                            <comment id="13879164" author="hadoopqa" created="Wed, 22 Jan 2014 20:49:08 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624412/hadoop-10254.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624412/hadoop-10254.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3461//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3461//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3461//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3461//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13879177" author="wheat9" created="Wed, 22 Jan 2014 21:03:53 +0000"  >&lt;p&gt;Connector address is supposed to be null when the code is not listening on the privileged port. I&apos;m yet to be convinced that changing the code just to pass unit tests in HBase.&lt;/p&gt;

&lt;p&gt;It seems to me that it might be worthwhile to take a step back to think through what is the right approach rather than quickly putting in some code and rushing for a release.&lt;/p&gt;</comment>
                            <comment id="13879181" author="stack" created="Wed, 22 Jan 2014 21:06:27 +0000"  >&lt;p&gt;Just took a look at HttpServer in branch-2 comparing to branch-2.2.  Radical change.&lt;/p&gt;

&lt;p&gt;Jimmy copying what was in build into constructor, is there a means of making sure in the build call we don&apos;t re-add the unmanaged listener?  Ditto for the createDefaultChannelConnector. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; help us out please.  We need this fixed.  Thanks.&lt;/p&gt;
</comment>
                            <comment id="13879201" author="jxiang" created="Wed, 22 Jan 2014 21:25:26 +0000"  >&lt;p&gt;Those two methods are private, won&apos;t be called many times. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;, why is the connector address supposed to be null? The connectors are added in loadListeners(), right?&lt;/p&gt;</comment>
                            <comment id="13879228" author="wheat9" created="Wed, 22 Jan 2014 21:49:30 +0000"  >&lt;p&gt;Looked at the InfoServer in hbase.&lt;/p&gt;

&lt;p&gt;Given the current status of the code, it seems to me that it is difficult to do so if &lt;tt&gt;InfoServer&lt;/tt&gt; inherits &lt;tt&gt;HttpServer&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;My suggestion is to adopt parts of the early patches in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10232&quot; title=&quot;More options to HttpServer Builder&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10232&quot;&gt;&lt;del&gt;HADOOP-10232&lt;/del&gt;&lt;/a&gt;, that are:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Use composition instead of inheritance.&lt;/li&gt;
	&lt;li&gt;Expose &lt;tt&gt;appDir()&lt;/tt&gt; in the builder.&lt;/li&gt;
	&lt;li&gt;Expose &lt;tt&gt;getWebAppContext()&lt;/tt&gt; in {HttpServer}} to customize the log directory.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;It should work for the release aligned with 2.4, but just keep your heads up &amp;#8211; there are no guarantees that this APIs will stay stable. HBase might be broken again whenever we move away from Jetty 6. I anticipate some security-related work (e.g. &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5716&quot; title=&quot;Allow WebHDFS to use pluggable authentication filter&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5716&quot;&gt;HDFS-5716&lt;/a&gt;) could potentially change the APIs as well. The work can start as early as 2.5, so you really need to evaluate the balance of riding along with &lt;tt&gt;HttpServer&lt;/tt&gt; versus the difficulties on working with different Hadoop versions.&lt;/p&gt;

&lt;p&gt;On the other hand, can you please elaborate on your concerns of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt;? It is a big patch indeed, but most of them are copying from the hadoop codebase directly thus the risk is minimal.&lt;/p&gt;</comment>
                            <comment id="13879233" author="wheat9" created="Wed, 22 Jan 2014 21:53:27 +0000"  >&lt;p&gt;Exposing Connector into the builder&apos;s API is essentially a hack to allow datanode to take privileged HTTP port. It is there for historical reasons. Other users should never use it.&lt;/p&gt;</comment>
                            <comment id="13879271" author="jxiang" created="Wed, 22 Jan 2014 22:18:20 +0000"  >&lt;p&gt;Per &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10253&quot; title=&quot;Remove deprecated methods in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10253&quot;&gt;&lt;del&gt;HADOOP-10253&lt;/del&gt;&lt;/a&gt;, it will be cleaner to bring the original HttpServer back.&lt;/p&gt;</comment>
                            <comment id="13879290" author="stack" created="Wed, 22 Jan 2014 22:41:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; You have made the same request multiple times in multiple different issues.  We do not want existing releases to break going from 2.2 to 2.4.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; If we revert &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9784&quot; title=&quot;Add a builder for HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9784&quot;&gt;&lt;del&gt;HADOOP-9784&lt;/del&gt;&lt;/a&gt;, does stuff work again?  &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9784&quot; title=&quot;Add a builder for HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9784&quot;&gt;&lt;del&gt;HADOOP-9784&lt;/del&gt;&lt;/a&gt; is a nice-to-have improvement that &apos;affects&apos; 3.0 that gentleman &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lukekliu&quot; class=&quot;user-hover&quot; rel=&quot;lukekliu&quot;&gt;Luke Liu&lt;/a&gt; appled for 2.4 timeframe.  I&apos;m sure &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=djp&quot; class=&quot;user-hover&quot; rel=&quot;djp&quot;&gt;Junping Du&lt;/a&gt; would be cool removing this from 2.4 if he knew it was messing up downstreamers.&lt;/p&gt;</comment>
                            <comment id="13879311" author="jxiang" created="Wed, 22 Jan 2014 22:52:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, it won&apos;t work just removing &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9784&quot; title=&quot;Add a builder for HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9784&quot;&gt;&lt;del&gt;HADOOP-9784&lt;/del&gt;&lt;/a&gt;. We need to remove &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5545&quot; title=&quot;Allow specifying endpoints for listeners in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5545&quot;&gt;&lt;del&gt;HDFS-5545&lt;/del&gt;&lt;/a&gt; too.  My patch here is kind of reverting some change to &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5545&quot; title=&quot;Allow specifying endpoints for listeners in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5545&quot;&gt;&lt;del&gt;HDFS-5545&lt;/del&gt;&lt;/a&gt;: still keeping the listener init in the deprecated constructor.  So, to me, the patch is a valid fix.  Haohui&apos;s suggestion makes things more complex.&lt;/p&gt;</comment>
                            <comment id="13879399" author="eric@apache.org" created="Thu, 23 Jan 2014 03:04:58 +0000"  >&lt;p&gt;Reverting &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9784&quot; title=&quot;Add a builder for HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9784&quot;&gt;&lt;del&gt;HADOOP-9784&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5545&quot; title=&quot;Allow specifying endpoints for listeners in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5545&quot;&gt;&lt;del&gt;HDFS-5545&lt;/del&gt;&lt;/a&gt; is too much work IMHO&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; Your patch should work for the port connector. On &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt;, you say &quot;I just tested. My HBase cluster works fine with it.&quot; - do you mean you applied &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10254&quot; title=&quot;HttpServer doesn&amp;#39;t load listeners&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10254&quot;&gt;&lt;del&gt;HADOOP-10254&lt;/del&gt;&lt;/a&gt;, ran hbase without any change, and got access to all web contexts. If this is the case, I guess the easy solution is to apply this on hadoop.&lt;/p&gt;</comment>
                            <comment id="13879414" author="jxiang" created="Thu, 23 Jan 2014 03:26:40 +0000"  >&lt;p&gt;I checked the master web UI. I clicked several links there. I checked the region server UI too. Not tested every link, of course. I agree this is the easy solution.&lt;/p&gt;</comment>
                            <comment id="13879441" author="eric@apache.org" created="Thu, 23 Jan 2014 05:03:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; then it is ok (I was asking because I had issue decoupling hbase from hadoop jetty for a few servlets, but here if the server starts, all servlets should be up). master and region were also using different methods, but good to have checked both,&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12690351">HADOOP-10253</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12688732">HBASE-10336</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624412" name="hadoop-10254.patch" size="1781" author="jxiang" created="Wed, 22 Jan 2014 20:06:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 20:21:57 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369323</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369324</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10253] Remove deprecated methods in HttpServer</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10253</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;There are a lot of deprecated methods in &lt;tt&gt;HttpServer&lt;/tt&gt;. They are not used anymore. They should be removed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690351">HADOOP-10253</key>
            <summary>Remove deprecated methods in HttpServer</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jan 2014 19:12:09 +0000</created>
                <updated>Tue, 28 Jan 2014 07:32:09 +0000</updated>
                            <resolved>Tue, 28 Jan 2014 07:32:09 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13879057" author="apurtell" created="Wed, 22 Jan 2014 19:19:35 +0000"  >&lt;p&gt;Have you checked if downstream projects are using them?&lt;/p&gt;</comment>
                            <comment id="13879060" author="andrew.wang" created="Wed, 22 Jan 2014 19:24:01 +0000"  >&lt;p&gt;Echoing &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, there are a lot of downstreams using HttpServer. Even if these methods were deprecated in 1.x, it seems kind of nasty to remove them in a 2.x release after 2.2 GA.&lt;/p&gt;</comment>
                            <comment id="13879064" author="stack" created="Wed, 22 Jan 2014 19:25:36 +0000"  >&lt;p&gt;Why not remove in 3.x?&lt;/p&gt;</comment>
                            <comment id="13879066" author="wheat9" created="Wed, 22 Jan 2014 19:26:04 +0000"  >&lt;p&gt;According to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt;, the deprecated methods will stay in the 2.4 release. The methods will be removed in the next release.&lt;/p&gt;</comment>
                            <comment id="13879068" author="apurtell" created="Wed, 22 Jan 2014 19:27:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;The methods will be removed in the next release.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If you mean 2.5, then you will have only moved the problem for HBase 0.96.x and HBase 0.98.x to 2.5. Surely other downstreams will be affected also.&lt;/p&gt;</comment>
                            <comment id="13879074" author="andrew.wang" created="Wed, 22 Jan 2014 19:31:18 +0000"  >&lt;p&gt;I feel like we can&apos;t do this change in a 2.x. For 3.x it&apos;s fine, but as all the HBasers are saying, it&apos;s clearly backwards incompatible with earlier 2.x releases.&lt;/p&gt;</comment>
                            <comment id="13879086" author="wheat9" created="Wed, 22 Jan 2014 19:39:16 +0000"  >&lt;p&gt;This is exactly the situation that we want to avoid &amp;#8211; &lt;tt&gt;HttpServer&lt;/tt&gt; is a private API and it should not support any downstream uses.&lt;/p&gt;

&lt;p&gt;The only downstream user of this class is HBase. Once &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt; is landed, you should be clear to upgrade.&lt;/p&gt;</comment>
                            <comment id="13879088" author="apurtell" created="Wed, 22 Jan 2014 19:41:16 +0000"  >&lt;p&gt;My read of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt; is the change there will be committed to HBase trunk, but not to the 0.96 and 0.98 release branches. For those releases, we will need to add a disclaimer they will not work with Hadoop 2.X where X is wherever the backwards compatibility is broken on the Hadoop 2.x release line. &lt;/p&gt;</comment>
                            <comment id="13879141" author="apurtell" created="Wed, 22 Jan 2014 20:23:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;This is exactly the situation that we want to avoid &#8211; HttpServer is a private API and it should not support any downstream uses.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I went and reviewed the code in question, and I don&apos;t understand this statement. This is the interface annotation for HttpServer on HEAD of Hadoop common branch-2:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;@InterfaceAudience.LimitedPrivate({&quot;HDFS&quot;, &quot;MapReduce&quot;, &quot;HBase&quot;})
@InterfaceStability.Evolving
public class HttpServer implements FilterContainer {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13879165" author="stack" created="Wed, 22 Jan 2014 20:50:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; &quot;...HttpServer is a private API and it should not support any downstream uses.&quot;&lt;/p&gt;

&lt;p&gt;Go easy.  The above is all well and good as some sort of general statement only there is the caveat that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; quotes you above (and which was quoted to you a few days ago over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10232&quot; title=&quot;More options to HttpServer Builder&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10232&quot;&gt;&lt;del&gt;HADOOP-10232&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I believe the hope was that those listed in the LimitedPrivate set would get notice if the class was to change radically.  Notice noted.  We are moving to get off this Interface now  &amp;#8211; a patch will go in in the next few days and we&apos;ll soon enough have a release out with the patch in it &amp;#8211; but please do not remove these methods just yet and make it so releases we have in the field now fail when our users would like to go to apache 2.5/2.6, etc.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13879248" author="sureshms" created="Wed, 22 Jan 2014 22:02:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;HttpServer is a private API and it should not support any downstream uses.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;, given that this class is marked as LimitedPrivate this class cannot be removed or made private. ,The interface is marked as evolving, so incompatible changes should be allowed. However, I suggest just making a copy of this HttpServer (HttpServer2?) for internal use in HDFS and MapReduce, with cleaner code and leave HttpServer class alone. At some point in time when HBase folks are ready, they can copy this to their project and we can delete this from Hadoop, possibly in 3.0.&lt;/p&gt;</comment>
                            <comment id="13879268" author="jxiang" created="Wed, 22 Jan 2014 22:15:24 +0000"  >&lt;p&gt;+1 to make a copy of this HttpServer and bring the original HttpServer back.&lt;/p&gt;</comment>
                            <comment id="13879292" author="jxiang" created="Wed, 22 Jan 2014 22:42:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt;, the patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10254&quot; title=&quot;HttpServer doesn&amp;#39;t load listeners&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10254&quot;&gt;&lt;del&gt;HADOOP-10254&lt;/del&gt;&lt;/a&gt;, is kind of undo part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5545&quot; title=&quot;Allow specifying endpoints for listeners in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5545&quot;&gt;&lt;del&gt;HDFS-5545&lt;/del&gt;&lt;/a&gt;, so it is about the same as the original version. Is that not an option?&lt;/p&gt;</comment>
                            <comment id="13879296" author="jxiang" created="Wed, 22 Jan 2014 22:44:13 +0000"  >&lt;p&gt;Is the end effect kind of the same as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt; suggested?&lt;/p&gt;</comment>
                            <comment id="13879343" author="stack" created="Wed, 22 Jan 2014 23:26:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt; Thanks for the helpful suggestion.  We&apos;re letting go of this dependency in our trunk.  We can&apos;t just do it &apos;now&apos; in existing releases w/o frustrating our users.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13883860" author="wheat9" created="Tue, 28 Jan 2014 07:32:09 +0000"  >&lt;p&gt;According to the discussion in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10255&quot; title=&quot;Rename HttpServer to HttpServer2 to retain older HttpServer in branch-2 for compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10255&quot;&gt;&lt;del&gt;HADOOP-10255&lt;/del&gt;&lt;/a&gt;. HttpServer is reserved for HBase&apos;s use. Marking this jira as won&apos;t fix.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12690365">HADOOP-10254</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12688732">HBASE-10336</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 19:19:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369309</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369310</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10252] HttpServer can&apos;t start if hostname is not specified</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10252</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8362&quot; title=&quot;Improve exception message when Configuration.set() is called with a null key or value&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8362&quot;&gt;&lt;del&gt;HADOOP-8362&lt;/del&gt;&lt;/a&gt; added a checking to make sure configuration values are not null. By default, we don&apos;t specify the hostname for the HttpServer. So we could not start info server due to&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-01-22 08:43:05,969 FATAL [M:0;localhost:48573] master.HMaster(2187): Unhandled exception. Starting shutdown.
java.lang.IllegalArgumentException: Property value must not be null
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:92)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:958)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:940)
	at org.apache.hadoop.http.HttpServer.initializeWebServer(HttpServer.java:510)
	at org.apache.hadoop.http.HttpServer.&amp;lt;init&amp;gt;(HttpServer.java:470)
	at org.apache.hadoop.http.HttpServer.&amp;lt;init&amp;gt;(HttpServer.java:458)
	at org.apache.hadoop.http.HttpServer.&amp;lt;init&amp;gt;(HttpServer.java:412)
	at org.apache.hadoop.hbase.util.InfoServer.&amp;lt;init&amp;gt;(InfoServer.java:59)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:584)
	at java.lang.Thread.run(Thread.java:722)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12690305">HADOOP-10252</key>
            <summary>HttpServer can&apos;t start if hostname is not specified</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jxiang">Jimmy Xiang</assignee>
                                    <reporter username="jxiang">Jimmy Xiang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jan 2014 16:43:27 +0000</created>
                <updated>Tue, 28 Jan 2014 23:37:00 +0000</updated>
                            <resolved>Wed, 22 Jan 2014 18:13:48 +0000</resolved>
                                    <version>2.0.2-alpha</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13878878" author="atm" created="Wed, 22 Jan 2014 17:36:14 +0000"  >&lt;p&gt;Patch looks good to me. +1 pending Jenkins.&lt;/p&gt;</comment>
                            <comment id="13878903" author="hadoopqa" created="Wed, 22 Jan 2014 17:53:24 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624372/hadoop-10252.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624372/hadoop-10252.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3459//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3459//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3459//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3459//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13878935" author="atm" created="Wed, 22 Jan 2014 18:13:48 +0000"  >&lt;p&gt;I&apos;ve just committed this to trunk and branch-2.&lt;/p&gt;

&lt;p&gt;Thanks a lot for the contribution, Jimmy.&lt;/p&gt;</comment>
                            <comment id="13878958" author="hudson" created="Wed, 22 Jan 2014 18:26:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5032 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5032/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5032/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10252&quot; title=&quot;HttpServer can&amp;#39;t start if hostname is not specified&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10252&quot;&gt;&lt;del&gt;HADOOP-10252&lt;/del&gt;&lt;/a&gt;. HttpServer can&apos;t start if hostname is not specified. Contributed by Jimmy Xiang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13878987" author="wheat9" created="Wed, 22 Jan 2014 18:40:44 +0000"  >&lt;p&gt;This is due to hbase is using the deprecated constructor. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt; is tracking the issue.&lt;/p&gt;</comment>
                            <comment id="13878993" author="jxiang" created="Wed, 22 Jan 2014 18:45:17 +0000"  >&lt;p&gt;Yes, HBase uses the deprecate constructor. It should work if it is not removed.&lt;/p&gt;</comment>
                            <comment id="13879000" author="wheat9" created="Wed, 22 Jan 2014 18:49:28 +0000"  >&lt;p&gt;My concern is that it might not solve the HBase problem completely. Recently &lt;tt&gt;HttpServer&lt;/tt&gt; has gone through major surgeries for HTTPS support. For obvious reason the deprecated code path is not very well tested.&lt;/p&gt;

&lt;p&gt;I have spent reasonable amount of time to test the current code paths of the &lt;tt&gt;HttpServer&lt;/tt&gt; in NN / DN / JN / SNN in various configuration. In my opinion the approach that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt; takes might be a safer bet.&lt;/p&gt;</comment>
                            <comment id="13879011" author="jxiang" created="Wed, 22 Jan 2014 18:55:53 +0000"  >&lt;p&gt;I think we can do both for now. Otherwise, existing older versions of HBase will have problem to work with HDFS 2.4+.&lt;/p&gt;</comment>
                            <comment id="13879016" author="apurtell" created="Wed, 22 Jan 2014 18:59:49 +0000"  >&lt;p&gt;Based on the discussion on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt;, it is likely not to go in on any released or soon to be released version of HBase. The next release is likely a few months out. &lt;/p&gt;</comment>
                            <comment id="13879036" author="stack" created="Wed, 22 Jan 2014 19:07:35 +0000"  >&lt;p&gt;Thanks for applying this patch.  We are working to undo our dependency but cannot take the hit just yet; the undo will go into our trunk in a day or so with a release to follow soon after (a few months at most as per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; above).  Thanks.&lt;/p&gt;</comment>
                            <comment id="13879051" author="wheat9" created="Wed, 22 Jan 2014 19:15:16 +0000"  >&lt;p&gt;Created &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10253&quot; title=&quot;Remove deprecated methods in HttpServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10253&quot;&gt;&lt;del&gt;HADOOP-10253&lt;/del&gt;&lt;/a&gt; to track the effort of removing deprecated methods in &lt;tt&gt;HttpServer&lt;/tt&gt;. Let&apos;s coordinate our effort in that jira.&lt;/p&gt;</comment>
                            <comment id="13881842" author="hudson" created="Sat, 25 Jan 2014 12:27:45 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #461 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10252&quot; title=&quot;HttpServer can&amp;#39;t start if hostname is not specified&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10252&quot;&gt;&lt;del&gt;HADOOP-10252&lt;/del&gt;&lt;/a&gt;. HttpServer can&apos;t start if hostname is not specified. Contributed by Jimmy Xiang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881869" author="hudson" created="Sat, 25 Jan 2014 13:27:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1678 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10252&quot; title=&quot;HttpServer can&amp;#39;t start if hostname is not specified&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10252&quot;&gt;&lt;del&gt;HADOOP-10252&lt;/del&gt;&lt;/a&gt;. HttpServer can&apos;t start if hostname is not specified. Contributed by Jimmy Xiang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881887" author="hudson" created="Sat, 25 Jan 2014 13:38:06 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1653 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10252&quot; title=&quot;HttpServer can&amp;#39;t start if hostname is not specified&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10252&quot;&gt;&lt;del&gt;HADOOP-10252&lt;/del&gt;&lt;/a&gt;. HttpServer can&apos;t start if hostname is not specified. Contributed by Jimmy Xiang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560450&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12688732">HBASE-10336</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624372" name="hadoop-10252.patch" size="2015" author="jxiang" created="Wed, 22 Jan 2014 17:15:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 17:36:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369263</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369264</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10251] Both NameNodes could be in STANDBY State if SNN network is unstable</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10251</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Following corner scenario happened in one of our cluster.&lt;/p&gt;

&lt;p&gt;1. NN1 was Active and NN2 was Standby&lt;br/&gt;
2. NN2 machine&apos;s network was slow &lt;br/&gt;
3. NN1 got shutdown.&lt;br/&gt;
4. NN2 ZKFC got the notification and trying to check for old active for fencing. (This took little more time, again due to slow network)&lt;br/&gt;
5. In between, NN1 got restarted by our automatic monitoring, and ZKFC made it Active.&lt;br/&gt;
6. Now NN2 ZKFC got Old Active as NN2 and it did graceful fencing of NN1 to STANBY.&lt;br/&gt;
7. Before writing ActiveBreadCrumb to ZK, NN2 ZKFC got session timeout and got shutdown before making NN2 Active.&lt;/p&gt;


&lt;p&gt;&lt;b&gt;Now cluster having both NameNodes as STANDBY.&lt;/b&gt;&lt;br/&gt;
NN1 ZKFC still thinks that its nameNode is in Active state. &lt;br/&gt;
NN2 ZKFC waiting for election.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690252">HADOOP-10251</key>
            <summary>Both NameNodes could be in STANDBY State if SNN network is unstable</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="vinayrpet">Vinay</assignee>
                                    <reporter username="vinayrpet">Vinay</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jan 2014 12:05:23 +0000</created>
                <updated>Thu, 23 Jan 2014 06:12:50 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>ha</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13878576" author="vinayrpet" created="Wed, 22 Jan 2014 12:07:15 +0000"  >&lt;p&gt;ZKFC health check, checks the state of the NameNode, but it doesnot validate it with expected state.&lt;/p&gt;</comment>
                            <comment id="13878586" author="vinayrpet" created="Wed, 22 Jan 2014 12:16:05 +0000"  >&lt;p&gt;Attaching a patch for the above case. Please review&lt;/p&gt;</comment>
                            <comment id="13878739" author="hadoopqa" created="Wed, 22 Jan 2014 15:06:56 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624335/HADOOP-10251.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624335/HADOOP-10251.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.ha.TestZKFailoverController&lt;/p&gt;

&lt;p&gt;                                      The following test timeouts occurred in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.ha.TestZKFailoverControllerStress&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3457//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3457//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3457//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3457//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13879443" author="vinayrpet" created="Thu, 23 Jan 2014 05:12:56 +0000"  >&lt;p&gt;Updated the patch to fix test failures.&lt;br/&gt;
These are mainly time issues.&lt;/p&gt;</comment>
                            <comment id="13879454" author="vinayrpet" created="Thu, 23 Jan 2014 05:25:10 +0000"  >&lt;p&gt;Updated the patch again.&lt;br/&gt;
Also enabled tests in Windows.&lt;/p&gt;</comment>
                            <comment id="13879477" author="vinayrpet" created="Thu, 23 Jan 2014 06:12:50 +0000"  >&lt;p&gt;Attaching the updated patch, fixed some synchronization issue.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624583" name="HADOOP-10251.patch" size="9091" author="vinayrpet" created="Thu, 23 Jan 2014 06:12:50 +0000"/>
                            <attachment id="12624579" name="HADOOP-10251.patch" size="8985" author="vinayrpet" created="Thu, 23 Jan 2014 05:25:10 +0000"/>
                            <attachment id="12624575" name="HADOOP-10251.patch" size="7176" author="vinayrpet" created="Thu, 23 Jan 2014 05:12:56 +0000"/>
                            <attachment id="12624335" name="HADOOP-10251.patch" size="6741" author="vinayrpet" created="Wed, 22 Jan 2014 12:16:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 15:06:56 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369211</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369212</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10250] VersionUtil returns wrong value when comparing two versions</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10250</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;VersionUtil.compareVersions(&quot;1.0.0-beta-1&quot;, &quot;1.0.0&quot;) returns 7 instead of negative number, which is wrong, because 1.0.0-beta-1 older than 1.0.0.&lt;/p&gt;


</description>
                <environment></environment>
        <key id="12690122">HADOOP-10250</key>
            <summary>VersionUtil returns wrong value when comparing two versions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yzhangal">Yongjun Zhang</assignee>
                                    <reporter username="yzhangal">Yongjun Zhang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 21:58:22 +0000</created>
                <updated>Wed, 29 Jan 2014 23:44:02 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 21:39:22 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13878197" author="yzhangal" created="Wed, 22 Jan 2014 03:15:36 +0000"  >&lt;p&gt;I submitted a patch by reusing maven&apos;s version comparison class ComparableVersion.java.&lt;br/&gt;
Thanks for reviewing.&lt;/p&gt;</comment>
                            <comment id="13878227" author="hadoopqa" created="Wed, 22 Jan 2014 03:55:19 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624262/HADOOP-10250.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624262/HADOOP-10250.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 @author&lt;/font&gt;.  The patch appears to contain 2 @author tags which the Hadoop community has agreed to not allow in code contributions.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3452//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3452//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3452//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3452//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3452//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3452//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13878817" author="hadoopqa" created="Wed, 22 Jan 2014 16:33:14 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624364/HADOOP-10250.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624364/HADOOP-10250.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 @author&lt;/font&gt;.  The patch appears to contain 1 @author tags which the Hadoop community has agreed to not allow in code contributions.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3458//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3458//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3458//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3458//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3458//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3458//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13879262" author="yzhangal" created="Wed, 22 Jan 2014 22:10:46 +0000"  >&lt;p&gt;Updated new version to address the @author tag and findbugs issues reported by jenkins test.&lt;/p&gt;</comment>
                            <comment id="13879304" author="hadoopqa" created="Wed, 22 Jan 2014 22:47:12 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624417/HADOOP-10250.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624417/HADOOP-10250.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3462//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3462//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3462//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3462//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3462//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3462//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13879370" author="yzhangal" created="Thu, 23 Jan 2014 02:14:25 +0000"  >&lt;p&gt;uploaded a new version for the findbugs issue.&lt;/p&gt;</comment>
                            <comment id="13881923" author="yzhangal" created="Sat, 25 Jan 2014 15:24:33 +0000"  >&lt;p&gt;The build server has been down for a while. Upload the same version as last time to trigger build test. &lt;/p&gt;</comment>
                            <comment id="13881940" author="hadoopqa" created="Sat, 25 Jan 2014 16:06:10 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625192/HADOOP-10250.004.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625192/HADOOP-10250.004.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3471//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3471//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3471//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3471//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883355" author="atm" created="Mon, 27 Jan 2014 21:34:37 +0000"  >&lt;p&gt;+1, the latest patch looks good to me. I&apos;m going to commit this momentarily.&lt;/p&gt;</comment>
                            <comment id="13883363" author="atm" created="Mon, 27 Jan 2014 21:39:22 +0000"  >&lt;p&gt;I&apos;ve just committed this to trunk and branch-2.&lt;/p&gt;

&lt;p&gt;Thanks a lot for the contribution, Yongjun.&lt;/p&gt;</comment>
                            <comment id="13883398" author="hudson" created="Mon, 27 Jan 2014 21:57:54 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5047 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5047/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5047/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10250&quot; title=&quot;VersionUtil returns wrong value when comparing two versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10250&quot;&gt;&lt;del&gt;HADOOP-10250&lt;/del&gt;&lt;/a&gt;. VersionUtil returns wrong value when comparing two versions. Contributed by Yongjun Zhang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/dev-support/findbugsExcludeFile.xml&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ComparableVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/VersionUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestVersionUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13883449" author="yzhangal" created="Mon, 27 Jan 2014 22:34:30 +0000"  >&lt;p&gt;Many thanks Aaron!&lt;/p&gt;</comment>
                            <comment id="13884019" author="hudson" created="Tue, 28 Jan 2014 11:09:06 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10250&quot; title=&quot;VersionUtil returns wrong value when comparing two versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10250&quot;&gt;&lt;del&gt;HADOOP-10250&lt;/del&gt;&lt;/a&gt;. VersionUtil returns wrong value when comparing two versions. Contributed by Yongjun Zhang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/dev-support/findbugsExcludeFile.xml&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ComparableVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/VersionUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestVersionUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884125" author="hudson" created="Tue, 28 Jan 2014 13:29:58 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10250&quot; title=&quot;VersionUtil returns wrong value when comparing two versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10250&quot;&gt;&lt;del&gt;HADOOP-10250&lt;/del&gt;&lt;/a&gt;. VersionUtil returns wrong value when comparing two versions. Contributed by Yongjun Zhang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/dev-support/findbugsExcludeFile.xml&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ComparableVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/VersionUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestVersionUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884142" author="hudson" created="Tue, 28 Jan 2014 13:40:18 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10250&quot; title=&quot;VersionUtil returns wrong value when comparing two versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10250&quot;&gt;&lt;del&gt;HADOOP-10250&lt;/del&gt;&lt;/a&gt;. VersionUtil returns wrong value when comparing two versions. Contributed by Yongjun Zhang. (atm: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561860&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/dev-support/findbugsExcludeFile.xml&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ComparableVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/VersionUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestVersionUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885940" author="andrew.wang" created="Wed, 29 Jan 2014 22:47:14 +0000"  >&lt;p&gt;I merged this back to branch-2.3 post swizzle as well.&lt;/p&gt;</comment>
                            <comment id="13886009" author="yzhangal" created="Wed, 29 Jan 2014 23:44:02 +0000"  >&lt;p&gt;Thanks Andrew.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624262" name="HADOOP-10250.001.patch" size="24330" author="yzhangal" created="Wed, 22 Jan 2014 03:11:52 +0000"/>
                            <attachment id="12624364" name="HADOOP-10250.002.patch" size="24466" author="yzhangal" created="Wed, 22 Jan 2014 15:52:54 +0000"/>
                            <attachment id="12624417" name="HADOOP-10250.003.patch" size="24994" author="yzhangal" created="Wed, 22 Jan 2014 20:19:10 +0000"/>
                            <attachment id="12625192" name="HADOOP-10250.004.patch" size="25041" author="yzhangal" created="Sat, 25 Jan 2014 15:24:33 +0000"/>
                            <attachment id="12624461" name="HADOOP-10250.004.patch" size="25041" author="yzhangal" created="Thu, 23 Jan 2014 02:13:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 03:55:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369084</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369085</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10249] LdapGroupsMapping should trim ldap password read from file</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10249</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt; org.apache.hadoop.security.LdapGroupsMapping allows specifying ldap connection password in a file using property key&lt;/p&gt;

&lt;p&gt;hadoop.security.group.mapping.ldap.bind.password.file&lt;/p&gt;

&lt;p&gt;The code in LdapGroupsMapping  that reads the content of the password file does not trim the password value. This causes ldap connection failure as the password in the password file ends up having a trailing newline.&lt;/p&gt;

&lt;p&gt;Most of the text editors and echo adds a new line at the end of file.&lt;br/&gt;
So, LdapGroupsMapping should trim the password read from the file.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690102">HADOOP-10249</key>
            <summary>LdapGroupsMapping should trim ldap password read from file</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="darumugam">Dilli Arumugam</assignee>
                                    <reporter username="darumugam">Dilli Arumugam</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 20:14:51 +0000</created>
                <updated>Thu, 23 Jan 2014 23:27:20 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13877813" author="darumugam" created="Tue, 21 Jan 2014 20:19:33 +0000"  >&lt;p&gt;The patch(diff) that fixes the problem:&lt;/p&gt;

&lt;p&gt;svn diff&lt;br/&gt;
Index: src/main/java/org/apache/hadoop/security/LdapGroupsMapping.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/hadoop/security/LdapGroupsMapping.java	(revision 1560166)&lt;br/&gt;
+++ src/main/java/org/apache/hadoop/security/LdapGroupsMapping.java	(working copy)&lt;br/&gt;
@@ -356,7 +356,7 @@&lt;br/&gt;
         c = reader.read();&lt;br/&gt;
       }&lt;br/&gt;
       reader.close();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return password.toString();&lt;br/&gt;
+      return password.toString().trim();&lt;br/&gt;
     } catch (IOException ioe) 
{
       throw new RuntimeException(&quot;Could not read password file: &quot; + pwFile, ioe);
     }&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13879491" author="sureshms" created="Thu, 23 Jan 2014 06:31:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=darumugam&quot; class=&quot;user-hover&quot; rel=&quot;darumugam&quot;&gt;Dilli Arumugam&lt;/a&gt;, please post the above diff as a patch. I am +1 on the change. Once Jenkins +1s the patch, I will commit it.&lt;/p&gt;</comment>
                            <comment id="13880506" author="darumugam" created="Thu, 23 Jan 2014 23:27:20 +0000"  >&lt;p&gt;patch to resolve the problem&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624949" name="HADOOP-10249.patch" size="697" author="darumugam" created="Thu, 23 Jan 2014 23:27:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Jan 2014 06:31:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369064</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369065</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10248] Property name should be included in the exception where property value is null</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10248</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;I saw the following when trying to determine startup failure:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2014-01-21 06:07:17,871 FATAL [master:h2-centos6-uns-1390276854-hbase-10:60000] master.HMaster: Unhandled exception. Starting shutdown.
java.lang.IllegalArgumentException: Property value must not be &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:92)
at org.apache.hadoop.conf.Configuration.set(Configuration.java:958)
at org.apache.hadoop.conf.Configuration.set(Configuration.java:940)
at org.apache.hadoop.http.HttpServer.initializeWebServer(HttpServer.java:510)
at org.apache.hadoop.http.HttpServer.&amp;lt;init&amp;gt;(HttpServer.java:470)
at org.apache.hadoop.http.HttpServer.&amp;lt;init&amp;gt;(HttpServer.java:458)
at org.apache.hadoop.http.HttpServer.&amp;lt;init&amp;gt;(HttpServer.java:412)
at org.apache.hadoop.hbase.util.InfoServer.&amp;lt;init&amp;gt;(InfoServer.java:59)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Property name should be included in the following exception:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    Preconditions.checkArgument(
        value != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;,
        &lt;span class=&quot;code-quote&quot;&gt;&quot;Property value must not be &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12690096">HADOOP-10248</key>
            <summary>Property name should be included in the exception where property value is null</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ajisakaa">Akira AJISAKA</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Tue, 21 Jan 2014 19:35:27 +0000</created>
                <updated>Sat, 25 Jan 2014 13:38:06 +0000</updated>
                            <resolved>Fri, 24 Jan 2014 06:30:46 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13878108" author="ajisakaa" created="Wed, 22 Jan 2014 01:17:58 +0000"  >&lt;p&gt;Attaching a patch.&lt;/p&gt;</comment>
                            <comment id="13878120" author="yuzhihong@gmail.com" created="Wed, 22 Jan 2014 01:30:15 +0000"  >&lt;p&gt;Thanks for the patch. &lt;/p&gt;</comment>
                            <comment id="13878144" author="hadoopqa" created="Wed, 22 Jan 2014 01:55:10 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624249/HADOOP-10248.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624249/HADOOP-10248.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3451//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3451//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3451//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3451//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13878433" author="ajisakaa" created="Wed, 22 Jan 2014 09:09:28 +0000"  >&lt;p&gt;Added test to verify error messages.&lt;/p&gt;</comment>
                            <comment id="13878480" author="hadoopqa" created="Wed, 22 Jan 2014 10:04:58 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624307/HADOOP-10248.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624307/HADOOP-10248.2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3455//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3455//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3455//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3455//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13880076" author="umamaheswararao" created="Thu, 23 Jan 2014 16:59:52 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13880763" author="umamaheswararao" created="Fri, 24 Jan 2014 06:30:46 +0000"  >&lt;p&gt;Thanks Ted, for filing an issue. &lt;br/&gt;
Thanks a lot, Akira for the patch. I have just committed this to trunk and branch-2&lt;/p&gt;</comment>
                            <comment id="13881680" author="hudson" created="Sat, 25 Jan 2014 05:48:17 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5036 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5036/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5036/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10248&quot; title=&quot;Property name should be included in the exception where property value is null&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10248&quot;&gt;&lt;del&gt;HADOOP-10248&lt;/del&gt;&lt;/a&gt;. Property name should be included in the exception where property value is null. Contributed by Akira AJISAKA. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881841" author="hudson" created="Sat, 25 Jan 2014 12:27:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #461 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10248&quot; title=&quot;Property name should be included in the exception where property value is null&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10248&quot;&gt;&lt;del&gt;HADOOP-10248&lt;/del&gt;&lt;/a&gt;. Property name should be included in the exception where property value is null. Contributed by Akira AJISAKA. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881868" author="hudson" created="Sat, 25 Jan 2014 13:27:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1678 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10248&quot; title=&quot;Property name should be included in the exception where property value is null&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10248&quot;&gt;&lt;del&gt;HADOOP-10248&lt;/del&gt;&lt;/a&gt;. Property name should be included in the exception where property value is null. Contributed by Akira AJISAKA. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881886" author="hudson" created="Sat, 25 Jan 2014 13:38:06 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1653 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10248&quot; title=&quot;Property name should be included in the exception where property value is null&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10248&quot;&gt;&lt;del&gt;HADOOP-10248&lt;/del&gt;&lt;/a&gt;. Property name should be included in the exception where property value is null. Contributed by Akira AJISAKA. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560906&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624307" name="HADOOP-10248.2.patch" size="1946" author="ajisakaa" created="Wed, 22 Jan 2014 09:09:28 +0000"/>
                            <attachment id="12624249" name="HADOOP-10248.patch" size="850" author="ajisakaa" created="Wed, 22 Jan 2014 01:17:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 01:17:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369058</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369059</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10247] FsShell -ls -R output misaligned if child path has longer string representation than parent.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10247</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;When running a recursive ls, like &lt;tt&gt;hdfs dfs -ls -R /&lt;/tt&gt;, the column formatting becomes misaligned if there is a child path with a longer string representation (such as caused by a longer username) compared to its parent.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690091">HADOOP-10247</key>
            <summary>FsShell -ls -R output misaligned if child path has longer string representation than parent.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 19:29:56 +0000</created>
                <updated>Wed, 22 Jan 2014 22:51:36 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13877777" author="cnauroth" created="Tue, 21 Jan 2014 19:37:03 +0000"  >&lt;p&gt;See below for sample output that demonstrates the problem.  The reason for this is that &lt;tt&gt;Ls#adjustColumnWidths&lt;/tt&gt; executes separately for each recursion down the tree via the base &lt;tt&gt;Command&lt;/tt&gt; class.  Therefore, it can calculate the max lengths and readjust only for the subset of paths that it encounters within that recursion.  If it encounters a larger max length lower down in the tree, then it&apos;s too late to adjust for the paths higher in the tree that were already printed.&lt;/p&gt;

&lt;p&gt;I don&apos;t see an obvious way to fix this completely.  I don&apos;t think we can iterate through all paths recursively to get a more accurate max length calculation, because that would require holding the whole tree in memory on the client side.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[chris@Chriss-MacBook-Pro:ttys003] hadoop-deploy-HDFS-4685                                                          
&amp;gt; hadoop-3.0.0-SNAPSHOT/bin/hdfs dfs -ls -R /
drwxr-xr-x   - chris supergroup          0 2014-01-18 08:50 /dir1
-rw-r--r--   3 chris        supergroup          6 2014-01-18 08:50 /dir1/file1
-rw-r--r--   3 longusername supergroup          6 2014-01-18 08:50 /dir1/file2
drwxr-xr-x   - chris        supergroup          0 2014-01-18 08:50 /dir2
-rwxrwxrwt   3 chris        supergroup          6 2014-01-19 10:56 /file3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13879309" author="andrew.wang" created="Wed, 22 Jan 2014 22:51:36 +0000"  >&lt;p&gt;Yea, I agree with your analysis Chris. I think this is why (at least on my machine) &lt;tt&gt;ls -lR&lt;/tt&gt; prints directory-by-directory, so it can align one directory at a time. I guess we could change it to the per-dir format, but that&apos;s probably incompatible, and we&apos;d need a little more effort yet if the shell is using the batched listing API.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12689649">HADOOP-10241</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 22:51:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369053</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369054</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10246] define FS permissions model with tests</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10246</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;It&apos;s interesting that HDFS mkdirs(dir, permission) uses the umask, but setPermissions() does not&lt;/p&gt;

&lt;p&gt;The permissions model, including umask logic should be defined and have tests implemented by those filesystems that support permissions-based security&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690040">HADOOP-10246</key>
            <summary>define FS permissions model with tests</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12635325">HADOOP-9361</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stevel@apache.org">Steve Loughran</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 15:47:06 +0000</created>
                <updated>Fri, 24 Jan 2014 22:12:38 +0000</updated>
                                                                            <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13881474" author="cmccabe" created="Fri, 24 Jan 2014 22:11:23 +0000"  >&lt;p&gt;I agree that we should have more tests for this.  However, the current behavior seems correct to me.  It&apos;s modelled closely on the traditional POSIX behavior, where &lt;tt&gt;mkdir&lt;/tt&gt; honors &lt;tt&gt;umask&lt;/tt&gt;, but &lt;tt&gt;chmod&lt;/tt&gt; does not.  Anything else would be surprising for users coming from traditional filesystems.&lt;/p&gt;

&lt;p&gt;Another reason for the current behavior is that if  &lt;tt&gt;chmod&lt;/tt&gt; consulted &lt;tt&gt;umask&lt;/tt&gt;, there would be no way for users to set less restrictive permissions than specified in &lt;tt&gt;umask&lt;/tt&gt;.  This is contrary to the purpose of &lt;tt&gt;umask&lt;/tt&gt;, which is just to be a helpful default, not a hard constraint.&lt;/p&gt;</comment>
                            <comment id="13881476" author="cmccabe" created="Fri, 24 Jan 2014 22:12:38 +0000"  >&lt;p&gt;when referring to &quot;HDFS&apos;s &lt;tt&gt;chmod&lt;/tt&gt;&quot; I mean &lt;tt&gt;setPermissions&lt;/tt&gt; in HDFS, of course&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jan 2014 22:11:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369002</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369003</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10245] Hadoop command line always appends &quot;-Xmx&quot; option twice</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10245</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The Hadoop command line scripts (hadoop.sh or hadoop.cmd) will call java with &quot;-Xmx&quot; options twice. The impact is that any user defined HADOOP_HEAP_SIZE env variable will take no effect because it is overwritten by the second &quot;-Xmx&quot; option.&lt;/p&gt;

&lt;p&gt;For example, here is the java cmd generated for command &quot;hadoop fs -ls /&quot;, Notice that there are two &quot;-Xmx&quot; options: &quot;-Xmx1000m&quot; and &quot;-Xmx512m&quot; in the command line:&lt;/p&gt;

&lt;p&gt;java -Xmx1000m  -Dhadoop.log.dir=C:\tmp\logs -Dhadoop.log.file=hadoop.log -Dhadoop.root.logger=INFO,c&lt;br/&gt;
onsole,DRFA -Xmx512m  -Dhadoop.security.logger=INFO,RFAS -classpath XXX org.apache.hadoop.fs.FsShell -ls /&lt;/p&gt;

&lt;p&gt;Here is the root cause:&lt;br/&gt;
The call flow is: hadoop.sh calls hadoop_config.sh, which in turn calls hadoop-env.sh. &lt;br/&gt;
In hadoop.sh, the command line is generated by the following pseudo code:&lt;br/&gt;
java $JAVA_HEAP_MAX $HADOOP_CLIENT_OPTS -classpath ...&lt;/p&gt;

&lt;p&gt;In hadoop-config.sh, $JAVA_HEAP_MAX is initialized as &quot;-Xmx1000m&quot; if user didn&apos;t set $HADOOP_HEAP_SIZE env variable.&lt;/p&gt;

&lt;p&gt;In hadoop-env.sh, $HADOOP_CLIENT_OPTS is set as this:&lt;br/&gt;
export HADOOP_CLIENT_OPTS=&quot;-Xmx512m $HADOOP_CLIENT_OPTS&quot;&lt;/p&gt;

&lt;p&gt;To fix this problem, we should remove the &quot;-Xmx512m&quot; from HADOOP_CLIENT_OPTS. If we really want to change the memory settings we need to use $HADOOP_HEAP_SIZE env variable.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689912">HADOOP-10245</key>
            <summary>Hadoop command line always appends &quot;-Xmx&quot; option twice</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="shanyu">shanyu zhao</assignee>
                                    <reporter username="shanyu">shanyu zhao</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Jan 2014 23:30:19 +0000</created>
                <updated>Fri, 24 Jan 2014 15:41:19 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>bin</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13877002" author="ywskycn" created="Mon, 20 Jan 2014 23:59:20 +0000"  >&lt;p&gt;Hey, shanyu. Is this one related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9870&quot; title=&quot;Mixed configurations for JVM -Xmx in hadoop command&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9870&quot;&gt;HADOOP-9870&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13877017" author="hadoopqa" created="Tue, 21 Jan 2014 00:16:33 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624030/HADOOP-10245.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624030/HADOOP-10245.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3449//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3449//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3449//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3449//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13877068" author="shanyu" created="Tue, 21 Jan 2014 01:21:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ywskycn&quot; class=&quot;user-hover&quot; rel=&quot;ywskycn&quot;&gt;Wei Yan&lt;/a&gt; yes, it is the same issue. Sorry I didn&apos;t see &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9870&quot; title=&quot;Mixed configurations for JVM -Xmx in hadoop command&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9870&quot;&gt;HADOOP-9870&lt;/a&gt; before I submit this one. I also found similar JIRAs &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9211&quot; title=&quot;HADOOP_CLIENT_OPTS default setting fixes max heap size at 128m, disregards HADOOP_HEAPSIZE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9211&quot;&gt;&lt;del&gt;HADOOP-9211&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5087&quot; title=&quot;Allowing specific JAVA heap max setting for HDFS related services&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5087&quot;&gt;HDFS-5087&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I went through these JIRAs and here are my thoughts:&lt;br/&gt;
We should only rely on $HADOOP_HEAPSIZE to control Java heap size, instead of $HADOOP_CLIENT_OPTS. Otherwise it would be very confusing and hard to debug issues. And I&apos;ve seen many real world issues caused by this confusion.&lt;/p&gt;

&lt;p&gt;There are arguments that $HADOOP_HEAPSIZE is only for service, and client should have its own settings. Well, we could create HADOOP_CLIENT_HEAPSIZE which is initialized to 512m and used in hadoop.sh. But personally I think it does not worth it to add this new env variable. The client can just simply use $HADOOP_HEAPSIZE which defaults to 1000m. Also, there are scenarios that a java class executed by &quot;hadoop jar&quot; command has a large memory requirements. A real world example: Hive&apos;s MapredLocalTask calls &quot;hadoop jar&quot; to build a local hash table.&lt;/p&gt;

&lt;p&gt;Also, if there&apos;s a need to change the heapsize, one can always set env variable $HADOOP_HEAPSIZE.&lt;/p&gt;</comment>
                            <comment id="13877774" author="shanyu" created="Tue, 21 Jan 2014 19:31:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=drankye&quot; class=&quot;user-hover&quot; rel=&quot;drankye&quot;&gt;Kai Zheng&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=qwertymaniac&quot; class=&quot;user-hover&quot; rel=&quot;qwertymaniac&quot;&gt;Harsh J&lt;/a&gt; would you please help review this patch?&lt;/p&gt;</comment>
                            <comment id="13877837" author="ywskycn" created="Tue, 21 Jan 2014 20:44:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shanyu&quot; class=&quot;user-hover&quot; rel=&quot;shanyu&quot;&gt;shanyu zhao&lt;/a&gt;, as discussed, there are multiple places configuring -Xmx. In the lastest patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9870&quot; title=&quot;Mixed configurations for JVM -Xmx in hadoop command&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9870&quot;&gt;HADOOP-9870&lt;/a&gt; provided by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jhsenjaliya&quot; class=&quot;user-hover&quot; rel=&quot;jhsenjaliya&quot;&gt;Jayesh&lt;/a&gt;, $HADOOP_HEAPSIZE is checked firstly; if not set, assign -Xmx512m. Additionally, in bin/hadoop, also check the -Xmx configuration, to avoid duplicate configurations.&lt;br/&gt;
Simply remove -Xmx512m from HADOOP_CLIENT_OPTS may still generate multiple -Xmx, as bin/hadoop also has a default $JAVA_HEAP_MAX, which is 1000m.&lt;br/&gt;
IMO, I think &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9870&quot; title=&quot;Mixed configurations for JVM -Xmx in hadoop command&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9870&quot;&gt;HADOOP-9870&lt;/a&gt; has fixed this issue.&lt;/p&gt;</comment>
                            <comment id="13877905" author="shanyu" created="Tue, 21 Jan 2014 22:01:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ywskycn&quot; class=&quot;user-hover&quot; rel=&quot;ywskycn&quot;&gt;Wei Yan&lt;/a&gt; Thank you for your comment! If we remove -Xmx512m from HADOOP_CLIENT_OPTS in hadoop_env.cmd, there will be one and only one -Xmx, which is the $JAVA_HEAP_MAX in bin/hadoop. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9870&quot; title=&quot;Mixed configurations for JVM -Xmx in hadoop command&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9870&quot;&gt;HADOOP-9870&lt;/a&gt; may have solved the problem for you, but I think the fix in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9870&quot; title=&quot;Mixed configurations for JVM -Xmx in hadoop command&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9870&quot;&gt;HADOOP-9870&lt;/a&gt; might be too complicated and hard to maintain. For example, what about user use &quot;-Xmx&quot; in HADOOP_OPTS instead of HADOOP_CLIENT_OPTS? I think we should avoid using HADOOP_CLIENT_OPTS or HADOOP_OPTS to specify memory, because the fact that we&apos;ve defined HADOOP_HEAPSIZE but not using it for memory specification is confusing. If you want to change heap size, just change HADOOP_HEAPSIZE, I think this is simple and clear. Thoughts?&lt;/p&gt;</comment>
                            <comment id="13881057" author="ywskycn" created="Fri, 24 Jan 2014 15:41:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shanyu&quot; class=&quot;user-hover&quot; rel=&quot;shanyu&quot;&gt;shanyu zhao&lt;/a&gt;, sorry for the late reply. So you mean we only let users specify -Xmx through $JAVA_HEAP_MAX?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624030" name="HADOOP-10245.patch" size="1808" author="shanyu" created="Mon, 20 Jan 2014 23:37:36 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 20 Jan 2014 23:59:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368883</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368884</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10244] TestKeyShell improperly tests the results of a Delete</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10244</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The TestKeyShell.testKeySuccessfulKeyLifecycle test is supposed to ensure that the deleted key is no longer in the results of a subsequent delete command. Mistakenly, it is testing that it is STILL there.&lt;/p&gt;

&lt;p&gt;The delete command is actually working but the stdout capture should be reset instead of flushed. Therefore, the test is picking up the existence of the key name from the deletion message in the previous command.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689877">HADOOP-10244</key>
            <summary>TestKeyShell improperly tests the results of a Delete</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="lmccay">Larry McCay</assignee>
                                    <reporter username="lmccay">Larry McCay</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Jan 2014 20:22:47 +0000</created>
                <updated>Mon, 20 Jan 2014 21:14:39 +0000</updated>
                                                                            <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13876838" author="lmccay" created="Mon, 20 Jan 2014 20:33:48 +0000"  >&lt;p&gt;Fix TestKeyShell test.&lt;/p&gt;</comment>
                            <comment id="13876839" author="lmccay" created="Mon, 20 Jan 2014 20:35:04 +0000"  >&lt;p&gt;Fix of inappropriate test of delete functionality. Changed the use of flush to reset and test that the deleted keyName is expected to NOT be in the list output after a delete.&lt;/p&gt;</comment>
                            <comment id="13876857" author="hadoopqa" created="Mon, 20 Jan 2014 21:14:39 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624011/10244.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624011/10244.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3448//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3448//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3448//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3448//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624011" name="10244.patch" size="2656" author="lmccay" created="Mon, 20 Jan 2014 20:33:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 20 Jan 2014 21:14:39 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368848</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368849</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fix of inappropriate test of delete functionality.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10242] No space in an error output message</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10242</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;nzhdusr@nhga0007 ~&amp;#93;&lt;/span&gt;$ hadoop job -history ~/1&lt;br/&gt;
Exception in thread &quot;main&quot; java.io.IOException: Not able to initialize History viewer&lt;br/&gt;
	at org.apache.hadoop.mapred.HistoryViewer.&amp;lt;init&amp;gt;(HistoryViewer.java:95)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobClient.viewHistory(JobClient.java:1917)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobClient.run(JobClient.java:1866)&lt;br/&gt;
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)&lt;br/&gt;
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobClient.main(JobClient.java:2123)&lt;br/&gt;
Caused by: java.io.IOException: History directory /home/nzhdusr/1/_logs/historydoes not exist&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689768">HADOOP-10242</key>
            <summary>No space in an error output message</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="sicness">Anton Balashov</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Jan 2014 05:59:01 +0000</created>
                <updated>Mon, 20 Jan 2014 05:59:01 +0000</updated>
                                            <version>1.3.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368740</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368741</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12324327</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10241] Clean up output of FsShell getfacl.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10241</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;This patch will clean up a few formatting issues in the output of the getfacl command:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Currently, the file name is output as the full URI with &quot;hdfs&quot; scheme.  We&apos;ll change this to print just the path portion for consistency with other shell commands like ls.&lt;/li&gt;
	&lt;li&gt;Print a blank line after printing an ACL.  Linux getfacl does this.  It&apos;s particularly helpful with getfacl -R, so that you get a visual indicator in between each returned ACL.&lt;/li&gt;
	&lt;li&gt;The &apos;+&apos; indicator appended to the permissions when the ACL bit is on throws off the nicely aligned table formatting of ls.&lt;/li&gt;
&lt;/ol&gt;
</description>
                <environment></environment>
        <key id="12689649">HADOOP-10241</key>
            <summary>Clean up output of FsShell getfacl.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Sat, 18 Jan 2014 17:34:04 +0000</created>
                <updated>Tue, 21 Jan 2014 21:21:05 +0000</updated>
                            <resolved>Tue, 21 Jan 2014 21:21:05 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13875703" author="cnauroth" created="Sat, 18 Jan 2014 17:35:08 +0000"  >&lt;p&gt;I have a patch in progress, so I&apos;m assigning this to myself.&lt;/p&gt;</comment>
                            <comment id="13877795" author="cnauroth" created="Tue, 21 Jan 2014 20:00:44 +0000"  >&lt;p&gt;I&apos;m attaching the patch.  Summary:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;getfacl now uses &lt;tt&gt;PathData#toString&lt;/tt&gt; so that it prints either the path&apos;s full URI or just the path, depending on whether the user called the command with a full URI or just path.  This behavior is consistent with other commands like ls.&lt;/li&gt;
	&lt;li&gt;getfacl now prints a blank line after every path&apos;s ACL.&lt;/li&gt;
	&lt;li&gt;The column formatting of ls now considers the possibility of an extra &apos;+&apos; character on the end of the permission string to calculate padding.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;There are no tests in this patch, because &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vinayrpet&quot; class=&quot;user-hover&quot; rel=&quot;vinayrpet&quot;&gt;Vinay&lt;/a&gt; plans to add a comprehensive test suite for the new ACL CLI commands in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5702&quot; title=&quot;FsShell Cli: Add XML based End-to-End test for getfacl and setfacl commands&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5702&quot;&gt;&lt;del&gt;HDFS-5702&lt;/del&gt;&lt;/a&gt;.  For now, I tested the changes manually by building a distro from the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; branch.  I also ran &lt;tt&gt;TestCLI&lt;/tt&gt; and &lt;tt&gt;TestHDFSCLI&lt;/tt&gt; to verify that there are no regressions.&lt;/p&gt;

&lt;p&gt;While working on this, I discovered an existing bug in the column formatting for recursive ls.  That&apos;s a trunk bug, so I&apos;m not going to attempt to fix it here.  Instead, I reported the bug in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10247&quot; title=&quot;FsShell -ls -R output misaligned if child path has longer string representation than parent.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10247&quot;&gt;HADOOP-10247&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13877848" author="wheat9" created="Tue, 21 Jan 2014 20:57:03 +0000"  >&lt;p&gt;+1. I&apos;ll commit it shortly.&lt;/p&gt;</comment>
                            <comment id="13877867" author="wheat9" created="Tue, 21 Jan 2014 21:21:05 +0000"  >&lt;p&gt;I&apos;ve committed the patch. Thanks Chris for the contribution.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12686502">HDFS-5702</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12690091">HADOOP-10247</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12686476">HADOOP-10184</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624185" name="HADOOP-10241.1.patch" size="2759" author="cnauroth" created="Tue, 21 Jan 2014 20:00:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 21 Jan 2014 20:57:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368621</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368622</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325672</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10240] Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10240</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;When we upgraded to protoc 2.5.0, we updated BUILDING.txt to state the new requirement.  However, there is another section of the document for Windows builds, and that section still lists version 2.4.1.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689560">HADOOP-10240</key>
            <summary>Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Jan 2014 19:57:15 +0000</created>
                <updated>Sat, 18 Jan 2014 13:27:06 +0000</updated>
                            <resolved>Fri, 17 Jan 2014 23:33:00 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13875205" author="cnauroth" created="Fri, 17 Jan 2014 19:58:52 +0000"  >&lt;p&gt;This patch changes the doc to state 2.5.0.  I also reordered the requirements so that this section reads more consistently with the Linux section at the top of the doc.&lt;/p&gt;</comment>
                            <comment id="13875260" author="hadoopqa" created="Fri, 17 Jan 2014 21:13:01 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623719/HADOOP-10240.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623719/HADOOP-10240.1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+0 tests included&lt;/font&gt;.  The patch appears to be a documentation patch that doesn&apos;t require tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3443//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3443//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3443//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3443//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13875279" author="arpitagarwal" created="Fri, 17 Jan 2014 21:31:17 +0000"  >&lt;p&gt;+1 for the patch. Thanks Chris.&lt;/p&gt;</comment>
                            <comment id="13875395" author="cnauroth" created="Fri, 17 Jan 2014 23:33:00 +0000"  >&lt;p&gt;Thanks for the review, Arpit.  I committed this to trunk, branch-2 and branch-2.3.&lt;/p&gt;</comment>
                            <comment id="13875397" author="hudson" created="Fri, 17 Jan 2014 23:35:24 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5022 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5022/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5022/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10240&quot; title=&quot;Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10240&quot;&gt;&lt;del&gt;HADOOP-10240&lt;/del&gt;&lt;/a&gt;. Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/BUILDING.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875621" author="hudson" created="Sat, 18 Jan 2014 11:08:49 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #456 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10240&quot; title=&quot;Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10240&quot;&gt;&lt;del&gt;HADOOP-10240&lt;/del&gt;&lt;/a&gt;. Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/BUILDING.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875649" author="hudson" created="Sat, 18 Jan 2014 13:26:07 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1648 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10240&quot; title=&quot;Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10240&quot;&gt;&lt;del&gt;HADOOP-10240&lt;/del&gt;&lt;/a&gt;. Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/BUILDING.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875657" author="hudson" created="Sat, 18 Jan 2014 13:27:06 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1673 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10240&quot; title=&quot;Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10240&quot;&gt;&lt;del&gt;HADOOP-10240&lt;/del&gt;&lt;/a&gt;. Windows build instructions incorrectly state requirement of protoc 2.4.1 instead of 2.5.0. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559278&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/BUILDING.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623719" name="HADOOP-10240.1.patch" size="617" author="cnauroth" created="Fri, 17 Jan 2014 19:58:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 17 Jan 2014 21:13:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368532</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368533</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320357</customfieldvalue>
    <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10239] Add Spark as a related project on the Hadoop page</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10239</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12689443">HADOOP-10239</key>
            <summary>Add Spark as a related project on the Hadoop page</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/task.png">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rxin">Reynold Xin</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Jan 2014 06:57:20 +0000</created>
                <updated>Thu, 23 Jan 2014 19:49:41 +0000</updated>
                            <resolved>Thu, 23 Jan 2014 19:36:23 +0000</resolved>
                                                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13874515" author="rxin" created="Fri, 17 Jan 2014 06:59:13 +0000"  >&lt;p&gt;Patch included.&lt;/p&gt;</comment>
                            <comment id="13874517" author="matei" created="Fri, 17 Jan 2014 07:00:39 +0000"  >&lt;p&gt;Wording looks good to me.&lt;/p&gt;</comment>
                            <comment id="13874572" author="sandyr" created="Fri, 17 Jan 2014 08:44:30 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13874585" author="stevel@apache.org" created="Fri, 17 Jan 2014 09:08:23 +0000"  >&lt;p&gt;This may be an opportunity to create a section of YARN applications listing things that YARN can deploy, on that the basis that this number will grow and grow&lt;/p&gt;</comment>
                            <comment id="13880267" author="sandyr" created="Thu, 23 Jan 2014 19:36:23 +0000"  >&lt;p&gt;Pushed this to the website&lt;/p&gt;</comment>
                            <comment id="13880272" author="matei" created="Thu, 23 Jan 2014 19:39:38 +0000"  >&lt;p&gt;Thanks Sandy!&lt;/p&gt;</comment>
                            <comment id="13880282" author="rxin" created="Thu, 23 Jan 2014 19:49:41 +0000"  >&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623594" name="HADOOP-10239.patch" size="1946" author="rxin" created="Fri, 17 Jan 2014 06:59:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 17 Jan 2014 07:00:39 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368415</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368416</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10238] Decouple the Creation of Key metadata from the creation of a key version</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10238</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Currently, KeyProvider createKey establishes a new key metadata and an initial version of the key. This should be separated such that a key is created and an initial version is then realized through the KeyProvider rollNewVersion method.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689319">HADOOP-10238</key>
            <summary>Decouple the Creation of Key metadata from the creation of a key version</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="lmccay">Larry McCay</assignee>
                                    <reporter username="lmccay">Larry McCay</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 18:50:07 +0000</created>
                <updated>Thu, 16 Jan 2014 18:50:07 +0000</updated>
                                                                            <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368291</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368293</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10237] JavaKeyStoreProvider needs to set keystore permissions properly</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10237</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;In order protect access to the created keystores permissions should initially be set to 700 by the JavaKeyStoreProvider. Subsequent permission changes can then be done using FS.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689318">HADOOP-10237</key>
            <summary>JavaKeyStoreProvider needs to set keystore permissions properly</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="lmccay">Larry McCay</assignee>
                                    <reporter username="lmccay">Larry McCay</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 18:45:03 +0000</created>
                <updated>Thu, 16 Jan 2014 18:45:03 +0000</updated>
                                                                            <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368290</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368292</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10236] Fix typo in o.a.h.ipc.Client#checkResponse</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10236</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;There&apos;s a typo in o.a.h.ipc.Client.java. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Client IDs not matched: local ID=&quot;&lt;/span&gt;
              + StringUtils.byteToHexString(clientId) + &lt;span class=&quot;code-quote&quot;&gt;&quot;, ID in reponse=&quot;&lt;/span&gt;
              + StringUtils.byteToHexString(header.getClientId().toByteArray()));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It should be fixed as follows:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Client IDs not matched: local ID=&quot;&lt;/span&gt;
              + StringUtils.byteToHexString(clientId) + &lt;span class=&quot;code-quote&quot;&gt;&quot;, ID in response=&quot;&lt;/span&gt;
              + StringUtils.byteToHexString(header.getClientId().toByteArray()));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12688910">HADOOP-10236</key>
            <summary>Fix typo in o.a.h.ipc.Client#checkResponse</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ajisakaa">Akira AJISAKA</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Wed, 15 Jan 2014 01:32:40 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:59 +0000</updated>
                            <resolved>Wed, 15 Jan 2014 18:33:13 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13871803" author="ajisakaa" created="Wed, 15 Jan 2014 08:28:57 +0000"  >&lt;p&gt;Attaching a patch.&lt;/p&gt;</comment>
                            <comment id="13871825" author="hadoopqa" created="Wed, 15 Jan 2014 09:06:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623093/HADOOP-10236.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623093/HADOOP-10236.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3435//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3435//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3435//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3435//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13871907" author="ajisakaa" created="Wed, 15 Jan 2014 10:29:24 +0000"  >&lt;p&gt;The patch only fixes a typo, so no new tests are needed.&lt;br/&gt;
In addition, the failed test looks unrelated to the patch.&lt;/p&gt;</comment>
                            <comment id="13872363" author="sureshms" created="Wed, 15 Jan 2014 18:20:54 +0000"  >&lt;p&gt;+1 for the patch.&lt;/p&gt;</comment>
                            <comment id="13872393" author="sureshms" created="Wed, 15 Jan 2014 18:33:13 +0000"  >&lt;p&gt;I have committed the patch to trunk and branch-2. Thank you Akira Ajisaka!&lt;/p&gt;</comment>
                            <comment id="13872395" author="hudson" created="Wed, 15 Jan 2014 18:35:37 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5002 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5002/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5002/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10236&quot; title=&quot;Fix typo in o.a.h.ipc.Client#checkResponse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10236&quot;&gt;&lt;del&gt;HADOOP-10236&lt;/del&gt;&lt;/a&gt;. Fix typo in o.a.h.ipc.Client#checkResponse. Contributed by Akira Ajisaka. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872908" author="ajisakaa" created="Thu, 16 Jan 2014 01:19:26 +0000"  >&lt;p&gt;Thank you for committing, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="13873277" author="hudson" created="Thu, 16 Jan 2014 11:10:20 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #454 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/454/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/454/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10236&quot; title=&quot;Fix typo in o.a.h.ipc.Client#checkResponse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10236&quot;&gt;&lt;del&gt;HADOOP-10236&lt;/del&gt;&lt;/a&gt;. Fix typo in o.a.h.ipc.Client#checkResponse. Contributed by Akira Ajisaka. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873367" author="hudson" created="Thu, 16 Jan 2014 13:27:07 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1671 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1671/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1671/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10236&quot; title=&quot;Fix typo in o.a.h.ipc.Client#checkResponse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10236&quot;&gt;&lt;del&gt;HADOOP-10236&lt;/del&gt;&lt;/a&gt;. Fix typo in o.a.h.ipc.Client#checkResponse. Contributed by Akira Ajisaka. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873389" author="hudson" created="Thu, 16 Jan 2014 13:41:37 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1646 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1646/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1646/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10236&quot; title=&quot;Fix typo in o.a.h.ipc.Client#checkResponse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10236&quot;&gt;&lt;del&gt;HADOOP-10236&lt;/del&gt;&lt;/a&gt;. Fix typo in o.a.h.ipc.Client#checkResponse. Contributed by Akira Ajisaka. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558498&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623093" name="HADOOP-10236.patch" size="909" author="ajisakaa" created="Wed, 15 Jan 2014 08:28:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 Jan 2014 09:06:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367882</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367884</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10235] Hadoop tarball has 2 versions of stax-api JARs</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10235</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;They are:&lt;/p&gt;

&lt;p&gt;stax-api-1.0-2.jar&lt;br/&gt;
stax-api-1.0.2.jar&lt;/p&gt;

&lt;p&gt;Maven cannot resolve them property because they are published under different groupIds, because of that for maven are different things.&lt;/p&gt;

&lt;p&gt;we need to exclude one of them explicitly&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688908">HADOOP-10235</key>
            <summary>Hadoop tarball has 2 versions of stax-api JARs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tucu00">Alejandro Abdelnur</assignee>
                                    <reporter username="tucu00">Alejandro Abdelnur</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 01:13:55 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:59 +0000</updated>
                            <resolved>Fri, 17 Jan 2014 19:31:22 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13873266" author="lewismc" created="Thu, 16 Jan 2014 10:59:02 +0000"  >&lt;p&gt;This should be a simple exclusion in Maven no? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tucu00&quot; class=&quot;user-hover&quot; rel=&quot;tucu00&quot;&gt;Alejandro Abdelnur&lt;/a&gt; are you going to provide a patch? If not then maybe I can look in to it.&lt;/p&gt;</comment>
                            <comment id="13874223" author="tucu00" created="Fri, 17 Jan 2014 00:42:06 +0000"  >&lt;p&gt;patch excluding stax 1.0.1 JAR, 1.0-2 surviving. Reference for the decision of which one: &lt;a href=&quot;https://java.net/jira/browse/JERSEY-769&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://java.net/jira/browse/JERSEY-769&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13874243" author="sandyr" created="Fri, 17 Jan 2014 00:58:45 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13874336" author="hadoopqa" created="Fri, 17 Jan 2014 02:24:56 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623544/HADOOP-10235.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623544/HADOOP-10235.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3438//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3438//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3438//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3438//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13875160" author="tucu00" created="Fri, 17 Jan 2014 19:31:22 +0000"  >&lt;p&gt;Committed to trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13875166" author="hudson" created="Fri, 17 Jan 2014 19:36:26 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5020 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5020/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5020/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10235&quot; title=&quot;Hadoop tarball has 2 versions of stax-api JARs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10235&quot;&gt;&lt;del&gt;HADOOP-10235&lt;/del&gt;&lt;/a&gt;. Hadoop tarball has 2 versions of stax-api JARs. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-project/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875618" author="hudson" created="Sat, 18 Jan 2014 11:08:48 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #456 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10235&quot; title=&quot;Hadoop tarball has 2 versions of stax-api JARs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10235&quot;&gt;&lt;del&gt;HADOOP-10235&lt;/del&gt;&lt;/a&gt;. Hadoop tarball has 2 versions of stax-api JARs. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-project/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875646" author="hudson" created="Sat, 18 Jan 2014 13:26:06 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1648 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10235&quot; title=&quot;Hadoop tarball has 2 versions of stax-api JARs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10235&quot;&gt;&lt;del&gt;HADOOP-10235&lt;/del&gt;&lt;/a&gt;. Hadoop tarball has 2 versions of stax-api JARs. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-project/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875654" author="hudson" created="Sat, 18 Jan 2014 13:27:05 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1673 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10235&quot; title=&quot;Hadoop tarball has 2 versions of stax-api JARs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10235&quot;&gt;&lt;del&gt;HADOOP-10235&lt;/del&gt;&lt;/a&gt;. Hadoop tarball has 2 versions of stax-api JARs. (tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559230&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-project/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623544" name="HADOOP-10235.patch" size="838" author="tucu00" created="Fri, 17 Jan 2014 00:42:06 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 16 Jan 2014 10:59:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367880</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367882</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10234] &quot;hadoop.cmd jar&quot; does not propagate exit code.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10234</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Running &quot;hadoop.cmd jar&quot; does not always propagate the exit code to the caller.  In interactive use, it works fine.  However, in some usages (notably Hive), it gets called through &lt;tt&gt;Shell#getRunScriptCommand&lt;/tt&gt;, which needs to do an intermediate &quot;cmd /c&quot; to execute the script.  In that case, the last exit code is getting dropped, so Hive can&apos;t detect job failures.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688888">HADOOP-10234</key>
            <summary>&quot;hadoop.cmd jar&quot; does not propagate exit code.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 23:44:02 +0000</created>
                <updated>Wed, 15 Jan 2014 13:26:42 +0000</updated>
                            <resolved>Wed, 15 Jan 2014 05:49:45 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>scripts</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13871388" author="cnauroth" created="Tue, 14 Jan 2014 23:47:05 +0000"  >&lt;p&gt;This patch explicitly exits the script with the last returned exit code.  I&apos;ve confirmed that this patch fixes the problem that was seen in Hive.&lt;/p&gt;</comment>
                            <comment id="13871398" author="shanyu" created="Tue, 14 Jan 2014 23:55:47 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;This patch fixed the problem that a Java program starts a process with command line &quot;hadoop.cmd ...&quot; but always read 0 as exit status even if the process failed. Thanks for the fix Chris!&lt;/p&gt;</comment>
                            <comment id="13871405" author="sureshms" created="Wed, 15 Jan 2014 00:03:11 +0000"  >&lt;p&gt;+1 for the patch.&lt;/p&gt;</comment>
                            <comment id="13871407" author="arpitagarwal" created="Wed, 15 Jan 2014 00:04:27 +0000"  >&lt;p&gt;+1 the change looks good. I did not test it myself but it&apos;s a simple enough edit.&lt;/p&gt;</comment>
                            <comment id="13871579" author="hadoopqa" created="Wed, 15 Jan 2014 03:17:20 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623016/HADOOP-10234.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623016/HADOOP-10234.1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3434//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3434//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3434//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3434//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13871676" author="cnauroth" created="Wed, 15 Jan 2014 05:42:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;-1 tests included. The patch doesn&apos;t appear to include any new or modified tests.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This patch covered just a script file, so there wasn&apos;t a way to add a test.  We&apos;ve confirmed that this patch fixes the Hive test failure that made us notice the problem.&lt;/p&gt;

&lt;p&gt;I&apos;ll commit this.&lt;/p&gt;</comment>
                            <comment id="13871681" author="cnauroth" created="Wed, 15 Jan 2014 05:49:45 +0000"  >&lt;p&gt;I committed this to trunk, branch-2 and branch-2.3.  Thank you to Shanyu, Suresh and Arpit for code reviews.&lt;/p&gt;</comment>
                            <comment id="13871687" author="hudson" created="Wed, 15 Jan 2014 05:56:00 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #4998 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/4998/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/4998/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10234&quot; title=&quot;&amp;quot;hadoop.cmd jar&amp;quot; does not propagate exit code.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10234&quot;&gt;&lt;del&gt;HADOOP-10234&lt;/del&gt;&lt;/a&gt;. &quot;hadoop.cmd jar&quot; does not propagate exit code. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop.cmd&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13871930" author="hudson" created="Wed, 15 Jan 2014 11:08:55 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #453 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/453/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/453/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10234&quot; title=&quot;&amp;quot;hadoop.cmd jar&amp;quot; does not propagate exit code.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10234&quot;&gt;&lt;del&gt;HADOOP-10234&lt;/del&gt;&lt;/a&gt;. &quot;hadoop.cmd jar&quot; does not propagate exit code. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop.cmd&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872041" author="hudson" created="Wed, 15 Jan 2014 13:25:31 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1645 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1645/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1645/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10234&quot; title=&quot;&amp;quot;hadoop.cmd jar&amp;quot; does not propagate exit code.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10234&quot;&gt;&lt;del&gt;HADOOP-10234&lt;/del&gt;&lt;/a&gt;. &quot;hadoop.cmd jar&quot; does not propagate exit code. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop.cmd&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872049" author="hudson" created="Wed, 15 Jan 2014 13:26:42 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1670 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1670/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1670/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10234&quot; title=&quot;&amp;quot;hadoop.cmd jar&amp;quot; does not propagate exit code.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10234&quot;&gt;&lt;del&gt;HADOOP-10234&lt;/del&gt;&lt;/a&gt;. &quot;hadoop.cmd jar&quot; does not propagate exit code. Contributed by Chris Nauroth. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558296&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/bin/hadoop.cmd&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623016" name="HADOOP-10234.1.patch" size="538" author="cnauroth" created="Tue, 14 Jan 2014 23:47:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 14 Jan 2014 23:55:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367860</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367862</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320357</customfieldvalue>
    <customfieldvalue>12325254</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10233] RPC lacks output flow control</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10233</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The RPC layer has input flow control via the callq, however it lacks any output flow control.  A handler will try to directly send the response.  If the full response is not sent then it is queued for the background responder thread.  The RPC layer may end up queuing so many buffers that it &quot;locks&quot; up in GC.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688877">HADOOP-10233</key>
            <summary>RPC lacks output flow control</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="daryn">Daryn Sharp</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 22:58:11 +0000</created>
                <updated>Wed, 29 Jan 2014 20:12:34 +0000</updated>
                            <resolved>Wed, 29 Jan 2014 20:12:34 +0000</resolved>
                                    <version>2.0.0-alpha</version>
                    <version>3.0.0</version>
                                                    <component>ipc</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13871337" author="daryn" created="Tue, 14 Jan 2014 23:02:34 +0000"  >&lt;p&gt;Issue was seen when a errant job&apos;s 6k tasks issued listLocatedStatus on a 9k directory.  Each initial response for the 1k entries was ~1.2M.  The full response couldn&apos;t be sent immediately so the response queue held 6G+ of buffers.  The NN went repeatedly went into GC for up to 5m.&lt;/p&gt;</comment>
                            <comment id="13871389" author="jlowe" created="Tue, 14 Jan 2014 23:48:31 +0000"  >&lt;p&gt;Dup of &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8942&quot; title=&quot;Thundering herd of RPCs with large responses leads to OOM&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8942&quot;&gt;HADOOP-8942&lt;/a&gt;?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12612479">HADOOP-8942</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 14 Jan 2014 23:48:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367849</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367851</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320357</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10232] More options to HttpServer Builder</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10232</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;o.a.h.h.HttpServer can can be instanciated and configured:&lt;br/&gt;
1. Via classical constructor&lt;br/&gt;
2. Via static build method&lt;/p&gt;

&lt;p&gt;Those 2 methods don&apos;t populate the same way the (deprecated) hostname and port, nor the jetty Connector.&lt;/p&gt;

&lt;p&gt;This gives issue when using hbase on hadoop3 (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6581&quot; title=&quot;Build with hadoop.profile=3.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6581&quot;&gt;HBASE-6581&lt;/a&gt;)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688548">HADOOP-10232</key>
            <summary>More options to HttpServer Builder</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="eric@apache.org">Eric Charles</reporter>
                        <labels>
                    </labels>
                <created>Mon, 13 Jan 2014 14:47:44 +0000</created>
                <updated>Mon, 27 Jan 2014 20:03:14 +0000</updated>
                            <resolved>Thu, 16 Jan 2014 04:55:11 +0000</resolved>
                                    <version>3.0.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13869587" author="eric@apache.org" created="Mon, 13 Jan 2014 14:49:43 +0000"  >&lt;p&gt;The attached patch fixes the issue for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6581&quot; title=&quot;Build with hadoop.profile=3.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6581&quot;&gt;HBASE-6581&lt;/a&gt; and should not have side-effect on any other HttpServer consumers.&lt;/p&gt;</comment>
                            <comment id="13869877" author="wheat9" created="Mon, 13 Jan 2014 19:41:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=echarles&quot; class=&quot;user-hover&quot; rel=&quot;echarles&quot;&gt;Eric Charles&lt;/a&gt;, the first approach has been deprecated for a while. These methods will be removed from trunk shortly. Can you please fix HBase instead?&lt;/p&gt;</comment>
                            <comment id="13870702" author="eric@apache.org" created="Tue, 14 Jan 2014 13:11:56 +0000"  >&lt;p&gt;Thx &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; for the feedback.&lt;/p&gt;

&lt;p&gt;Although &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10232&quot; title=&quot;More options to HttpServer Builder&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10232&quot;&gt;&lt;del&gt;HDFS-5760&lt;/del&gt;&lt;/a&gt;-1.patch works well for hbase, it breaks hadoop.&lt;/p&gt;

&lt;p&gt;I checked the o.a.h.h.u.InfoServer class, and rather than using inheritance, we could use composition, but we would need additional getters (will submit a patch proposal - see method fixupLogsServletLocation in &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://github.com/apache/hbase/blob/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/InfoServer.java#L68&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hbase/blob/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/util/InfoServer.java#L68&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="13870794" author="eric@apache.org" created="Tue, 14 Jan 2014 15:07:29 +0000"  >&lt;p&gt;Additional accessors and also parameter in the builder to make it more friendly for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10336&quot; title=&quot;Remove deprecated usage of Hadoop HttpServer in InfoServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10336&quot;&gt;HBASE-10336&lt;/a&gt; and any other consumer willing to run with a webapp located somewhere else than the harcoded webapps path.&lt;/p&gt;</comment>
                            <comment id="13870795" author="eric@apache.org" created="Tue, 14 Jan 2014 15:08:03 +0000"  >&lt;p&gt;btw, don&apos;t know why I created under HDFS. This is a common component, so it should be a HADOOP jira.&lt;/p&gt;</comment>
                            <comment id="13870913" author="stack" created="Tue, 14 Jan 2014 17:11:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=echarles&quot; class=&quot;user-hover&quot; rel=&quot;echarles&quot;&gt;Eric Charles&lt;/a&gt; Do you mean &apos;Hadoop Common&apos;?  If so, I can move it there for you if you do not have credential.&lt;/p&gt;

&lt;p&gt;+1 on patch from me.&lt;/p&gt;</comment>
                            <comment id="13870927" author="eric@apache.org" created="Tue, 14 Jan 2014 17:25:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; yes, please move it to Hadoop Common, I don&apos;t have the credentials. Thx.&lt;/p&gt;</comment>
                            <comment id="13870931" author="stack" created="Tue, 14 Jan 2014 17:28:03 +0000"  >&lt;p&gt;Done sir.&lt;/p&gt;</comment>
                            <comment id="13870944" author="eric@apache.org" created="Tue, 14 Jan 2014 17:35:42 +0000"  >&lt;p&gt;That&apos;s cool &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13871248" author="wheat9" created="Tue, 14 Jan 2014 21:48:56 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; webapps = WEBAPPS;
+
+
+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Builder setWebapps(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; webapps) {
+      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.webapps = webapps;
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;;
+    }
+
+  
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; getWebAppsPath(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; appName) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; FileNotFoundException {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; getWebAppsPath(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.webapps, appName);
+  }
 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems to me that it might not be the right fix. We probably should add a new property &lt;tt&gt;appDir&lt;/tt&gt; in the builder and deprecate &lt;tt&gt;name&lt;/tt&gt;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Map&amp;lt;Context, &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;&amp;gt; getDefaultContexts() {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.defaultContexts;
+  }
+
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Server getWebServer() {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.webServer;
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These methods are not supposed to be publicly accessible. Looking at the hbase code, it seems what you want to do is to override the log servlet. If this is the case, calling &lt;tt&gt;addServlet&lt;/tt&gt; on the same path probably can do the trick.&lt;/p&gt;</comment>
                            <comment id="13872117" author="eric@apache.org" created="Wed, 15 Jan 2014 14:26:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10232&quot; title=&quot;More options to HttpServer Builder&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10232&quot;&gt;&lt;del&gt;HADOOP-10232&lt;/del&gt;&lt;/a&gt;-3.patch takes your comments into account. The logDir option is needed for hbase (just adding a servlet is not enough).&lt;/p&gt;</comment>
                            <comment id="13872359" author="stack" created="Wed, 15 Jan 2014 18:18:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=echarles&quot; class=&quot;user-hover&quot; rel=&quot;echarles&quot;&gt;Eric Charles&lt;/a&gt; The +  protected String logDir; is needed for the logs servlet?&lt;/p&gt;

&lt;p&gt;Would your life be easier Mr Eric Charles if we just let go of our use of hadoop&apos;s jetty and servlets (we could copy the few we need local).  Loser coupling, etc.&lt;/p&gt;</comment>
                            <comment id="13872360" author="stack" created="Wed, 15 Jan 2014 18:18:54 +0000"  >&lt;p&gt;Otherwise patch lgtm.&lt;/p&gt;</comment>
                            <comment id="13872379" author="eric@apache.org" created="Wed, 15 Jan 2014 18:27:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; yes, the logDir is needed to do the job of the InfoServer.java#fixupLogsServletLocation. With that logDir conf, hbase&apos;s life is easier than ever &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; But yes, decoupling the hbase-jetty stuff from hadoop may be something to evaluate. but we would have to redevelop around the same, with ssl support... If this jira finally goes to trunk, it will be nice. Also, decoupling can be risky: I already had issues with mixed mortaby (6.x) and eclipe (9.x) environments, so keeping in sync will avoid clashes.&lt;/p&gt;</comment>
                            <comment id="13872392" author="stack" created="Wed, 15 Jan 2014 18:33:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;I already had issues with mixed mortaby (6.x) and eclipe (9.x) environments, so keeping in sync will avoid clashes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm... yeah.  We depend on hadoop and since its poms include the all the jars of the world (caveat &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;Steve Loughran&lt;/a&gt; effort), as a downstreamer, we could run into &apos;interesting&apos; conflcts.   Lets hold with the devil we know as you suggest.&lt;/p&gt;</comment>
                            <comment id="13872428" author="wheat9" created="Wed, 15 Jan 2014 19:00:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would your life be easier Mr Eric Charles if we just let go of our use of hadoop&apos;s jetty and servlets (we could copy the few we need local). Loser coupling, etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 for the decoupling. The class is an internal class, it is never intended to be used outside of HDFS and YARN. You can copy the class to the hbase repository and be done with it.&lt;/p&gt;

&lt;p&gt;In the near term it looks like that we might revisit the implementation of this class and change the API again, so this type of jira might happen over and over again.&lt;/p&gt;</comment>
                            <comment id="13872452" author="eric@apache.org" created="Wed, 15 Jan 2014 19:15:50 +0000"  >&lt;p&gt;Sounds like we can close this and copy the code... No sense to further push if hadoop doesn&apos;t commit to provide the http common services.&lt;br/&gt;
Still waiting one day for any further comment before closing this jira and copying the class.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; between all jars of the world and all the issues of it, the wise man has to choose. Btw, any link on &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;Steve Loughran&lt;/a&gt; effort, wondering if it can help the hbase-shim?&lt;/p&gt;</comment>
                            <comment id="13872487" author="stack" created="Wed, 15 Jan 2014 19:35:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;+1 for the decoupling. The class is an internal class, it is never intended to be used outside of HDFS and YARN...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;From HttpServer class branch-2 (and trunk has the same):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@InterfaceAudience.LimitedPrivate({&lt;span class=&quot;code-quote&quot;&gt;&quot;HDFS&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;MapReduce&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;HBase&quot;&lt;/span&gt;})
@InterfaceStability.Evolving
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class HttpServer &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; FilterContainer {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;HBase has been ordained limited private (YARN is only in the list via proxy).&lt;/p&gt;

&lt;p&gt;If the choice is between this small patch here and an all day maven hell transitive include weeding project down the road &amp;#8211; that may or may not succeed &amp;#8211; I&apos;d vote add this patch now and meantime we&apos;ll work on decoupling (we&apos;ll circle back and remove our selves from the LimitedPrivate list should we prevail).  Thanks.&lt;/p&gt;</comment>
                            <comment id="13872574" author="wheat9" created="Wed, 15 Jan 2014 20:51:53 +0000"  >&lt;p&gt;I added the annotation in 2.2 just to indicate that HBase does use this class. The class does not intend to support users other than HDFS / MapReduce.&lt;/p&gt;

&lt;p&gt;I don&apos;t quite follow the value of putting in this patch right now. Indeed this patch can make Hbase compile against trunk right now, but I believe that the compatibility will be broken pretty soon (at least I plan to revisit this class in near term). Therefore I would suggest to start the work of decoupling the class today.&lt;/p&gt;</comment>
                            <comment id="13872836" author="stack" created="Wed, 15 Jan 2014 23:56:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;I added the annotation in 2.2 just to indicate that HBase does use this class.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If I do git blame, it says I added the annotation, not you.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bfc1e08c src/java/org/apache/hadoop/http/HttpServer.java                                          (Michael Stack           2011-06-02 18:54:40 +0000   93) @InterfaceAudience.LimitedPrivate({&lt;span class=&quot;code-quote&quot;&gt;&quot;HDFS&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;MapReduce&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;HBase&quot;&lt;/span&gt;})
bfc1e08c src/java/org/apache/hadoop/http/HttpServer.java                                          (Michael Stack           2011-06-02 18:54:40 +0000   94) @InterfaceStability.Evolving
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t quite follow the value of putting in this patch right now.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The answer to the above is in your next sentence...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Indeed this patch can make Hbase compile against trunk right now&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;On the below....&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...but I believe that the compatibility will be broken pretty soon (at least I plan to revisit this class in near term).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;... is there a JIRA we can consult where what you are thinking is outlined?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Therefore I would suggest to start the work of decoupling the class today.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Please tell us more what you are thinking regards refactoring.   We&apos;d like to avoid being in a situation where say, we have jetty9 and jetty6 and all their dependencies trying to duke it out on the one downstream CLASSPATH (or poms full of crafted includes/excludes hard won after spending hours figuring what combination &apos;works&apos;).&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
</comment>
                            <comment id="13872878" author="wheat9" created="Thu, 16 Jan 2014 00:38:50 +0000"  >&lt;p&gt;Jetty 6 has been definitely a pain so far. My preliminary plan is to move away from Jetty 6 towards netty. It means a much smaller set of dependency. However, many servlets and the HttpServer has to be revisited.&lt;/p&gt;

&lt;p&gt;In this case it would be almost impossible to maintain any API compatibilities.&lt;/p&gt;</comment>
                            <comment id="13873043" author="eric@apache.org" created="Thu, 16 Jan 2014 04:54:32 +0000"  >&lt;p&gt;Thx git to tell us the truth.&lt;br/&gt;
My 2 cents would be going to jetty9 (spdy, comet, websocket...).&lt;br/&gt;
Netty to develop a webapp would be a pain (no filter. no jsp...) even with their nice HTTP handlers. Keep netty for RPC communication. &lt;br/&gt;
To be discussed on another JIRA, so will close and fork the HTTP part to HBase.&lt;/p&gt;</comment>
                            <comment id="13883217" author="wheat9" created="Mon, 27 Jan 2014 20:03:14 +0000"  >&lt;p&gt;Just for clarification, I confused myself with the annotation that I added for &lt;tt&gt;AbstractDelegationTokenSecretManager&lt;/tt&gt; and the one of &lt;tt&gt;HttpServer&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Sorry for the confusion.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623144" name="HADOOP-10232-3.patch" size="6522" author="eric@apache.org" created="Wed, 15 Jan 2014 14:26:17 +0000"/>
                            <attachment id="12622632" name="HDFS-5760-1.patch" size="1686" author="eric@apache.org" created="Mon, 13 Jan 2014 14:49:43 +0000"/>
                            <attachment id="12622867" name="HDFS-5760-2.patch" size="3904" author="eric@apache.org" created="Tue, 14 Jan 2014 15:07:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 13 Jan 2014 19:41:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367572</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367574</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10231] Add some components in Native Libraries document</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10231</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The documented components in Native Libraries are only zlib and gzip.&lt;br/&gt;
Now Native Libraries includes some other components such as other compression formats (lz4, snappy), libhdfs and fuse module. These components should be documented.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688685">HADOOP-10231</key>
            <summary>Add some components in Native Libraries document</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="ajisakaa">Akira AJISAKA</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Tue, 14 Jan 2014 06:28:54 +0000</created>
                <updated>Mon, 20 Jan 2014 07:37:31 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13876192" author="ajisakaa" created="Mon, 20 Jan 2014 07:01:41 +0000"  >&lt;p&gt;Attaching a patch to add some components of libhadoop.so and a link to libhdfs.so.&lt;/p&gt;</comment>
                            <comment id="13876221" author="hadoopqa" created="Mon, 20 Jan 2014 07:37:31 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623911/HADOOP-10231.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623911/HADOOP-10231.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+0 tests included&lt;/font&gt;.  The patch appears to be a documentation patch that doesn&apos;t require tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3446//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3446//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3446//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3446//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623911" name="HADOOP-10231.patch" size="1370" author="ajisakaa" created="Mon, 20 Jan 2014 07:01:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 20 Jan 2014 07:37:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367709</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367711</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HADOOP-10230] GSetByHashMap breaks contract of GSet</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10230</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The contract of GSet says it is ensured to throw NullPointerException if a given argument is null for many methods, but GSetByHashMap doesn&apos;t. I think just writing non-null preconditions for GSet are required.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688680">HADOOP-10230</key>
            <summary>GSetByHashMap breaks contract of GSet</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ikeda">Hiroshi Ikeda</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 05:14:18 +0000</created>
                <updated>Tue, 14 Jan 2014 05:14:18 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367704</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367706</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10229] DaemonFactory should not extend Daemon</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10229</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The static nested class org.apache.hadoop.util.Daemon.DaemonFactory unnecessarily extends its nesting class Daemon, though a thread factory is not required to be a thread.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688664">HADOOP-10229</key>
            <summary>DaemonFactory should not extend Daemon</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ikeda">Hiroshi Ikeda</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 02:38:46 +0000</created>
                <updated>Tue, 14 Jan 2014 02:38:46 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                    <timeoriginalestimate seconds="300">5m</timeoriginalestimate>
                            <timeestimate seconds="300">5m</timeestimate>
                                                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367688</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367690</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10228] FsPermission#fromShort() should cache FsAction.values()</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10228</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;FsPermission#fromShort() calls FsAction.values() every time, which causes unnecessary performance penalty.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688636">HADOOP-10228</key>
            <summary>FsPermission#fromShort() should cache FsAction.values()</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Mon, 13 Jan 2014 23:43:50 +0000</created>
                <updated>Tue, 28 Jan 2014 23:37:09 +0000</updated>
                            <resolved>Tue, 14 Jan 2014 20:37:29 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13870185" author="hadoopqa" created="Tue, 14 Jan 2014 00:42:08 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622733/HADOOP-10228.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622733/HADOOP-10228.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The following test timeouts occurred in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.http.TestSSLHttpServer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3430//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3430//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3430//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3430//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13870221" author="cnauroth" created="Tue, 14 Jan 2014 01:03:40 +0000"  >&lt;p&gt;+1 for the patch.  Thanks, Haohui.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;-1 tests included. The patch doesn&apos;t appear to include any new or modified tests.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is an internal change, so there isn&apos;t a meaningful way to add a new unit test that demonstrates it.  The existing tests in &lt;tt&gt;TestFsPermission&lt;/tt&gt; cover the logic and protect against regressions.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;-1 core tests. The following test timeouts occurred in hadoop-common-project/hadoop-common:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t see how this could be related.  I applied the patch locally and ran the test successfully.&lt;/p&gt;</comment>
                            <comment id="13871111" author="cnauroth" created="Tue, 14 Jan 2014 20:37:29 +0000"  >&lt;p&gt;I committed this to trunk and branch-2.  Haohui, thank you for contributing this patch.&lt;/p&gt;</comment>
                            <comment id="13871934" author="hudson" created="Wed, 15 Jan 2014 11:08:55 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #453 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/453/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/453/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10228&quot; title=&quot;FsPermission#fromShort() should cache FsAction.values()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10228&quot;&gt;&lt;del&gt;HADOOP-10228&lt;/del&gt;&lt;/a&gt;. FsPermission#fromShort() should cache FsAction.values(). Contributed by Haohui Mai. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558139&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558139&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/permission/FsPermission.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872045" author="hudson" created="Wed, 15 Jan 2014 13:25:32 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1645 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1645/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1645/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10228&quot; title=&quot;FsPermission#fromShort() should cache FsAction.values()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10228&quot;&gt;&lt;del&gt;HADOOP-10228&lt;/del&gt;&lt;/a&gt;. FsPermission#fromShort() should cache FsAction.values(). Contributed by Haohui Mai. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558139&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558139&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/permission/FsPermission.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13872053" author="hudson" created="Wed, 15 Jan 2014 13:26:42 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1670 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1670/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1670/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10228&quot; title=&quot;FsPermission#fromShort() should cache FsAction.values()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10228&quot;&gt;&lt;del&gt;HADOOP-10228&lt;/del&gt;&lt;/a&gt;. FsPermission#fromShort() should cache FsAction.values(). Contributed by Haohui Mai. (cnauroth: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558139&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558139&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/permission/FsPermission.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12622733" name="HADOOP-10228.000.patch" size="1080" author="wheat9" created="Mon, 13 Jan 2014 23:46:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 14 Jan 2014 00:42:08 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367660</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367662</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320357</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10227] IPC shutdown hangs if remote connection not reachable</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10227</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;If the remote HDFS namenode isn&apos;t reachable, and an attempt to shut down the JVM is made, the process will keep running&lt;/p&gt;</description>
                <environment>&lt;p&gt;OS/X Java7&lt;/p&gt;</environment>
        <key id="12688468">HADOOP-10227</key>
            <summary>IPC shutdown hangs if remote connection not reachable</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stevel@apache.org">Steve Loughran</reporter>
                        <labels>
                    </labels>
                <created>Sun, 12 Jan 2014 21:19:37 +0000</created>
                <updated>Sun, 12 Jan 2014 21:26:15 +0000</updated>
                            <resolved>Sun, 12 Jan 2014 21:26:15 +0000</resolved>
                                    <version>2.2.0</version>
                                                    <component>ipc</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13869150" author="stevel@apache.org" created="Sun, 12 Jan 2014 21:20:03 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-0&quot;&lt;/span&gt; prio=5 tid=0x00007fb05a077000 nid=0x5d0f waiting on condition [0x0000000116565000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: TIMED_WAITING (sleeping)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(Native Method)
	at org.apache.hadoop.ipc.Client.stop(Client.java:1173)
	at org.apache.hadoop.ipc.ClientCache.stopClient(ClientCache.java:100)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.close(ProtobufRpcEngine.java:251)
	at org.apache.hadoop.ipc.RPC.stopProxy(RPC.java:626)
	at org.apache.hadoop.io.retry.DefaultFailoverProxyProvider.close(DefaultFailoverProxyProvider.java:57)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.close(RetryInvocationHandler.java:206)
	at org.apache.hadoop.ipc.RPC.stopProxy(RPC.java:626)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.close(ClientNamenodeProtocolTranslatorPB.java:174)
	at org.apache.hadoop.ipc.RPC.stopProxy(RPC.java:621)
	at org.apache.hadoop.hdfs.DFSClient.closeConnectionToNamenode(DFSClient.java:738)
	at org.apache.hadoop.hdfs.DFSClient.close(DFSClient.java:794)
	- locked &amp;lt;0x00000007fec77980&amp;gt; (a org.apache.hadoop.hdfs.DFSClient)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:847)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2524)
	- locked &amp;lt;0x00000007fec76600&amp;gt; (a org.apache.hadoop.fs.FileSystem$Cache)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2541)
	- locked &amp;lt;0x00000007fec76618&amp;gt; (a org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)

&lt;span class=&quot;code-quote&quot;&gt;&quot;SIGINT handler&quot;&lt;/span&gt; daemon prio=5 tid=0x00007fb0588f7000 nid=0x440f in &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait() [0x00000001138bb000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: WAITING (on object monitor)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(Native Method)
	- waiting on &amp;lt;0x00000007fed3d2c8&amp;gt; (a org.apache.hadoop.util.ShutdownHookManager$1)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.join(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:1280)
	- locked &amp;lt;0x00000007fed3d2c8&amp;gt; (a org.apache.hadoop.util.ShutdownHookManager$1)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.join(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:1354)
	at java.lang.ApplicationShutdownHooks.runHooks(ApplicationShutdownHooks.java:106)
	at java.lang.ApplicationShutdownHooks$1.run(ApplicationShutdownHooks.java:46)
	at java.lang.Shutdown.runHooks(Shutdown.java:123)
	at java.lang.Shutdown.sequence(Shutdown.java:167)
	at java.lang.Shutdown.exit(Shutdown.java:212)
	- locked &amp;lt;0x00000007fed5dfe8&amp;gt; (a java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; java.lang.Shutdown)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt;.exit(&lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt;.java:109)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.exit(&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.java:962)
	at org.apache.hadoop.util.ExitUtil.terminate(ExitUtil.java:133)
	at org.apache.hadoop.yarn.service.launcher.ServiceLauncher.exit(ServiceLauncher.java:279)
	at org.apache.hadoop.yarn.service.launcher.ServiceLauncher.interrupted(ServiceLauncher.java:266)
	at org.apache.hadoop.yarn.service.launcher.IrqHandler.handle(IrqHandler.java:70)
	at sun.misc.Signal$1.run(Signal.java:212)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)

&lt;span class=&quot;code-quote&quot;&gt;&quot;Service &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;&quot;&lt;/span&gt; daemon prio=5 tid=0x00007fb059011000 nid=0x5303 runnable [0x0000000000000000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE

&lt;span class=&quot;code-quote&quot;&gt;&quot;C2 CompilerThread1&quot;&lt;/span&gt; daemon prio=5 tid=0x00007fb05b002000 nid=0x5103 waiting on condition [0x0000000000000000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE

&lt;span class=&quot;code-quote&quot;&gt;&quot;C2 CompilerThread0&quot;&lt;/span&gt; daemon prio=5 tid=0x00007fb05b000000 nid=0x4f03 waiting on condition [0x0000000000000000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE

&lt;span class=&quot;code-quote&quot;&gt;&quot;Signal Dispatcher&quot;&lt;/span&gt; daemon prio=5 tid=0x00007fb058826800 nid=0x4d03 waiting on condition [0x0000000000000000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE

&lt;span class=&quot;code-quote&quot;&gt;&quot;Finalizer&quot;&lt;/span&gt; daemon prio=5 tid=0x00007fb05a04e000 nid=0x3903 in &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait() [0x0000000113772000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: WAITING (on object monitor)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(Native Method)
	- waiting on &amp;lt;0x00000007feb00658&amp;gt; (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
	- locked &amp;lt;0x00000007feb00658&amp;gt; (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189)

&lt;span class=&quot;code-quote&quot;&gt;&quot;Reference Handler&quot;&lt;/span&gt; daemon prio=5 tid=0x00007fb05a04b000 nid=0x3703 in &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait() [0x000000011366f000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: WAITING (on object monitor)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(Native Method)
	- waiting on &amp;lt;0x00000007feb104b8&amp;gt; (a java.lang.ref.Reference$Lock)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.java:503)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
	- locked &amp;lt;0x00000007feb104b8&amp;gt; (a java.lang.ref.Reference$Lock)

&lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; prio=5 tid=0x00007fb059002800 nid=0x1903 runnable [0x000000010b545000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:200)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x00000007fb6a4260&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x00000007fb6a41e0&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x00000007fb6a4058&amp;gt; (a sun.nio.ch.KQueueSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:203)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:547)
	- locked &amp;lt;0x00000007fb5c4708&amp;gt; (a org.apache.hadoop.ipc.Client$Connection)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:642)
	- locked &amp;lt;0x00000007fb5c4708&amp;gt; (a org.apache.hadoop.ipc.Client$Connection)
	at org.apache.hadoop.ipc.Client$Connection.access$2600(Client.java:314)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1399)
	at org.apache.hadoop.ipc.Client.call(Client.java:1318)
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy13.getApplications(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getApplications(ApplicationClientProtocolPBClientImpl.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getApplications(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplications(YarnClientImpl.java:237)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplications(YarnClientImpl.java:221)
	at org.apache.hadoop.hoya.yarn.client.HoyaYarnClientImpl.listHoyaInstances(HoyaYarnClientImpl.java:75)
	at org.apache.hadoop.hoya.yarn.client.HoyaClient.listHoyaInstances(HoyaClient.java:1167)
	at org.apache.hadoop.hoya.yarn.client.HoyaClient.actionList(HoyaClient.java:1179)
	at org.apache.hadoop.hoya.yarn.client.HoyaClient.runService(HoyaClient.java:234)
	at org.apache.hadoop.yarn.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:178)
	at org.apache.hadoop.yarn.service.launcher.ServiceLauncher.launchServiceRobustly(ServiceLauncher.java:394)
	at org.apache.hadoop.yarn.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:323)
	at org.apache.hadoop.yarn.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:539)
	at org.apache.hadoop.hoya.Hoya.main(Hoya.java:49)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13869152" author="stevel@apache.org" created="Sun, 12 Jan 2014 21:26:15 +0000"  >&lt;p&gt;resolving as duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10219&quot; title=&quot;ipc.Client.setupIOstreams() needs to check for ClientCache.stopClient requested shutdowns &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10219&quot;&gt;HADOOP-10219&lt;/a&gt;. Sorry -I needed to rerun the video I was making on filing issues and this was the bug I had to hand&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367492</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367494</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10226] Help! My Hadoop doesn&apos;t work!</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10226</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;I have installed hadoop but it it is failing&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
hadop version
-bash: hadop: command not found
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;please help!!&lt;/p&gt;</description>
                <environment>&lt;p&gt;big data borat&apos;s hadoop&lt;/p&gt;</environment>
        <key id="12688467">HADOOP-10226</key>
            <summary>Help! My Hadoop doesn&apos;t work!</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stevel@apache.org">Steve Loughran</reporter>
                        <labels>
                    </labels>
                <created>Sun, 12 Jan 2014 21:09:13 +0000</created>
                <updated>Sun, 12 Jan 2014 21:09:55 +0000</updated>
                            <resolved>Sun, 12 Jan 2014 21:09:55 +0000</resolved>
                                    <version>1.0.3</version>
                                                    <component>bin</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13869147" author="stevel@apache.org" created="Sun, 12 Jan 2014 21:09:42 +0000"  >&lt;p&gt;closing as Invalid&lt;br/&gt;
&lt;a href=&quot;https://wiki.apache.org/hadoop/InvalidJiraIssues&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://wiki.apache.org/hadoop/InvalidJiraIssues&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367491</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367493</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10225] Publish Maven javadoc and sources artifacts with Hadoop releases.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10225</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Right now Maven javadoc and sources artifacts do not accompany Hadoop releases within Maven central. This means that one needs to checkout source code to DEBUG aspects of the codebase... this is not user friendly.&lt;/p&gt;

&lt;p&gt;The build script(s) should be amended to accommodate publication of javadoc and sources artifacts alongside pom and jar artifacts. &lt;/p&gt;

&lt;p&gt;Some history on this conversation can be seen below&lt;br/&gt;
&lt;a href=&quot;http://s.apache.org/7qR&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://s.apache.org/7qR&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688449">HADOOP-10225</key>
            <summary>Publish Maven javadoc and sources artifacts with Hadoop releases.</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="lewismc">Lewis John McGibbney</reporter>
                        <labels>
                            <label>hadoop</label>
                            <label>javadoc</label>
                            <label>maven</label>
                            <label>sources</label>
                    </labels>
                <created>Sun, 12 Jan 2014 14:05:14 +0000</created>
                <updated>Sun, 12 Jan 2014 22:10:35 +0000</updated>
                                                            <fixVersion>3.0.0</fixVersion>
                                    <component>build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13869051" author="lewismc" created="Sun, 12 Jan 2014 14:07:03 +0000"  >&lt;p&gt;Can someone please mark &apos;fix versions&apos; box and i will produce patches for all branches this concerns?&lt;br/&gt;
Thanks in advance&lt;br/&gt;
Lewis&lt;/p&gt;</comment>
                            <comment id="13869078" author="lewismc" created="Sun, 12 Jan 2014 16:36:10 +0000"  >&lt;p&gt;I am developing a patch for common-trunk however I would like to obtain some advice on the following:&lt;br/&gt;
The parent pom.xml &lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; defines X profiles, namely &lt;b&gt;src&lt;/b&gt;, &lt;b&gt;dist&lt;/b&gt;, &lt;b&gt;sign&lt;/b&gt; and &lt;b&gt;clover&lt;/b&gt;. I am unsure which profile the Hadoop release manager uses for pushing releases. Can someone (a release manager or someone familiar with the Maven profile(s) used within the release process) please confirm what the process actually is?&lt;br/&gt;
Once I know this I can edit the Maven workflow and add the correct config.&lt;br/&gt;
Thank you  &lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://svn.apache.org/repos/asf/hadoop/common/trunk/pom.xml&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://svn.apache.org/repos/asf/hadoop/common/trunk/pom.xml&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13869163" author="lewismc" created="Sun, 12 Jan 2014 22:07:43 +0000"  >&lt;p&gt;Patch for hadoop-common trunk codebase.&lt;br/&gt;
Adds scm properties as well as a release profile to parent pom.xml.&lt;br/&gt;
Using the maven-release-plugin like&lt;/p&gt;

&lt;p&gt;mvn release:clean release:prepare -DautoVersionSubmodules=true&lt;/p&gt;

&lt;p&gt;to check generated artifacts, then &lt;/p&gt;

&lt;p&gt;mvn release:perform&lt;/p&gt;

&lt;p&gt;to push the Maven artifacts to Nexus should do the trick. I&apos;ve confirmed that sources and Javadoc artifacts are now generated locally.&lt;br/&gt;
This works perfectly for us over on Apache Gora when we are doing the release procedure. &lt;/p&gt;</comment>
                            <comment id="13869165" author="lewismc" created="Sun, 12 Jan 2014 22:10:35 +0000"  >&lt;p&gt;I would be happy to update documentation to accommodate the new &lt;b&gt;release&lt;/b&gt; profile introduced here. I&apos;ve asked for write permissions on the common-dev list&lt;br/&gt;
&lt;a href=&quot;http://www.mail-archive.com/common-dev%40hadoop.apache.org/msg11358.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.mail-archive.com/common-dev%40hadoop.apache.org/msg11358.html&lt;/a&gt; &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12459384">HADOOP-6635</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12622550" name="HADOOP-10225.patch" size="6943" author="lewismc" created="Sun, 12 Jan 2014 22:07:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367473</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367475</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10224] JavaKeyStoreProvider has to protect against corrupting underlying store</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10224</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Java keystores get corrupted at times. A key management operation that writes the store to disk could cause a corruption and all protected data would then be unaccessible.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688362">HADOOP-10224</key>
            <summary>JavaKeyStoreProvider has to protect against corrupting underlying store</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="lmccay">Larry McCay</assignee>
                                    <reporter username="lmccay">Larry McCay</reporter>
                        <labels>
                    </labels>
                <created>Sat, 11 Jan 2014 00:02:38 +0000</created>
                <updated>Sat, 11 Jan 2014 00:06:45 +0000</updated>
                                                                            <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13868499" author="lmccay" created="Sat, 11 Jan 2014 00:06:45 +0000"  >&lt;p&gt;I am thinking that the flush() needs to backup the original store to a randomized name, write the contents of the store, reload and maybe list the keys to ensure that it isn&apos;t corrupt.&lt;/p&gt;

&lt;p&gt;Once it has proven to not e corrupt we can delete the backup.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367386</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367388</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10223] MiniKdc#main() should close the FileReader it creates</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10223</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;FileReader is used to read MiniKDC properties.&lt;/p&gt;

&lt;p&gt;This FileReader should be closed after reading.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688358">HADOOP-10223</key>
            <summary>MiniKdc#main() should close the FileReader it creates</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yuzhihong@gmail.com">Ted Yu</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Jan 2014 23:49:43 +0000</created>
                <updated>Tue, 28 Jan 2014 23:37:06 +0000</updated>
                            <resolved>Sun, 12 Jan 2014 23:27:32 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13868484" author="tucu00" created="Fri, 10 Jan 2014 23:56:14 +0000"  >&lt;p&gt;One NIT, for complete correctness the * r = new FileReader(file);* should be done within the try block.&lt;/p&gt;</comment>
                            <comment id="13868496" author="tucu00" created="Sat, 11 Jan 2014 00:05:28 +0000"  >&lt;p&gt;Oops there is new NIT:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (r != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) r.close();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;it should be:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (r != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
  r.close();
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13868507" author="tucu00" created="Sat, 11 Jan 2014 00:13:19 +0000"  >&lt;p&gt;+1 pending jenkins.&lt;/p&gt;</comment>
                            <comment id="13868516" author="hadoopqa" created="Sat, 11 Jan 2014 00:16:53 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622466/hadoop-10223-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622466/hadoop-10223-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-minikdc.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3426//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3426//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3426//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3426//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13868525" author="hadoopqa" created="Sat, 11 Jan 2014 00:29:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622467/hadoop-10223-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622467/hadoop-10223-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-minikdc.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3427//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3427//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3427//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3427//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13868537" author="hadoopqa" created="Sat, 11 Jan 2014 00:47:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622467/hadoop-10223-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622467/hadoop-10223-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-minikdc.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3428//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3428//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3428//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3428//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13869188" author="tucu00" created="Sun, 12 Jan 2014 23:27:32 +0000"  >&lt;p&gt;Thanks Ted. Committed to trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13869196" author="hudson" created="Sun, 12 Jan 2014 23:35:11 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #4991 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/4991/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/4991/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10223&quot; title=&quot;MiniKdc#main() should close the FileReader it creates&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10223&quot;&gt;&lt;del&gt;HADOOP-10223&lt;/del&gt;&lt;/a&gt;. MiniKdc#main() should close the FileReader it creates. (Ted Yu via tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-minikdc/src/main/java/org/apache/hadoop/minikdc/MiniKdc.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13869425" author="hudson" created="Mon, 13 Jan 2014 11:08:56 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #451 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/451/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/451/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10223&quot; title=&quot;MiniKdc#main() should close the FileReader it creates&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10223&quot;&gt;&lt;del&gt;HADOOP-10223&lt;/del&gt;&lt;/a&gt;. MiniKdc#main() should close the FileReader it creates. (Ted Yu via tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-minikdc/src/main/java/org/apache/hadoop/minikdc/MiniKdc.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13869533" author="hudson" created="Mon, 13 Jan 2014 13:26:55 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1668 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1668/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1668/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10223&quot; title=&quot;MiniKdc#main() should close the FileReader it creates&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10223&quot;&gt;&lt;del&gt;HADOOP-10223&lt;/del&gt;&lt;/a&gt;. MiniKdc#main() should close the FileReader it creates. (Ted Yu via tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-minikdc/src/main/java/org/apache/hadoop/minikdc/MiniKdc.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13869541" author="hudson" created="Mon, 13 Jan 2014 13:40:44 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1643 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1643/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1643/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10223&quot; title=&quot;MiniKdc#main() should close the FileReader it creates&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10223&quot;&gt;&lt;del&gt;HADOOP-10223&lt;/del&gt;&lt;/a&gt;. MiniKdc#main() should close the FileReader it creates. (Ted Yu via tucu) (tucu: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1557627&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-minikdc/src/main/java/org/apache/hadoop/minikdc/MiniKdc.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12622466" name="hadoop-10223-v2.txt" size="805" author="yuzhihong@gmail.com" created="Sat, 11 Jan 2014 00:00:41 +0000"/>
                            <attachment id="12622467" name="hadoop-10223-v3.txt" size="825" author="yuzhihong@gmail.com" created="Sat, 11 Jan 2014 00:12:44 +0000"/>
                            <attachment id="12622462" name="hadoop-10223.txt" size="773" author="yuzhihong@gmail.com" created="Fri, 10 Jan 2014 23:50:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 10 Jan 2014 23:56:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367382</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367384</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HADOOP-10222] estSSLHttpServer creates ssl-server.xml in hadoop-common test classes without cleaning up</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10222</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;TestSSLHttpServer creates ssl-server.xml hadoop-common test-classes without cleaning up. Other tests could pick up the ssl-server configuration file and get the wrong keystore and truststore.&lt;/p&gt;

&lt;p&gt;Got the following exception while running org.apache.hadoop.hdfs.TestNameNodeHttpServer and the cause is TestNameNodeHttpServer is picking up the ssl-server.xml file written by TestSSLHttpServer&lt;/p&gt;

&lt;p&gt;java.io.IOException: Keystore was tampered with, or password was incorrect&lt;br/&gt;
	at com.ibm.crypto.provider.JavaKeyStore.engineLoad(Unknown Source)&lt;br/&gt;
	at java.security.KeyStore.load(KeyStore.java:414)&lt;br/&gt;
	at org.mortbay.jetty.security.SslSocketConnector.createFactory(SslSocketConnector.java:246)&lt;br/&gt;
	at org.mortbay.jetty.security.SslSocketConnector.newServerSocket(SslSocketConnector.java:476)&lt;br/&gt;
	at org.mortbay.jetty.bio.SocketConnector.open(SocketConnector.java:73)&lt;br/&gt;
	at org.mortbay.jetty.AbstractConnector.doStart(AbstractConnector.java:283)&lt;br/&gt;
	at org.mortbay.jetty.bio.SocketConnector.doStart(SocketConnector.java:147)&lt;br/&gt;
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)&lt;br/&gt;
	at org.mortbay.jetty.Server.doStart(Server.java:235)&lt;br/&gt;
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)&lt;br/&gt;
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:692)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:158)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:626)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:488)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.&amp;lt;init&amp;gt;(NameNode.java:684)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.&amp;lt;init&amp;gt;(NameNode.java:669)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1254)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:893)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:784)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:642)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.&amp;lt;init&amp;gt;(MiniDFSCluster.java:334)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:316)&lt;br/&gt;
	at org.apache.hadoop.hdfs.TestNameNodeHttpServer.testSslConfiguration(TestNameNodeHttpServer.java:38)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688346">HADOOP-10222</key>
            <summary>estSSLHttpServer creates ssl-server.xml in hadoop-common test classes without cleaning up</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jwang302">Jinghui Wang</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Jan 2014 22:22:06 +0000</created>
                <updated>Mon, 13 Jan 2014 18:48:49 +0000</updated>
                                            <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13868399" author="jwang302" created="Fri, 10 Jan 2014 22:22:40 +0000"  >&lt;p&gt;Will attach a patch fix the problem.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12622677" name="HADOOP-10222.patch" size="1038" author="jwang302" created="Mon, 13 Jan 2014 18:48:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367370</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367372</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10221] Add a plugin to specify SaslProperties for RPC protocol based on connection properties</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10221</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Add a plugin to specify SaslProperties for RPC protocol based on connection properties.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10211&quot; title=&quot;Enable RPC protocol to negotiate SASL-QOP values between clients and servers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10211&quot;&gt;HADOOP-10211&lt;/a&gt; enables client and server to specify and support multiple QOP.  Some connections needs to be restricted to a specific set of QOP based on connection properties.&lt;br/&gt;
Eg. connections from client from a specific subnet needs to be encrypted (QOP=privacy)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688334">HADOOP-10221</key>
            <summary>Add a plugin to specify SaslProperties for RPC protocol based on connection properties</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="benoyantony">Benoy Antony</assignee>
                                    <reporter username="benoyantony">Benoy Antony</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Jan 2014 21:31:40 +0000</created>
                <updated>Fri, 10 Jan 2014 21:35:12 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13868326" author="benoyantony" created="Fri, 10 Jan 2014 21:35:12 +0000"  >&lt;p&gt;Solution could be to allow SaslProperties (which includes QOP) to be decided for each connection based on custom logic that can be plugged in. &lt;br/&gt;
SASLRPCServer obtains SASLProperties from  a configured SASLPropertiesResolver if one exists. If not , it falls backs to the default SASLProperites loaded during initialization.&lt;/p&gt;

&lt;p&gt;The feature is backward compatible.&lt;br/&gt;
Additional tests are enabled in TestSaslRPC&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12687727">HADOOP-10211</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12622444" name="HADOOP-10221.patch" size="15648" author="benoyantony" created="Fri, 10 Jan 2014 21:35:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367358</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367360</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HADOOP-10220] Add ACL indicator bit to FsPermission.</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10220</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;This patch will take a previously unused bit in the 16-bit &lt;tt&gt;FsPermission&lt;/tt&gt; and use it to indicate the presence of an ACL on the file or directory.  The CLI will use this to display an indicator in the permission string if an ACL is present.  The NameNode will use it in ACL modification APIs, permission checks, and display of an indicator in the directory browser web UI.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688281">HADOOP-10220</key>
            <summary>Add ACL indicator bit to FsPermission.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686476">HADOOP-10184</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Jan 2014 17:22:13 +0000</created>
                <updated>Fri, 17 Jan 2014 23:51:55 +0000</updated>
                            <resolved>Sat, 11 Jan 2014 00:38:42 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13868162" author="cnauroth" created="Fri, 10 Jan 2014 19:20:18 +0000"  >&lt;p&gt;Summary of changes:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Add ACL bit member to &lt;tt&gt;FsPermission&lt;/tt&gt;.  Add new constructor, bit twiddling and string parsing.&lt;/li&gt;
	&lt;li&gt;Update &lt;tt&gt;TestFsPermission&lt;/tt&gt; to fully cover new constructor, binary parsing and string parsing for the new ACL bit.  While I was in here, I noticed that &lt;tt&gt;TestFsPermission#testFsPermission&lt;/tt&gt; was not fully covering sticky bit handling, so I also added tests for that.&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;RawLocalFileSystem&lt;/tt&gt; previously had a special case to ignore the &apos;+&apos; ACL indicator when parsing results from a local file system that might have ACLs enabled.  Now that we have an ACL bit, we don&apos;t need this special case.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This patch is targeted for the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; feature branch, but it can apply cleanly to trunk, so I&apos;m going to try submitting it for a Jenkins run.&lt;/p&gt;</comment>
                            <comment id="13868226" author="hadoopqa" created="Fri, 10 Jan 2014 20:00:28 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622421/HADOOP-10220.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622421/HADOOP-10220.1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3425//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3425//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3425//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3425//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13868464" author="szetszwo" created="Fri, 10 Jan 2014 23:34:53 +0000"  >&lt;p&gt;+1 patch looks good.  Thanks, Chris.&lt;/p&gt;</comment>
                            <comment id="13868531" author="cnauroth" created="Sat, 11 Jan 2014 00:38:42 +0000"  >&lt;p&gt;I committed this to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; feature branch.  Nicholas, thank you for the code review.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12682490">HDFS-5621</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12688348">HDFS-5758</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12622421" name="HADOOP-10220.1.patch" size="11811" author="cnauroth" created="Fri, 10 Jan 2014 19:20:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 10 Jan 2014 20:00:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367305</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367306</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325672</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>