<!--
RSS generated by JIRA (6.1.5#6160-sha1:a61a0fc278117a0da0ec9b89167b8f29b6afdab2) at Mon Feb 03 15:46:21 UTC 2014

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/sr/jira.issueviews:searchrequest-xml/temp/SearchRequest.xml?jqlQuery=project+%3D+HDFS&tempMax=100&field=key&field=summary
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&amp;jqlQuery=project+%3D+HDFS</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="100" total="5656"/>
                <build-info>
            <version>6.1.5</version>
            <build-number>6160</build-number>
            <build-date>03-12-2013</build-date>
        </build-info>
<item>
            <title>[HDFS-5868] Make hsync implementation pluggable</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5868</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The current implementation of hsync in BlockReceiver only works if the output streams are instances of FileOutputStream. Therefore, there is currently no way for a FSDatasetSpi plugin to implement hsync if it is not using standard OS files.&lt;/p&gt;

&lt;p&gt;One possible solution is to push the implementation of hsync into the ReplicaOutputStreams class. This class is constructed by the ReplicaInPipeline which is constructed by the FSDatasetSpi plugin, therefore it can be extended. Instead of directly calling sync on the output stream, BlockReceiver would call ReplicaOutputStream.sync.  The default implementation of sync in ReplicaOutputStream would be the same as the current implementation in BlockReceiver. &lt;/p&gt;
</description>
                <environment></environment>
        <key id="12692883">HDFS-5868</key>
            <summary>Make hsync implementation pluggable</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="buddytaylor0">Buddy</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Feb 2014 15:31:16 +0000</created>
                <updated>Mon, 3 Feb 2014 15:31:16 +0000</updated>
                                            <version>2.4.0</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371475</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371461</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5867] Clean up the output of NameDistribution processor</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5867</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description></description>
                <environment>&lt;p&gt;The output of &apos;hdfs oiv -i INPUT -o OUTPUT -p NameDistribution&apos; is as follows:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Total unique file names 86
0 names are used by 0 files between 100000-13 times. Heap savings ~0 bytes.
0 names are used by 0 files between 10000-99999 times. Heap savings ~0 bytes.
0 names are used by 0 files between 1000-9999 times. Heap savings ~0 bytes.
0 names are used by 0 files between 100-999 times. Heap savings ~0 bytes.
1 names are used by 13 files between 10-99 times. Heap savings ~372 bytes.
4 names are used by 34 files between 5-9 times. Heap savings ~942 bytes.
2 names are used by 8 files 4 times. Heap savings ~192 bytes.
0 names are used by 0 files 3 times. Heap savings ~0 bytes.
7 names are used by 14 files 2 times. Heap savings ~222 bytes.

Total saved heap ~1728bytes.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&apos;between 100000-13 times&apos; should be &apos;over 99999 times&apos; , or the line starting with &apos;0 names&apos; should not output.&lt;/p&gt;</environment>
        <key id="12692804">HDFS-5867</key>
            <summary>Clean up the output of NameDistribution processor</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12692795">HDFS-5863</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Feb 2014 09:23:16 +0000</created>
                <updated>Mon, 3 Feb 2014 09:23:17 +0000</updated>
                                                                            <component>tools</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371396</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371382</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5866] &apos;-maxSize&apos; and &apos;-step&apos; option fail in OfflineImageViewer</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5866</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Executing -step or/and -maxSize option will get the following error:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ hdfs oiv -p FileDistribution -step 102400 -i input -o output
Error parsing command-line options:
Usage: bin/hdfs oiv [OPTIONS] -i INPUTFILE -o OUTPUTFILE
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12692801">HDFS-5866</key>
            <summary>&apos;-maxSize&apos; and &apos;-step&apos; option fail in OfflineImageViewer</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12692795">HDFS-5863</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="ajisakaa">Akira AJISAKA</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Feb 2014 09:08:59 +0000</created>
                <updated>Mon, 3 Feb 2014 09:08:59 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>tools</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371393</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371379</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5865] Document some arguments in &apos;hdfs oiv --processor&apos; option</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5865</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The Offline Image Viewer document now describes &quot;Currently valid options are &lt;tt&gt;Ls&lt;/tt&gt;, &lt;tt&gt;XML&lt;/tt&gt;, and &lt;tt&gt;Indented&lt;/tt&gt;&quot; in &lt;tt&gt;--processor&lt;/tt&gt; option, but there&apos;re more options such as &lt;tt&gt;Delimited&lt;/tt&gt;, &lt;tt&gt;FileDistribution&lt;/tt&gt;, and &lt;tt&gt;NameDistribution&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692800">HDFS-5865</key>
            <summary>Document some arguments in &apos;hdfs oiv --processor&apos; option</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12692795">HDFS-5863</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Mon, 3 Feb 2014 08:59:40 +0000</created>
                <updated>Mon, 3 Feb 2014 08:59:40 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371392</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371378</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5864] Missing &apos;\n&apos; in the output of &apos;hdfs oiv --help&apos;</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5864</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In OfflineImageViewer.java, &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-quote&quot;&gt;&quot;  * NameDistribution: This processor analyzes the file names\n&quot;&lt;/span&gt; +
    &lt;span class=&quot;code-quote&quot;&gt;&quot;    in the image and prints total number of file names and how frequently&quot;&lt;/span&gt; +
    &lt;span class=&quot;code-quote&quot;&gt;&quot;    file names are reused.\n&quot;&lt;/span&gt; +
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;should be&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-quote&quot;&gt;&quot;  * NameDistribution: This processor analyzes the file names\n&quot;&lt;/span&gt; +
    &lt;span class=&quot;code-quote&quot;&gt;&quot;    in the image and prints total number of file names and how frequently\n&quot;&lt;/span&gt; +
    &lt;span class=&quot;code-quote&quot;&gt;&quot;    file names are reused.\n&quot;&lt;/span&gt; +
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12692797">HDFS-5864</key>
            <summary>Missing &apos;\n&apos; in the output of &apos;hdfs oiv --help&apos;</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12692795">HDFS-5863</parent>
                                    <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Mon, 3 Feb 2014 08:52:49 +0000</created>
                <updated>Mon, 3 Feb 2014 08:52:49 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>tools</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371389</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371375</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5863] Improve OfflineImageViewer</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5863</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This is an umbrella jira for improving Offline Image Viewer.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692795">HDFS-5863</key>
            <summary>Improve OfflineImageViewer</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Feb 2014 08:43:11 +0000</created>
                <updated>Mon, 3 Feb 2014 08:43:11 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>tools</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                    <attachments>
                    </attachments>
                <subtasks>
                            <subtask id="12692797">HDFS-5864</subtask>
                            <subtask id="12692800">HDFS-5865</subtask>
                            <subtask id="12692801">HDFS-5866</subtask>
                            <subtask id="12692804">HDFS-5867</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371387</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371373</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5862] NameNode.NAMENODE_SPECIFIC_KEYS includes DFS_HA_FENCE_METHODS_KEY twice.</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5862</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;I think it has been caused by merging branches.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692774">HDFS-5862</key>
            <summary>NameNode.NAMENODE_SPECIFIC_KEYS includes DFS_HA_FENCE_METHODS_KEY twice.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ikeda">Hiroshi Ikeda</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Feb 2014 05:41:12 +0000</created>
                <updated>Mon, 3 Feb 2014 05:41:12 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371375</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371361</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5861] Add CLI test for Ls output for extended ACL marker</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5861</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Add a xml test to aclTestCLI.xml to test the output of the LS command for the extended ACL file/dir.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692646">HDFS-5861</key>
            <summary>Add CLI test for Ls output for extended ACL marker</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12642003">HDFS-4685</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vinayrpet">Vinay</assignee>
                                    <reporter username="vinayrpet">Vinay</reporter>
                        <labels>
                    </labels>
                <created>Sat, 1 Feb 2014 05:13:49 +0000</created>
                <updated>Sat, 1 Feb 2014 05:59:34 +0000</updated>
                            <resolved>Sat, 1 Feb 2014 05:59:34 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                                    <component>hdfs-client</component>
                    <component>namenode</component>
                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13888461" author="vinayrpet" created="Sat, 1 Feb 2014 05:16:43 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cnauroth&quot; class=&quot;user-hover&quot; rel=&quot;cnauroth&quot;&gt;Chris Nauroth&lt;/a&gt; , Could you take a look at added test.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13888468" author="cnauroth" created="Sat, 1 Feb 2014 05:59:34 +0000"  >&lt;p&gt;+1 for the patch.  I verified the test, and I committed it to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; feature branch.  Vinay, thank you for adding this test.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626453" name="HDFS-5861.patch" size="1432" author="vinayrpet" created="Sat, 1 Feb 2014 05:15:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 1 Feb 2014 05:59:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371247</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371233</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325671</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5860] Refactor INodeDirectory getDirectoryXFeature methods to use common getFeature helper method.</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5860</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; feature branch has introduced a helper method for getting an inode feature of a particular class: &lt;tt&gt;INodeWithAdditionalFields#getFeature&lt;/tt&gt;.  Currently, this is only called by code related to ACLs, but we can also use the same method to reduce code duplication in the various &lt;tt&gt;INodeDirectory&lt;/tt&gt; methods that get different kinds of features.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692586">HDFS-5860</key>
            <summary>Refactor INodeDirectory getDirectoryXFeature methods to use common getFeature helper method.</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Jan 2014 20:28:53 +0000</created>
                <updated>Sat, 1 Feb 2014 05:55:39 +0000</updated>
                            <resolved>Sat, 1 Feb 2014 05:55:39 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13888467" author="cnauroth" created="Sat, 1 Feb 2014 05:55:39 +0000"  >&lt;p&gt;+1 for the patch.  I committed it to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; feature branch.  Thanks for taking care of this so quickly, Jing.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12682483">HDFS-5614</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12642003">HDFS-4685</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626422" name="HDFS-5860.000.patch" size="1434" author="jingzhao" created="Fri, 31 Jan 2014 23:47:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371187</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371173</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325671</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5859] DataNode#checkBlockToken should check block tokens even if security is not enabled</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5859</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;DataNode#checkBlockToken should check block tokens even if security is not enabled, so that unit tests that turn on block tokens (but not security) can get an effective test.  This is only for unit tests.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692573">HDFS-5859</key>
            <summary>DataNode#checkBlockToken should check block tokens even if security is not enabled</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cmccabe">Colin Patrick McCabe</assignee>
                                    <reporter username="cmccabe">Colin Patrick McCabe</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Jan 2014 19:40:08 +0000</created>
                <updated>Sat, 1 Feb 2014 13:40:01 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 23:10:05 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13888210" author="hadoopqa" created="Fri, 31 Jan 2014 21:54:59 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626358/HDFS-5859.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626358/HDFS-5859.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6003//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6003//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6003//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6003//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888265" author="andrew.wang" created="Fri, 31 Jan 2014 22:55:03 +0000"  >&lt;p&gt;+1 LGTM, thanks Colin.&lt;/p&gt;</comment>
                            <comment id="13888294" author="hudson" created="Fri, 31 Jan 2014 23:18:19 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5088 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5088/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5088/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5859&quot; title=&quot;DataNode#checkBlockToken should check block tokens even if security is not enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5859&quot;&gt;&lt;del&gt;HDFS-5859&lt;/del&gt;&lt;/a&gt;.  DataNode#checkBlockToken should check block tokens even if security is not enabled (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888532" author="hudson" created="Sat, 1 Feb 2014 11:04:50 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #468 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5859&quot; title=&quot;DataNode#checkBlockToken should check block tokens even if security is not enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5859&quot;&gt;&lt;del&gt;HDFS-5859&lt;/del&gt;&lt;/a&gt;.  DataNode#checkBlockToken should check block tokens even if security is not enabled (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888582" author="hudson" created="Sat, 1 Feb 2014 13:29:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1685 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5859&quot; title=&quot;DataNode#checkBlockToken should check block tokens even if security is not enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5859&quot;&gt;&lt;del&gt;HDFS-5859&lt;/del&gt;&lt;/a&gt;.  DataNode#checkBlockToken should check block tokens even if security is not enabled (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888596" author="hudson" created="Sat, 1 Feb 2014 13:40:01 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1660 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5859&quot; title=&quot;DataNode#checkBlockToken should check block tokens even if security is not enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5859&quot;&gt;&lt;del&gt;HDFS-5859&lt;/del&gt;&lt;/a&gt;.  DataNode#checkBlockToken should check block tokens even if security is not enabled (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563328&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626358" name="HDFS-5859.001.patch" size="992" author="cmccabe" created="Fri, 31 Jan 2014 19:41:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 21:54:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371174</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371160</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5858] Refactor common ACL test cases to be run through multiple FileSystem implementations.</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5858</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5608&quot; title=&quot;WebHDFS: implement ACL APIs.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5608&quot;&gt;&lt;del&gt;HDFS-5608&lt;/del&gt;&lt;/a&gt; implemented WebHDFS bindings for the new ACL APIs.  As part of that patch, the test cases implemented in &lt;tt&gt;TestNameNodeAcl&lt;/tt&gt; were duplicated to be run through &lt;tt&gt;WebHdfsFileSystem&lt;/tt&gt;.  Instead of duplicating, we can refactor so that the test cases are defined in a shared base class, and individual test suite subclasses initialize a different &lt;tt&gt;FileSystem&lt;/tt&gt; implementation for those test cases to use.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692452">HDFS-5858</key>
            <summary>Refactor common ACL test cases to be run through multiple FileSystem implementations.</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Jan 2014 06:57:43 +0000</created>
                <updated>Fri, 31 Jan 2014 23:03:26 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 23:03:14 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>namenode</component>
                    <component>test</component>
                    <component>webhdfs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13887537" author="cnauroth" created="Fri, 31 Jan 2014 07:05:31 +0000"  >&lt;p&gt;This patch looks large, but it&apos;s all strictly refactoring of test code.  Every &lt;tt&gt;@Test&lt;/tt&gt; formerly defined in &lt;tt&gt;TestNameNodeAcl&lt;/tt&gt; has been pushed up into a new abstract base class: &lt;tt&gt;FSAclBaseTest&lt;/tt&gt;.  &lt;tt&gt;TestNameNodeAcl&lt;/tt&gt; is a subclass that initializes the tests to run through an instance of &lt;tt&gt;DistributedFileSystem&lt;/tt&gt;.  &lt;tt&gt;TestWebHDFSAcl&lt;/tt&gt; is a subclass that initializes the tests to run through an instance of &lt;tt&gt;WebHdfsFileSystem&lt;/tt&gt;.  All of the tests that had been duplicated inside &lt;tt&gt;TestWebHDFS&lt;/tt&gt; have been removed.  (Basically, this is just taking &lt;tt&gt;TestWebHDFS&lt;/tt&gt; back to the trunk version.)&lt;/p&gt;

&lt;p&gt;This patch is dependent on applying &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5614&quot; title=&quot;NameNode: implement handling of ACLs in combination with snapshots.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5614&quot;&gt;&lt;del&gt;HDFS-5614&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5849&quot; title=&quot;Removing ACL from an inode fails if it has only a default ACL.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5849&quot;&gt;&lt;del&gt;HDFS-5849&lt;/del&gt;&lt;/a&gt; first.  Both of those patches had added new test cases to &lt;tt&gt;TestNameNodeAcl&lt;/tt&gt;.  I intend to commit both of those before this test refactoring.&lt;/p&gt;</comment>
                            <comment id="13888198" author="arpitagarwal" created="Fri, 31 Jan 2014 21:36:28 +0000"  >&lt;p&gt;Hi Chris, it looks like the patch needs to be rebased.&lt;/p&gt;</comment>
                            <comment id="13888203" author="cnauroth" created="Fri, 31 Jan 2014 21:44:36 +0000"  >&lt;p&gt;Thanks, Arpit.  We&apos;re close to committing &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5614&quot; title=&quot;NameNode: implement handling of ACLs in combination with snapshots.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5614&quot;&gt;&lt;del&gt;HDFS-5614&lt;/del&gt;&lt;/a&gt; now, so I&apos;m going to wait for that one to go in, and then I&apos;ll rebase this.&lt;/p&gt;</comment>
                            <comment id="13888254" author="cnauroth" created="Fri, 31 Jan 2014 22:39:29 +0000"  >&lt;p&gt;Here is a v2 patch for the rebase.&lt;/p&gt;</comment>
                            <comment id="13888270" author="arpitagarwal" created="Fri, 31 Jan 2014 22:58:11 +0000"  >&lt;p&gt;+1 for the patch, verified all updated tests pass.&lt;/p&gt;</comment>
                            <comment id="13888274" author="cnauroth" created="Fri, 31 Jan 2014 23:03:14 +0000"  >&lt;p&gt;Thanks once again, Arpit.  I committed this to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; branch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12682475">HDFS-5608</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12642003">HDFS-4685</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                            <outwardlinks description="requires">
                                        <issuelink>
            <issuekey id="12682483">HDFS-5614</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12692135">HDFS-5849</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626272" name="HDFS-5858.1.patch" size="96818" author="cnauroth" created="Fri, 31 Jan 2014 07:05:31 +0000"/>
                            <attachment id="12626400" name="HDFS-5858.2.patch" size="96727" author="cnauroth" created="Fri, 31 Jan 2014 22:39:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 21:36:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371053</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>371039</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325671</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5857] TestWebHDFS#testNamenodeRestart fails intermittently with NPE</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5857</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.AssertionError: There are 1 exception(s):
  Exception 0: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): null
	at org.apache.hadoop.hdfs.web.JsonUtil.toRemoteException(JsonUtil.java:157)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:315)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$700(WebHdfsFileSystem.java:105)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.getResponse(WebHdfsFileSystem.java:625)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:532)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.run(WebHdfsFileSystem.java:421)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1816)
	at org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:196)
	at org.apache.hadoop.hdfs.TestDFSClientRetries$6.run(TestDFSClientRetries.java:920)
	at java.lang.Thread.run(Thread.java:722)

	at org.junit.Assert.fail(Assert.java:93)
	at org.apache.hadoop.hdfs.TestDFSClientRetries.assertEmpty(TestDFSClientRetries.java:1031)
	at org.apache.hadoop.hdfs.TestDFSClientRetries.namenodeRestartTest(TestDFSClientRetries.java:951)
	at org.apache.hadoop.hdfs.web.TestWebHDFS.testNamenodeRestart(TestWebHDFS.java:216)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12692364">HDFS-5857</key>
            <summary>TestWebHDFS#testNamenodeRestart fails intermittently with NPE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 18:41:34 +0000</created>
                <updated>Thu, 30 Jan 2014 19:08:37 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370965</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370951</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5856] DataNode.checkDiskError might throw NPE</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5856</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Running a small 2.2.0 cluster with a heavy workload. I noticed in the DataNode log that when faced with network exceptions, I would sometimes get a NullPointerException from checkDiskError.&lt;/p&gt;

&lt;p&gt;Looking at the code, if the Exception that is handed to checkDiskError contains a null message, the checks that try to identify if the Exception is network-related will throw a NPE.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692353">HDFS-5856</key>
            <summary>DataNode.checkDiskError might throw NPE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="elserj">Josh Elser</assignee>
                                    <reporter username="elserj">Josh Elser</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 18:29:05 +0000</created>
                <updated>Fri, 31 Jan 2014 17:47:49 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 05:39:14 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13886877" author="elserj" created="Thu, 30 Jan 2014 18:30:30 +0000"  >&lt;p&gt;Patch against trunk&lt;/p&gt;</comment>
                            <comment id="13886878" author="elserj" created="Thu, 30 Jan 2014 18:32:36 +0000"  >&lt;p&gt;A patch that checks for a non-null message on the Exception before calling String methods on that message. Lifted the &quot;network-related&quot; conditional into its own method and added a quick test to ensure we identify the &quot;network-related&quot; exceptions as intended.&lt;/p&gt;</comment>
                            <comment id="13886893" author="elserj" created="Thu, 30 Jan 2014 18:42:08 +0000"  >&lt;p&gt;Current patch also applies cleanly to branch-2.&lt;/p&gt;</comment>
                            <comment id="13887035" author="hadoopqa" created="Thu, 30 Jan 2014 20:56:45 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626140/HDFS-5856.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626140/HDFS-5856.diff&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.TestPersistBlocks&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5991//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5991//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5991//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5991//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13887324" author="sureshms" created="Fri, 31 Jan 2014 00:51:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=elserj&quot; class=&quot;user-hover&quot; rel=&quot;elserj&quot;&gt;Josh Elser&lt;/a&gt;, thanks for the patch.&lt;/p&gt;

&lt;p&gt;Minor nits:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Instead of repeating e.getMessage() many times, you could use String msg = e.getMessage(). Might make it is easy to format the code.&lt;/li&gt;
	&lt;li&gt;One of the lines goes beyond 80 chars. It might be more readable with a line limited to a single exception.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Other than that it looks good. &lt;/p&gt;</comment>
                            <comment id="13887397" author="elserj" created="Fri, 31 Jan 2014 02:37:40 +0000"  >&lt;p&gt;Thanks for the quick suggestions, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt;. New patch with your suggestions taken into consideration.&lt;/p&gt;</comment>
                            <comment id="13887432" author="sureshms" created="Fri, 31 Jan 2014 03:40:47 +0000"  >&lt;p&gt;+1 for the patch. I will commit it once Jenkins posts +1.&lt;/p&gt;</comment>
                            <comment id="13887477" author="hadoopqa" created="Fri, 31 Jan 2014 05:14:19 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626248/HDFS-5856.diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626248/HDFS-5856.diff&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5998//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5998//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5998//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5998//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13887496" author="sureshms" created="Fri, 31 Jan 2014 05:39:14 +0000"  >&lt;p&gt;I committed the patch to trunk and branch-2. Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=elserj&quot; class=&quot;user-hover&quot; rel=&quot;elserj&quot;&gt;Josh Elser&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="13887498" author="hudson" created="Fri, 31 Jan 2014 05:46:52 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5081 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5081/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5081/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5856&quot; title=&quot;DataNode.checkDiskError might throw NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5856&quot;&gt;&lt;del&gt;HDFS-5856&lt;/del&gt;&lt;/a&gt;. DataNode.checkDiskError might throw NPE. Contributed by Josh Elser. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887654" author="hudson" created="Fri, 31 Jan 2014 11:14:08 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #467 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5856&quot; title=&quot;DataNode.checkDiskError might throw NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5856&quot;&gt;&lt;del&gt;HDFS-5856&lt;/del&gt;&lt;/a&gt;. DataNode.checkDiskError might throw NPE. Contributed by Josh Elser. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887738" author="hudson" created="Fri, 31 Jan 2014 13:29:54 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1684 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5856&quot; title=&quot;DataNode.checkDiskError might throw NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5856&quot;&gt;&lt;del&gt;HDFS-5856&lt;/del&gt;&lt;/a&gt;. DataNode.checkDiskError might throw NPE. Contributed by Josh Elser. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887752" author="hudson" created="Fri, 31 Jan 2014 13:39:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1659 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5856&quot; title=&quot;DataNode.checkDiskError might throw NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5856&quot;&gt;&lt;del&gt;HDFS-5856&lt;/del&gt;&lt;/a&gt;. DataNode.checkDiskError might throw NPE. Contributed by Josh Elser. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563064&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887941" author="elserj" created="Fri, 31 Jan 2014 17:47:49 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626248" name="HDFS-5856.diff" size="4183" author="elserj" created="Fri, 31 Jan 2014 02:37:40 +0000"/>
                            <attachment id="12626140" name="HDFS-5856.diff" size="4147" author="elserj" created="Thu, 30 Jan 2014 18:30:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 20:56:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370954</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370940</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5855] Reading edits should not stop at UpgradeMarker for normal restart of the namenode</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5855</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;As mentioned &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5645?focusedCommentId=13867530&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13867530&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5645&quot; title=&quot;Support upgrade marker in editlog streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5645&quot;&gt;&lt;del&gt;HDFS-5645&lt;/del&gt;&lt;/a&gt; NameNode restart will stop reading Edits at UpgradeMarker. But this should happen only if namenode is rolling back from upgrade. &lt;br/&gt;
There is also a possibility that namenode could get restarted after rolling upgrade started. This should not rollback everything.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692303">HDFS-5855</key>
            <summary>Reading edits should not stop at UpgradeMarker for normal restart of the namenode</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12680353">HDFS-5535</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="vinayrpet">Vinay</assignee>
                                    <reporter username="vinayrpet">Vinay</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 15:25:17 +0000</created>
                <updated>Thu, 30 Jan 2014 16:08:18 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 16:08:18 +0000</resolved>
                                                                    <component>datanode</component>
                    <component>ha</component>
                    <component>hdfs-client</component>
                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13886697" author="szetszwo" created="Thu, 30 Jan 2014 15:59:46 +0000"  >&lt;p&gt;Hi Vinay, only Standby NN could be restarted in rolling upgrade (otherwise, there is downtime).  For restarting Standby NN, &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5835&quot; title=&quot;Add a new option for starting standby NN when rolling upgrade is in progress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5835&quot;&gt;&lt;del&gt;HDFS-5835&lt;/del&gt;&lt;/a&gt; has already addressed the problem you mentioned here. Could you take a look?&lt;/p&gt;</comment>
                            <comment id="13886704" author="vinayrpet" created="Thu, 30 Jan 2014 16:07:37 +0000"  >&lt;p&gt;Thanks Nicholas. That could actually solve the issue. My bad. I dint see all jiras. Will close this as duplicate.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12691323">HDFS-5835</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 15:59:46 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370904</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370890</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5854] WebHDFS file browsing not working on secure cluster -or displaying meaningful errors</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5854</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;webhdfs is on by default and the new NN status UI is coming up (after setting the {{ &apos;dfs.web.authentication.kerberos.principal}} property -but the FS browser failing with error code 401 -unauth. &lt;/p&gt;

&lt;p&gt;That&apos;s inevitably security related -somehow.  But&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;the principal is set -or does httpfs-site.xml need to be filled in too?&lt;/li&gt;
	&lt;li&gt;if it is invalid, then some statement in the GUI should be provided&lt;/li&gt;
&lt;/ol&gt;
</description>
                <environment>&lt;p&gt;linux, kerberized 2.4.0 snapshot, commit #941ce6a&lt;/p&gt;</environment>
        <key id="12692246">HDFS-5854</key>
            <summary>WebHDFS file browsing not working on secure cluster -or displaying meaningful errors</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stevel@apache.org">Steve Loughran</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 10:17:53 +0000</created>
                <updated>Thu, 30 Jan 2014 16:54:11 +0000</updated>
                                            <version>2.4.0</version>
                                                    <component>webhdfs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13886463" author="stevel@apache.org" created="Thu, 30 Jan 2014 10:18:55 +0000"  >&lt;p&gt;screen shot&lt;/p&gt;</comment>
                            <comment id="13886464" author="stevel@apache.org" created="Thu, 30 Jan 2014 10:19:54 +0000"  >&lt;p&gt;a GET on the command line returns the HTTP error code, though the body is meaningless&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ GET http:&lt;span class=&quot;code-comment&quot;&gt;//localhost:50070/webhdfs/v1/?op=LISTSTATUS
&lt;/span&gt;&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;meta http-equiv=&lt;span class=&quot;code-quote&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt; content=&lt;span class=&quot;code-quote&quot;&gt;&quot;text/html; charset=ISO-8859-1&quot;&lt;/span&gt;/&amp;gt;
&amp;lt;title&amp;gt;Error 401 &amp;lt;/title&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;&amp;lt;h2&amp;gt;HTTP ERROR 401&amp;lt;/h2&amp;gt;
&amp;lt;p&amp;gt;Problem accessing /webhdfs/v1/. Reason:
&amp;lt;pre&amp;gt;    &amp;lt;/pre&amp;gt;&amp;lt;/p&amp;gt;&amp;lt;hr /&amp;gt;&amp;lt;i&amp;gt;&amp;lt;small&amp;gt;Powered by Jetty:&lt;span class=&quot;code-comment&quot;&gt;//&amp;lt;/small&amp;gt;&amp;lt;/i&amp;gt;&amp;lt;br/&amp;gt;                                                
&lt;/span&gt;&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                
&amp;lt;br/&amp;gt;                                                

&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13886468" author="stevel@apache.org" created="Thu, 30 Jan 2014 10:22:25 +0000"  >&lt;p&gt;workaround is to revert to the old GUI&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
   &amp;lt;value&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13886657" author="daryn" created="Thu, 30 Jan 2014 15:25:30 +0000"  >&lt;p&gt;Sidenote, one of the spnego patches I have available for webhdfs&apos;s http protocol violations will cause the body to contain &quot;Authentication required&quot;.  I do find it humorous that it currently appears to blame Jetty itself. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m not disagreeing with the fallback because it doesn&apos;t make sense for the NN UI to depend on an optional service.  I&apos;ve been a bit dismayed about the direct reliance on webhdfs http calls because it&apos;s problematic when the NN UI is protected by a custom non-spnego auth filter - in our case and probably yours because desktop clients aren&apos;t configured to do spnego.  Yet the UI references URL&apos;s that require spnego which the client cannot do.&lt;/p&gt;

&lt;p&gt;Perhaps the NN should be internally invoking the servlets to get the response direct webhdfs calls would return.  That retains the cool new UI and allows flexibility for authentication.&lt;/p&gt;</comment>
                            <comment id="13886773" author="kihwal" created="Thu, 30 Jan 2014 16:54:11 +0000"  >&lt;p&gt;Related to or possible dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5796&quot; title=&quot;The file system browser in the namenode UI requires SPNEGO.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5796&quot;&gt;HDFS-5796&lt;/a&gt;? &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Perhaps the NN should be internally invoking the servlets to get the response direct webhdfs calls would return. That retains the cool new UI and allows flexibility for authentication.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree, but &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5796&quot; title=&quot;The file system browser in the namenode UI requires SPNEGO.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5796&quot;&gt;HDFS-5796&lt;/a&gt; is not heading that way. Please chime in.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12680096">HDFS-5532</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626083" name="Screen Shot 2014-01-30 at 10.16.45.png" size="23999" author="stevel@apache.org" created="Thu, 30 Jan 2014 10:18:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 15:25:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370847</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370833</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5853] Add &quot;hadoop.user.group.metrics.percentiles.intervals&quot; to hdfs-default.xml</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5853</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&quot;hadoop.user.group.metrics.percentiles.intervals&quot; was added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5220&quot; title=&quot;Expose group resolution time as metric&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5220&quot;&gt;&lt;del&gt;HDFS-5220&lt;/del&gt;&lt;/a&gt;, but the parameter is not written in hdfs-default.xml.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692229">HDFS-5853</key>
            <summary>Add &quot;hadoop.user.group.metrics.percentiles.intervals&quot; to hdfs-default.xml</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="ajisakaa">Akira AJISAKA</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jan 2014 07:52:56 +0000</created>
                <updated>Thu, 30 Jan 2014 10:35:04 +0000</updated>
                                            <version>2.3.0</version>
                                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13886381" author="ajisakaa" created="Thu, 30 Jan 2014 08:18:46 +0000"  >&lt;p&gt;Attaching a patch.&lt;/p&gt;</comment>
                            <comment id="13886474" author="hadoopqa" created="Thu, 30 Jan 2014 10:35:04 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626078/HDFS-5853.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626078/HDFS-5853.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5990//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5990//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5990//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5990//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12669153">HDFS-5220</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626078" name="HDFS-5853.patch" size="834" author="ajisakaa" created="Thu, 30 Jan 2014 08:18:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 10:35:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370830</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370816</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5852] Change the colors on the hdfs UI</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5852</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The HDFS UI colors are too close to HWX green.&lt;/p&gt;

&lt;p&gt;Here is a patch that steers clear of vendor colors.&lt;/p&gt;

&lt;p&gt;I made it a blocker thinking this something we&apos;d want to fix before we release apache hadoop 2.3.0.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692193">HDFS-5852</key>
            <summary>Change the colors on the hdfs UI</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                                    <resolution id="7">Later</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                            <label>webui</label>
                    </labels>
                <created>Thu, 30 Jan 2014 00:16:55 +0000</created>
                <updated>Sat, 1 Feb 2014 22:36:40 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 20:32:00 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>30</watches>
                                                                <comments>
                            <comment id="13886065" author="stack" created="Thu, 30 Jan 2014 00:20:16 +0000"  >&lt;p&gt;Patch that changes our basis from &apos;green&apos; to &apos;orange&apos;.  Screen shot coming...&lt;/p&gt;</comment>
                            <comment id="13886069" author="stack" created="Thu, 30 Jan 2014 00:22:40 +0000"  >&lt;p&gt;Here is what the patch looks like.&lt;/p&gt;

&lt;p&gt;The colors used ... are &apos;International Orange (Aerospace)&lt;br/&gt;
#FF4F00&apos; for  banner background and &apos;International Orange (Golden Gate&lt;br/&gt;
Bridge) #C0362C&apos; for highlighting when an item is selected in the banner.&lt;br/&gt;
A lighter hue of &apos;International Orange (Aerospace)&apos; courtesy of&lt;br/&gt;
&lt;a href=&quot;http://www.colorhexa.com/ff4f00&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.colorhexa.com/ff4f00&lt;/a&gt; is also used for ui-tabs div.  See&lt;br/&gt;
&lt;a href=&quot;http://en.wikipedia.org/wiki/International_orange&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/International_orange&lt;/a&gt; for more on IO.&lt;/p&gt;</comment>
                            <comment id="13886077" author="andrew.wang" created="Thu, 30 Jan 2014 00:27:04 +0000"  >&lt;p&gt;I&apos;m +1, but let&apos;s give others some time to comment before committing.&lt;/p&gt;</comment>
                            <comment id="13886109" author="szetszwo" created="Thu, 30 Jan 2014 00:59:42 +0000"  >&lt;p&gt;What if there is a vendor using orange (or any color you chosen)?&lt;/p&gt;</comment>
                            <comment id="13886119" author="stack" created="Thu, 30 Jan 2014 01:09:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;What if there is a vendor using orange (or any color you chosen)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Such a vendor could exist.  My little survey was not extensive for sure.  I just clicked through here: &lt;a href=&quot;http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What you think of the green &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szetszwo&quot; class=&quot;user-hover&quot; rel=&quot;szetszwo&quot;&gt;Tsz Wo (Nicholas), SZE&lt;/a&gt;?  Does it make you think of any particular vendor in particular as it did this hadoop user?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
</comment>
                            <comment id="13886120" author="tlipcon" created="Thu, 30 Jan 2014 01:09:30 +0000"  >&lt;p&gt;Why don&apos;t we choose the Hadoop elephant yellow? Or Apache purple? Seems like we already have some project branding that we could &quot;fit with&quot; in that sense.&lt;/p&gt;</comment>
                            <comment id="13886124" author="vinodkv" created="Thu, 30 Jan 2014 01:12:12 +0000"  >&lt;p&gt;Interesting. It could be a controversial thing, but here&apos;s my take. There is no single HWX green, but if I were to pick one shade up, it would be the light green in the logo. And looking at the screenshot you shared (I deployed 2.4 clusters, but never happened to look at HDFS UI), that one seems much darker.&lt;/p&gt;

&lt;p&gt;If one focuses only on one color&apos;s shades, I can see why one would correlate them.&lt;/p&gt;

&lt;p&gt;Irrespective, since when is pure colors tied to a company? If this were the case, any company with grey background will conflict with the colors we chose in the YARN UI. And Oozie UI would essentially be same as Cloudera&apos;s? Not sure if we can rule out colors in Apache software because vendors happen to include those in their color palette.&lt;/p&gt;</comment>
                            <comment id="13886163" author="cos" created="Thu, 30 Jan 2014 01:53:56 +0000"  >&lt;p&gt;+1 - I like it!&lt;/p&gt;

&lt;p&gt;In fact - very bright and optimistic! And indeed brand neutral &lt;/p&gt;</comment>
                            <comment id="13886165" author="cos" created="Thu, 30 Jan 2014 01:54:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why don&apos;t we choose the Hadoop elephant yellow? Or Apache purple?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I believe these two won&apos;t look good in the interface - yellow is too light; and purple is on a darker side. I really like Stack&apos;s version!&lt;/p&gt;</comment>
                            <comment id="13886166" author="cos" created="Thu, 30 Jan 2014 01:55:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;And Oozie UI would essentially be same as Cloudera&apos;s?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oozie came from Yahoo and most of the committers there are from Y!, if I am not mistaken &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13886167" author="sureshms" created="Thu, 30 Jan 2014 01:56:40 +0000"  >&lt;p&gt;I think the UI which used to look decent now looks pretty ugly. Can we go back to just white and grey and be done with it?&lt;/p&gt;</comment>
                            <comment id="13886175" author="vinodkv" created="Thu, 30 Jan 2014 02:06:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;Oozie came from Yahoo and most of the committers there are from Y!, if I am not mistaken&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Which is precisely the point. Colors on Apache UIs don&apos;t necessarily correlate to Companies.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can we go back to just white and grey and be done with it?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1. There is far more important stuff that needs contributors than arguments on nonissues like this.&lt;/p&gt;</comment>
                            <comment id="13886184" author="cos" created="Thu, 30 Jan 2014 02:13:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can we go back to just white and grey and be done with it?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nah... a splash of color wouldn&apos;t hurt anyone. &lt;/p&gt;</comment>
                            <comment id="13886237" author="sureshms" created="Thu, 30 Jan 2014 04:16:11 +0000"  >&lt;p&gt;Current color scheme seems to be similar to &lt;a href=&quot;http://www.datastax.com/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datastax.com/&lt;/a&gt;. I am not sure if the shades are the same. We should avoid that. &lt;/p&gt;</comment>
                            <comment id="13886250" author="cos" created="Thu, 30 Jan 2014 04:34:27 +0000"  >&lt;p&gt;Is it because Cassandra treating us?&lt;/p&gt;</comment>
                            <comment id="13886261" author="stack" created="Thu, 30 Jan 2014 05:20:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt; bq. Why don&apos;t we choose the Hadoop elephant yellow? Or Apache purple? Seems like we already have some project branding that we could &quot;fit with&quot; in that sense.&lt;/p&gt;

&lt;p&gt;The color is just a suggestion.  I now think it too radical a departure after your comment and considering we are on the eve of a release; we shouldn&apos;t be choosing a hadoop color at this juncture.&lt;/p&gt;

&lt;p&gt;I put up a patch because I&apos;d gone to the trouble of hunting out what would need to change.  Elephant yellow would have been a good, non-controversial obviously &apos;apache hadoop&apos; color but as per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cos&quot; class=&quot;user-hover&quot; rel=&quot;cos&quot;&gt;Konstantin Boudnik&lt;/a&gt; it&apos;d probably be poor as background for white text.  A &apos;purple&apos; or the &apos;Maven Blue&apos; on hadoop.apache.org would work better as background.&lt;/p&gt;

&lt;p&gt;I was also after colors with a neutral provenance &amp;#8211; hence the choice from the International Orange palate &amp;#8211; so it was clear where they came from so this issue could be put to rest once and for all and never raise its head again.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vinodkv&quot; class=&quot;user-hover&quot; rel=&quot;vinodkv&quot;&gt;Vinod Kumar Vavilapalli&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Interesting. It could be a controversial thing, but here&apos;s my take. There is no single HWX green, but if I were to pick one shade up, it would be the light green in the logo. And looking at the screenshot you shared (I deployed 2.4 clusters, but never happened to look at HDFS UI), that one seems much darker.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for the opinion V.  I do think it a bit darker (though best to look at the actual UI since the link I posted is of a PNG of a desktop picture &amp;#8211; so some fidelity is lost). &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Irrespective, since when is pure colors tied to a company?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it fairly well established that color can stand for an entity such as a company (Here is a fun game that makes the point well: &lt;a href=&quot;http://www.businessinsider.com/can-you-identify-these-12-brands-by-their-trademarked-colors-alone-2012-2?op=1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.businessinsider.com/can-you-identify-these-12-brands-by-their-trademarked-colors-alone-2012-2?op=1&lt;/a&gt;)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If this were the case, any company with grey background will conflict with the colors we chose in the YARN UI. And Oozie UI would essentially be same as Cloudera&apos;s?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;IMO, grey is different.  My guess is that is probably hard to find a company that uses a washed out gray as its signature color.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Not sure if we can rule out colors in Apache software because vendors happen to include those in their color palette.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was just suggesting we could avoid a few colors, ones that the big hadoop vendors are known by.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt; bq. I think the UI which used to look decent now looks pretty ugly. Can we go back to just white and grey and be done with it?&lt;/p&gt;

&lt;p&gt;Let me do this.  In general, as per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cos&quot; class=&quot;user-hover&quot; rel=&quot;cos&quot;&gt;Konstantin Boudnik&lt;/a&gt;, I like a bit of color, let me put up a grey so we can be done.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

</comment>
                            <comment id="13886276" author="sureshms" created="Thu, 30 Jan 2014 05:46:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, coming to think of it, color is such a personal preference. I have no problems if you want to commit the patch as is.&lt;/p&gt;

&lt;p&gt;Enough time wasted. +1 for the patch from me.&lt;/p&gt;</comment>
                            <comment id="13886281" author="stack" created="Thu, 30 Jan 2014 06:20:43 +0000"  >&lt;p&gt;Here is what the gray looks like and the patch to implement it.&lt;/p&gt;</comment>
                            <comment id="13886284" author="stack" created="Thu, 30 Jan 2014 06:23:39 +0000"  >&lt;p&gt;Looks like I have a +1 from Suresh.  I&apos;ve tried it here.  I&apos;ll commit in a while unless objection (sorry &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cos&quot; class=&quot;user-hover&quot; rel=&quot;cos&quot;&gt;Konstantin Boudnik&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="13886286" author="cos" created="Thu, 30 Jan 2014 06:25:48 +0000"  >&lt;p&gt;No worries &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; - I am artistically challenged like most engineers, anyway &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13886287" author="sureshms" created="Thu, 30 Jan 2014 06:28:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, I must say the gray looks even worse. You have the knack of making poor color choices. Please do not get into UI &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Your new effort has convinced me that the orange scheme was better &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; +1 for that.&lt;/p&gt;</comment>
                            <comment id="13886291" author="cos" created="Thu, 30 Jan 2014 06:32:48 +0000"  >&lt;p&gt;Told ya guys - orange is awesome. Looks like I am less artistically challenged than &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/biggrin.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13886333" author="sureshms" created="Thu, 30 Jan 2014 06:48:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cos&quot; class=&quot;user-hover&quot; rel=&quot;cos&quot;&gt;Konstantin Boudnik&lt;/a&gt;, hope your liking for it is not because of Wandisco orange &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13886341" author="stack" created="Thu, 30 Jan 2014 07:01:42 +0000"  >&lt;p&gt;Sorry lads.&lt;/p&gt;</comment>
                            <comment id="13886353" author="wheat9" created="Thu, 30 Jan 2014 07:29:01 +0000"  >&lt;p&gt;Although I&apos;m not an HCI expert at all, but I think it is worthwhile to document the rationale of how the original colors are chosen.&lt;/p&gt;

&lt;p&gt;If you look at the original colors at the HSL space. They have the same hues (ignoring the rounding), with different values of saturation and light. The intervals between them are identical to the ones on &lt;a href=&quot;http://getbootstrap.com&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://getbootstrap.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hue decides the primary color (i.e., green, yellow, orange). Green is chosen because the color theory suggests that green color gives an impression of stability and relaxation. Another reason is that from the HCI prospective, cold color schemes (e.g., green / blue backgrounds + white text) usually have good visibility on computer screens.&lt;/p&gt;

&lt;p&gt;It is usually easy to see some code is better than the other, but it is subjective and subtle to tell which color is superior. I&apos;m pretty open on what color schemes should be used in the UI, and I understand everybody has his / her favorite colors and I fully respect their choices. I sincerely appreciate putting the time to reasoning about the changes from the HCI prospective so that the end-users can have the best experience.&lt;/p&gt;</comment>
                            <comment id="13886355" author="stack" created="Thu, 30 Jan 2014 07:29:21 +0000"  >&lt;p&gt;This is green, as it was, only darkened so it is away from the problematic part of the green spectrum.  This is what I will commit in the morning believing it the least controversial offering unless I hear otherwise.  Thanks.&lt;/p&gt;
</comment>
                            <comment id="13886371" author="cos" created="Thu, 30 Jan 2014 08:03:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;hope your liking for it is not because of Wandisco orange&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Damn, you totally figured me out. Now I can&apos;t help but wonder why did I get me 2 of those orange dial divers a few years ago?  Musta been sensing my career path.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Do you have paranoia?&lt;/li&gt;
	&lt;li&gt;Yes. Who told you?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886698" author="daryn" created="Thu, 30 Jan 2014 15:59:49 +0000"  >&lt;p&gt;Maybe this would be a good vendor-neutral color palette.  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Didn&apos;t view it but I think it&apos;s right.&lt;/p&gt;</comment>
                            <comment id="13886702" author="revans2" created="Thu, 30 Jan 2014 16:05:26 +0000"  >&lt;p&gt;+1 for &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5852&quot; title=&quot;Change the colors on the hdfs UI&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5852&quot;&gt;&lt;del&gt;HDFS-5852&lt;/del&gt;&lt;/a&gt;.best.txt.  I love purple (Y!) &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                            <comment id="13886709" author="stack" created="Thu, 30 Jan 2014 16:10:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; Thanks for the rationale.  I missed it last night.  Helps.  Gives the choice of color a provenance (I thought it some innocent random pick from the color palate).  Does the result make you think of a popular Hadoop vendor when viewed with other than a creator&apos;s eyes?  You think we should just hold the original color?  Or any opinion on the few uploaded?  Thanks.&lt;/p&gt;</comment>
                            <comment id="13886844" author="wheat9" created="Thu, 30 Jan 2014 18:06:01 +0000"  >&lt;p&gt;I&apos;ve uploaded color-rationale.png to visualize the intervals of the original color scheme.&lt;/p&gt;</comment>
                            <comment id="13886984" author="wheat9" created="Thu, 30 Jan 2014 19:48:06 +0000"  >&lt;p&gt;(Disclaimer: I&apos;m not an HCI expert, so please see the comments where it fits.)&lt;/p&gt;

&lt;p&gt;As I have said, the preferences of colors are highly subjective. Every people have their own interpretations of colors. It is understandable that people (especially software engineers like us) associate a particular color to the logos they see everyday.&lt;/p&gt;

&lt;p&gt;However, I suspect that the end-users (which are a much wider audiences) generally share the same interpretations as we had here. Therefore, if I had to choose some color for the UI I would start with two things in mind:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;The impressions of the colors of general populations, which are throughly studied in arts and architectures for centuries (e.g., green -&amp;gt; stability, red -&amp;gt; attacking, orange -&amp;gt; hot)&lt;/li&gt;
	&lt;li&gt;The color intervals chosen by one of the most popular front-end framework (i.e. bootstrap). The theory behind it has been quantitively studied for about 50 years [1].&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;After that you&apos;ll need to balance the style, visibility, etc.&lt;/p&gt;

&lt;p&gt;The original color is chosen to balance the visibility of the texts and the dropdown icon. Both of them can have two different colors with different lightness. The color harmony for all these cases [2] is achieved only through multiple trails. What I have learned so far is that the subtle issues do matter &amp;#8211; therefore I respect the ones that can get the issues right (like Bootstrap) and follow their leads.&lt;/p&gt;

&lt;p&gt;As I have said, I understand everybody has his / her own favorite color. My focus here is to promote the reasoning behind the choices. I&apos;m pretty open to the color schemes for the UI. I&apos;m okay on changing the color if someone raises the concern that the colors can be misinterpreted &amp;#8211; as long as the choice that has been well thought through.&lt;/p&gt;

&lt;p&gt;Picking the politically correct color, however, is not my focus and I sincerely believe that it should not be the focus of this jira either.&lt;/p&gt;

&lt;p&gt;References:&lt;/p&gt;

&lt;p&gt;1. Antal Nemcsics. Experimental Determination of Laws of Color Harmony. Part 1: Harmony Content of Different Scales with Similar Hue. In COLOR research and application, 2007.&lt;br/&gt;
2.Anders H&#229;rd, Lars Sivik. A Theory of Colors in Combination&#8212;A Descriptive Model Related to the NCS Color-Order System. In COLOR research and application, 1999.&lt;/p&gt;</comment>
                            <comment id="13887020" author="stack" created="Thu, 30 Jan 2014 20:31:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wheat9&quot; class=&quot;user-hover&quot; rel=&quot;wheat9&quot;&gt;Haohui Mai&lt;/a&gt; Thanks for the input.  Not sure how to react.  That color is subjective I &apos;know&apos; instinctively and this subjectivity is recognized and is at the root of the original question asked by me out on the mailing list where I solicit if I am the only one having the reaction that, &quot;these colors seem way to close to the signature HWX colors&quot;.   It seemed to me like a pretty basic question and it shouldn&apos;t take color theory making an answer.&lt;/p&gt;

&lt;p&gt;While you might ask that we avoid &apos;political correctness&apos;, as you call it, we do have an obligation to keep our work conflict-free, even though it require that we operate in areas in which we are inexpert: design or &apos;branding&apos;, to name two pertinent domains here.&lt;/p&gt;

&lt;p&gt;Let me close this issue as LATER.  Here is why:&lt;/p&gt;

&lt;p&gt;My original question gleaned one direct answer only if I am making a proper accounting and though the judgement was passed on a low-fidelity copy, a PNG screen shot, the opinion was similar to what I had posited, that the banner color is &apos;darker&apos; (I&apos;ll not infer any more than this).  My survey out on the mailing list has been distorted so I do not expect any more opinions to come in via that channel.  Asking the question here a few more times has not elicited any additional opinions.  I&apos;m not in the game of committing patches unless clean agreement.  That is lacking here.&lt;/p&gt;

&lt;p&gt;Let me also close this issue because this arena is a minefield whether it is engineers making design choices (though I like the orange too and counting my vote, it has 4x+1) but also, this is a minefield in that we do not yet seem up to talking about the issue in a civil manner.&lt;/p&gt;

&lt;p&gt;Finally I&apos;m closing this issue because I don&apos;t care that much about the color, whether or which, not enough to drive further along this contrib.  I was just wondering...&lt;/p&gt;

&lt;p&gt;This issue has been good in that the provenance of the chosen color has been surfaced and can be put under the nose of anyone who might have my reaction in the future.  I also now know who I need to consult when color stumped going forward.&lt;/p&gt;

&lt;p&gt;Thanks all for your contribs here.&lt;/p&gt;</comment>
                            <comment id="13887557" author="owen.omalley" created="Fri, 31 Jan 2014 07:56:22 +0000"  >&lt;p&gt;Just to show how &lt;b&gt;inane&lt;/b&gt; this is jira is, here are the colors measurements of Hortonwork&apos;s green, Cloudera Blue, and the original color using Mac&apos;s digital color meter:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Attribute &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Hortonworks Green &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; HDFS Color &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Cloudera Blue &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; L &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 69.52 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.94 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 34.4 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; A &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -44.68 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -22.34 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -17.68 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; B &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 60.91 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26.88 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -19.98 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;so Hortonworks Green - HDFS Color = 35.58 + 22.34 + 34.03 = 91.95&lt;br/&gt;
and Cloudera Blue - HDFS Color = 0.46 + 4.66 + 46.86 = 51.98&lt;/p&gt;

&lt;p&gt;Clearly we need to make the color greener to denote additional stability.&lt;/p&gt;</comment>
                            <comment id="13888089" author="cos" created="Fri, 31 Jan 2014 19:51:10 +0000"  >&lt;p&gt;Well, I am not even sure why the colors are set by PNG background file to start with. HDFS UI doesn&apos;t carry on any graphical elements and all the coloring stuff should be controlled via a CSS of some kind. Hence, anyone can tweak for their own liking.&lt;/p&gt;</comment>
                            <comment id="13888289" author="tucu00" created="Fri, 31 Jan 2014 23:15:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt;, you should leave Oozie&apos;s logo color outside of this discussion. If you have any concern please bring it directly to the Oozie community and/or Oozie PMC. Though, before you do so, let me remind you &lt;del&gt;in case you forgot or didn&apos;t know&lt;/del&gt; that Oozie&apos;s logo was created sometime in 2009 by Yahoo employees (which incidentally were not involved in Oozie development) and they may have not even been aware of Cloudera&apos;s existence then.&lt;/p&gt;</comment>
                            <comment id="13888768" author="stack" created="Sat, 1 Feb 2014 22:36:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; Your &quot;gang colors&quot; dissection seems to be missing connecting argument.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12692211">HADOOP-10311</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626116" name="HDFS-5852.best.txt" size="928" author="daryn" created="Thu, 30 Jan 2014 15:59:49 +0000"/>
                            <attachment id="12626060" name="HDFS-5852v2.txt" size="928" author="stack" created="Thu, 30 Jan 2014 06:20:43 +0000"/>
                            <attachment id="12626069" name="HDFS-5852v3-dkgreen.txt" size="943" author="stack" created="Thu, 30 Jan 2014 07:29:21 +0000"/>
                            <attachment id="12626068" name="color-rationale.png" size="121485" author="wheat9" created="Thu, 30 Jan 2014 07:29:01 +0000"/>
                            <attachment id="12626059" name="compromise_gray.png" size="70794" author="stack" created="Thu, 30 Jan 2014 06:20:43 +0000"/>
                            <attachment id="12626070" name="dkgreen.png" size="65749" author="stack" created="Thu, 30 Jan 2014 07:29:21 +0000"/>
                            <attachment id="12626023" name="hdfs-5852.txt" size="1499" author="stack" created="Thu, 30 Jan 2014 00:20:16 +0000"/>
                            <attachment id="12626025" name="new_hdfsui_colors.png" size="105953" author="stack" created="Thu, 30 Jan 2014 00:22:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 00:27:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370790</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370779</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5851] Support memory as a storage medium</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5851</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Memory can be used as a storage medium for smaller/transient files for fast write throughput.&lt;/p&gt;

&lt;p&gt;More information/design will be added later.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692183">HDFS-5851</key>
            <summary>Support memory as a storage medium</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12685453">HDFS-5682</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="arpitagarwal">Arpit Agarwal</assignee>
                                    <reporter username="arpitagarwal">Arpit Agarwal</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 23:50:50 +0000</created>
                <updated>Fri, 31 Jan 2014 02:56:14 +0000</updated>
                                            <version>3.0.0</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="13886212" author="cmccabe" created="Thu, 30 Jan 2014 03:05:25 +0000"  >&lt;p&gt;Hi Arpit,&lt;/p&gt;

&lt;p&gt;I don&apos;t know if you were present for some of the discussions around in-memory caching and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4949&quot; title=&quot;Centralized cache management in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4949&quot;&gt;&lt;del&gt;HDFS-4949&lt;/del&gt;&lt;/a&gt;.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4949?focusedCommentId=13707389&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13707389&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-4949?focusedCommentId=13707389&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13707389&lt;/a&gt;  for some discussion around this.&lt;/p&gt;

&lt;p&gt;In the past, we&apos;ve talked about having a &quot;transient tier&quot; for files that we write, but don&apos;t necessarily want to put on-disk.  I think many applications would choose to write to a tier that would put stuff into memory if space was available, but if not, would spill it to disk.  It&apos;s crucial to implement spilling, though.  Otherwise, we make the applications worry about how much memory is left on the DataNode, which I think would lead to limited adoption.  In this sense, memory gets used as a temporary area during a job, not so much a &quot;storage area&quot; (at least that&apos;s how I look at it.)  Does this line up with your thinking in this area?&lt;/p&gt;</comment>
                            <comment id="13887111" author="arpitagarwal" created="Thu, 30 Jan 2014 21:48:41 +0000"  >&lt;p&gt;I have not given much thought to the specifics except that it would fit within the Heterogeneous Storage framework.&lt;/p&gt;

&lt;p&gt;Spilling writes is an interesting idea. It could be done with extensions to &lt;em&gt;Storage Preferences&lt;/em&gt;. Or we don&apos;t spill writes silently and limit memory consumption with the quota extensions we described in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2832&quot; title=&quot;Enable support for heterogeneous storages in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2832&quot;&gt;HDFS-2832&lt;/a&gt;. DFSClient or the app could handle the failure.&lt;/p&gt;

&lt;p&gt;Do you see overlap with your CCM work?&lt;/p&gt;</comment>
                            <comment id="13887408" author="cmccabe" created="Fri, 31 Jan 2014 02:56:14 +0000"  >&lt;p&gt;The &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4949&quot; title=&quot;Centralized cache management in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4949&quot;&gt;&lt;del&gt;HDFS-4949&lt;/del&gt;&lt;/a&gt; work was centered around caching small, often-used files that were already stored durably to disk.  If we supported a &quot;temporary / non-durable&quot; storage tier, there would be some overlap with internal implementation, but probably not much with interface.  We should probably have a conference call about this at some point.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 03:05:25 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370780</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370769</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5850] DNS Issues during TrashEmptier initialization can silently leave it non-functional</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5850</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=knoguchi&quot; class=&quot;user-hover&quot; rel=&quot;knoguchi&quot;&gt;Koji Noguchi&lt;/a&gt; recently noticed that the trash directories of a restarted cluster were not cleaned up. It turned out that it was caused by a transient DNS problem during initialization.&lt;/p&gt;

&lt;p&gt;TrashEmptier thread in namenode is actually a FileSystem client running in a loop, which makes RPC calls to itself in order  to list, rename and delete trash files.  In a secure setup, the client needs to create the right service principal name for the namenode for making a RPC connection. If there is a DNS issue at that moment, the SPN ends up with the IP address, not the fqdn.&lt;/p&gt;

&lt;p&gt;Since KDC does not recognize this SPN, TrashEmptier does not work from that point on. I verified that the SPN with the IP address was what the TrashEmptier thread asked KDC for a service ticket for.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692142">HDFS-5850</key>
            <summary>DNS Issues during TrashEmptier initialization can silently leave it non-functional</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="kihwal">Kihwal Lee</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 21:28:28 +0000</created>
                <updated>Thu, 30 Jan 2014 15:06:44 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 15:06:44 +0000</resolved>
                                    <version>0.23.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13885974" author="daryn" created="Wed, 29 Jan 2014 23:15:54 +0000"  >&lt;p&gt;I&apos;m not sure this issue affects 2.x.  In 0.23, the client pre-constructs the kerberos service principal and caches it in the ConnectionId.  All subsequent connections use a cached Connection which in turn reuses the cached principal in the ConnectionId.  Thus, if the principal is misconstructed it will never recover.&lt;/p&gt;

&lt;p&gt;RPCv9 in 2.x should recover.  The client no longer preconstructs and caches the principal.  It verifies the principal advertised by the server.  If a transient DNS resolve failure occurs, the _HOST substitution in the service principal key will indeed yield a principal with an IP.  The client will reject the advertised principal because it doesn&apos;t match (ip vs hostname).  However, subsequent connections will attempt to reverify the advertised principal which involves a new DNS resolve.  The client should recover when DNS recovers.&lt;/p&gt;</comment>
                            <comment id="13886645" author="kihwal" created="Thu, 30 Jan 2014 15:06:44 +0000"  >&lt;p&gt;I don&apos;t think we need to fix this in 0.23, if it is already fixed in 2.x.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 29 Jan 2014 23:15:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370739</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370731</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5849] Removing ACL from an inode fails if it has only a default ACL.</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5849</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;When removing an ACL, the logic must restore the group permission previously stored in an ACL entry back into the group permission bits.  The logic for this in &lt;tt&gt;AclTransformation#removeINodeAcl&lt;/tt&gt; assumes that the group entry must be found in the former ACL.  This is not the case when removing the ACL from an inode that only had a default ACL and not an access ACL.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692135">HDFS-5849</key>
            <summary>Removing ACL from an inode fails if it has only a default ACL.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 20:44:36 +0000</created>
                <updated>Fri, 31 Jan 2014 18:34:30 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 18:34:30 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13886349" author="cnauroth" created="Thu, 30 Jan 2014 07:18:10 +0000"  >&lt;p&gt;I&apos;m attaching a patch that fixes the bug in &lt;tt&gt;AclStorage#removeINodeAcl&lt;/tt&gt; by checking that the ACL entries are for an access ACL (not just a default ACL) before attempting to restore the group permission bits.  I&apos;ve also added a new test that demonstrates the problem.&lt;/p&gt;</comment>
                            <comment id="13887349" author="arpitagarwal" created="Fri, 31 Jan 2014 01:30:30 +0000"  >&lt;p&gt;Hi Chris, the reason &lt;tt&gt;removeINodeAcl&lt;/tt&gt; can&apos;t just use &lt;tt&gt;perm.getGroupAction()&lt;/tt&gt; is because that has the mask already applied, and you don&apos;t want that?&lt;/p&gt;</comment>
                            <comment id="13887522" author="cnauroth" created="Fri, 31 Jan 2014 06:40:53 +0000"  >&lt;p&gt;Hi, Arpit.  When an access ACL is added to an inode, that ACL must include a mask entry, either provided by the user or calculated automatically as the union of the perms on the unnamed group entry, the named user entries, and the named group entries.  Those mask perms get stored into the group permission bits of the &lt;tt&gt;FsPermission&lt;/tt&gt;.  The mask perms might be different from the actual group perms, due to the logic described above for mask calculation.  The group perms need to go somewhere else, so they get stored in an unnamed group ACL entry in the &lt;tt&gt;AclFeature&lt;/tt&gt;.  Later, if the ACL is removed from the inode, then it would be incorrect to leave the old ACL&apos;s mask perms sitting in the group permission bits of the &lt;tt&gt;FsPermission&lt;/tt&gt;.  Those perms might not be the same as the group perms.  Instead, we need to restore the correct group perms from the old unnamed group ACL entry back into the &lt;tt&gt;FsPermission&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Now to further complicate things, it&apos;s possible that an inode&apos;s &lt;tt&gt;AclFeature&lt;/tt&gt; contains no access ACL (the ACL used during permission checks) and instead contains just a default ACL (defines the ACL that newly created files and sub-directories automatically receive).  This case is handled incorrectly in the current &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; codebase, and this patch fixes the bug.  When there is no access ACL, the &lt;tt&gt;FsPermission&lt;/tt&gt; bits alone define the outcome of permission checks.  The group permission bits already have the expected value, so there is no need to restore any data back into the &lt;tt&gt;FsPermission&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;You might be wondering why we go to all this trouble of storing the mask in the group permission bits.  The reason is that it helps minimize the impact on existing APIs.  For example, the POSIX ACL model states that if someone runs &quot;chmod g-w&quot; on a file that has an ACL, then it should have the effect of removing write permissions for everyone in what they call the &quot;group class&quot;.  The &quot;group class&quot; consists of the file&apos;s group, all named users in the ACL, and all named groups in the ACL.  By keeping the mask perms in the group permission bits of &lt;tt&gt;FsPermission&lt;/tt&gt;, the existing code of &lt;tt&gt;FSNamesystem#setPermission&lt;/tt&gt; can just go ahead and write the change into the group permission bits of &lt;tt&gt;FsPermission&lt;/tt&gt;.  It doesn&apos;t realize that it&apos;s really changing the mask.  Permission checks use the intersection of the perms in the ACL entries and the perms in the mask entry to determine the effective permissions.  By changing the mask, &lt;tt&gt;FSNamesystem#setPermission&lt;/tt&gt; really effectively applies the change to all users in the group class.  Another example of this is &quot;ls&quot;, which is supposed to display the mask perms in place of the group perms for inodes that have an ACL.  Instead of changing code in a lot of places like &lt;tt&gt;getFileInfo&lt;/tt&gt; and &lt;tt&gt;globStatus&lt;/tt&gt;, we just let the existing code keep returning the group permission bits, which is really the mask for files with an ACL.&lt;/p&gt;

&lt;p&gt;Hope this helps clarify.  Thanks for reviewing, and let me know if you have any other questions.&lt;/p&gt;</comment>
                            <comment id="13887944" author="arpitagarwal" created="Fri, 31 Jan 2014 17:55:46 +0000"  >&lt;p&gt;Thanks for the detailed explanation Chris.&lt;/p&gt;

&lt;p&gt;+1 for the patch.&lt;/p&gt;</comment>
                            <comment id="13887972" author="cnauroth" created="Fri, 31 Jan 2014 18:34:30 +0000"  >&lt;p&gt;Thanks for the review, Arpit.  I committed this to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4685&quot; title=&quot;Implementation of ACLs in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4685&quot;&gt;HDFS-4685&lt;/a&gt; branch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12642003">HDFS-4685</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12692452">HDFS-5858</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12626066" name="HDFS-5849.1.patch" size="4173" author="cnauroth" created="Thu, 30 Jan 2014 07:18:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 01:30:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370732</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370724</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325671</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5848] Add rolling upgrade infomation to heartbeat response</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5848</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;When rolling upgrade is in progress, NN should inform datanodes via heartbeat responses so that datanode should create hardlinks when deleting blocks.  We only change heartbeat response here.  The datanode change will be done in a separated JIRA.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692132">HDFS-5848</key>
            <summary>Add rolling upgrade infomation to heartbeat response</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12680353">HDFS-5535</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="szetszwo">Tsz Wo (Nicholas), SZE</assignee>
                                    <reporter username="szetszwo">Tsz Wo (Nicholas), SZE</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 20:35:09 +0000</created>
                <updated>Sat, 1 Feb 2014 09:00:05 +0000</updated>
                            <resolved>Sat, 1 Feb 2014 09:00:05 +0000</resolved>
                                                    <fixVersion>HDFS-5535 (Rolling upgrades)</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13885776" author="szetszwo" created="Wed, 29 Jan 2014 20:36:32 +0000"  >&lt;p&gt;h5848_20130130.patch: adds RollingUpgradeCommand.&lt;/p&gt;</comment>
                            <comment id="13885875" author="sureshms" created="Wed, 29 Jan 2014 22:01:05 +0000"  >&lt;p&gt;Why is this a command and not a state that is always sent to DataNode? &lt;/p&gt;</comment>
                            <comment id="13885990" author="szetszwo" created="Wed, 29 Jan 2014 23:26:15 +0000"  >&lt;p&gt;Heartbeat response is called &quot;DatanodeCommand&quot; in the code.  It will keep sending RollingUpgradeCommand for every heartbeat during rolling upgrade.&lt;/p&gt;</comment>
                            <comment id="13886103" author="szetszwo" created="Thu, 30 Jan 2014 00:52:12 +0000"  >&lt;p&gt;h5848_20130130b.patch: add a rollingUpgradeInfo field to HeartbeatResponse instead of a new DatanodeCommand.&lt;/p&gt;</comment>
                            <comment id="13886108" author="sureshms" created="Thu, 30 Jan 2014 00:56:16 +0000"  >&lt;p&gt;I actually think this just be an upgrade state that is part of HeartbeatResponse instead of a separate command, much like the &lt;tt&gt;haStatus&lt;/tt&gt; member it currently has.&lt;/p&gt;</comment>
                            <comment id="13886424" author="szetszwo" created="Thu, 30 Jan 2014 08:58:30 +0000"  >&lt;p&gt;Sure, the latest patch added a field in HeartbeatResponse instead of adding a new DatanodeCommand.&lt;/p&gt;</comment>
                            <comment id="13887031" author="sureshms" created="Thu, 30 Jan 2014 20:44:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szetszwo&quot; class=&quot;user-hover&quot; rel=&quot;szetszwo&quot;&gt;Tsz Wo (Nicholas), SZE&lt;/a&gt;, do you think there is any reason for Datanode to know the complete rolling upgrade information or just rolling upgrade in progress true/false is sufficient?&lt;/p&gt;</comment>
                            <comment id="13887500" author="szetszwo" created="Fri, 31 Jan 2014 05:49:40 +0000"  >&lt;p&gt;We also need block pool id in the response.  However, RollingUpgradeInfo may contain other information datanode does not need.  Let&apos;s add a new class, say RollingUpgradeStatus, for the response.  Then, RollingUpgradeInfo could extend it.&lt;/p&gt;</comment>
                            <comment id="13887532" author="szetszwo" created="Fri, 31 Jan 2014 06:59:28 +0000"  >&lt;p&gt;h5848_20140131.patch: add RollingUpgradeStatus and use it in HeartbeatResponse.&lt;/p&gt;</comment>
                            <comment id="13887562" author="vinayrpet" created="Fri, 31 Jan 2014 08:13:11 +0000"  >&lt;p&gt;Changes looks good. +1&lt;/p&gt;</comment>
                            <comment id="13888356" author="jingzhao" created="Sat, 1 Feb 2014 00:33:08 +0000"  >&lt;p&gt;+1 Patch looks good.&lt;/p&gt;</comment>
                            <comment id="13888496" author="szetszwo" created="Sat, 1 Feb 2014 09:00:05 +0000"  >&lt;p&gt;Thanks Vinay and Jing for reviewing the patch.&lt;/p&gt;

&lt;p&gt;I have committed this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625960" name="h5848_20130130.patch" size="10215" author="szetszwo" created="Wed, 29 Jan 2014 20:36:32 +0000"/>
                            <attachment id="12626030" name="h5848_20130130b.patch" size="18364" author="szetszwo" created="Thu, 30 Jan 2014 00:52:12 +0000"/>
                            <attachment id="12626271" name="h5848_20140131.patch" size="18115" author="szetszwo" created="Fri, 31 Jan 2014 06:59:28 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 29 Jan 2014 22:01:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370729</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370721</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5847] Consolidate INodeReference into a separate section</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5847</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Currently each INodeDirectorySection.Entry contains variable numbers of INodeReference entries. The INodeReference entries are inlined, therefore it is difficult to quickly navigate through a INodeDirectorySection.Entry. Skipping through a INodeDirectorySection.Entry without parsing is essential to parse these entries in parallel.&lt;/p&gt;

&lt;p&gt;This jira proposes to consolidate INodeReferences into a section and give each of them an ID. The INodeDirectorySection.Entry can store the list of the IDs as a repeated field. That way we can leverage the existing code in protobuf to quickly skip through a INodeDirectorySection.Entry.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12692106">HDFS-5847</key>
            <summary>Consolidate INodeReference into a separate section</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 18:53:37 +0000</created>
                <updated>Wed, 29 Jan 2014 18:53:37 +0000</updated>
                                            <version>HDFS-5698 (FSImage in protobuf)</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370703</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370695</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325854</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5846] Assigning DEFAULT_RACK in resolveNetworkLocation method can break data resiliency</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5846</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Medhod CachedDNSToSwitchMapping::resolve() can return NULL which requires careful handling. Null can be returned in two cases:&lt;br/&gt;
&#8226; An error occurred with topology script execution (script crashes).&lt;br/&gt;
&#8226; Script returns wrong number of values (other than expected)&lt;/p&gt;

&lt;p&gt;Critical handling is in the DN registration code. DN registration code is responsible for assigning proper topology paths to all registered datanodes. Existing code handles this NULL pointer on the following way (&lt;tt&gt;resolveNetworkLocation&lt;/tt&gt; method):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/ /resolve its network location
    List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; rName = dnsToSwitchMapping.resolve(names);
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; networkLocation;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (rName == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      LOG.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;The resolve call returned &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;! Using &quot;&lt;/span&gt; + 
          NetworkTopology.DEFAULT_RACK + &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; host &quot;&lt;/span&gt; + names);
      networkLocation = NetworkTopology.DEFAULT_RACK;
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      networkLocation = rName.get(0);
    }
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; networkLocation;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The line of code that is assigning default rack:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; networkLocation = NetworkTopology.DEFAULT_RACK; &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 
&lt;p&gt;can cause a serious problem. This means if somehow we got NULL, then the default rack will be assigned as a DN&apos;s network location and DN&apos;s registration will finish successfully. Under this circumstances, we will be able to load data into cluster which is working with a wrong topology. Wrong  topology means that fault domains are not honored. &lt;/p&gt;

&lt;p&gt;For the end user, it means that two data replicas can end up in the same fault domain and a single failure can cause loss of two, or more, replicas. Cluster would be in the inconsistent state but it would not be aware of that and the whole thing would work as if everything was fine. We can notice that something wrong happened almost only by looking in the log for the error:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
LOG.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;The resolve call returned &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;! Using &quot;&lt;/span&gt; + 
NetworkTopology.DEFAULT_RACK + &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; host &quot;&lt;/span&gt; + names);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment></environment>
        <key id="12692100">HDFS-5846</key>
            <summary>Assigning DEFAULT_RACK in resolveNetworkLocation method can break data resiliency</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="nikola.vujic">Nikola Vujic</assignee>
                                    <reporter username="nikola.vujic">Nikola Vujic</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jan 2014 18:37:39 +0000</created>
                <updated>Fri, 31 Jan 2014 13:25:50 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13887638" author="nikola.vujic" created="Fri, 31 Jan 2014 11:02:46 +0000"  >&lt;p&gt;I&apos;m attaching patch. I have changed &lt;tt&gt;resolveNetworkLocation&lt;/tt&gt; method to throw exception and added a new method {{resolveNetworkLocationWithFallBackToDefaultLocation} for calls that want to keep default location in a case of DNS to switch mapping failure.&lt;br/&gt;
I&apos;m adding a configuration property named: &lt;tt&gt;dfs.namenode.reject-unresolved-dn-topology-mapping&lt;/tt&gt; (default value: &lt;tt&gt;false&lt;/tt&gt;). &lt;tt&gt;registerDatanode&lt;/tt&gt; method uses this config property in order to decide whether to call &lt;tt&gt;resolveNetworkLocation&lt;/tt&gt; or &lt;tt&gt;resolveNetworkLocationWithFallBackToDefaultLocation&lt;/tt&gt; method.&lt;/p&gt;</comment>
                            <comment id="13887725" author="hadoopqa" created="Fri, 31 Jan 2014 13:25:50 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626286/hdfs-5846.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626286/hdfs-5846.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5999//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5999//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5999//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5999//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626286" name="hdfs-5846.patch" size="10236" author="nikola.vujic" created="Fri, 31 Jan 2014 11:02:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 13:25:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370697</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370689</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5845] SecondaryNameNode dies when checkpointing with cache pools</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5845</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The SecondaryNameNode clears and reloads its FSNamesystem when doing checkpointing. However, FSNamesystem#clear does not clear CacheManager state during this reload. This leads to an error like the following:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.fs.InvalidRequestException: Cache pool pool1 already exists.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691939">HDFS-5845</key>
            <summary>SecondaryNameNode dies when checkpointing with cache pools</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="andrew.wang">Andrew Wang</assignee>
                                    <reporter username="andrew.wang">Andrew Wang</reporter>
                        <labels>
                            <label>caching</label>
                    </labels>
                <created>Tue, 28 Jan 2014 23:50:02 +0000</created>
                <updated>Thu, 30 Jan 2014 13:49:10 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 00:01:02 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13884927" author="sureshms" created="Tue, 28 Jan 2014 23:52:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrew.wang&quot; class=&quot;user-hover&quot; rel=&quot;andrew.wang&quot;&gt;Andrew Wang&lt;/a&gt;, I am marking this as blocker for 2.3.0.&lt;/p&gt;</comment>
                            <comment id="13884934" author="andrew.wang" created="Wed, 29 Jan 2014 02:41:55 +0000"  >&lt;p&gt;Patch attached. This was pretty simple, but requires taking the FSN writelock on the 2NN since we have a bunch of write lock asserts in CacheManager. I think this is okay since we already do this in the SbNN, but someone should weigh in if this isn&apos;t okay.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;diff -w&lt;/tt&gt; helps with reviewing the test change, since I needed to indent a test by one.&lt;/p&gt;</comment>
                            <comment id="13885045" author="hadoopqa" created="Wed, 29 Jan 2014 06:11:14 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625772/hdfs-5845-1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625772/hdfs-5845-1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 2 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5975//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5975//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5975//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5975//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886011" author="andrew.wang" created="Wed, 29 Jan 2014 23:44:14 +0000"  >&lt;p&gt;I&apos;ll also note that I bumped the timeout on that seemingly unrelated test since it flaked twice for me at 30s.&lt;/p&gt;</comment>
                            <comment id="13886031" author="cmccabe" created="Wed, 29 Jan 2014 23:56:23 +0000"  >&lt;p&gt;Looks good to me.  +1&lt;/p&gt;</comment>
                            <comment id="13886036" author="andrew.wang" created="Thu, 30 Jan 2014 00:01:02 +0000"  >&lt;p&gt;Thanks Colin, I committed this to branch-2.3, branch-2, and trunk.&lt;/p&gt;</comment>
                            <comment id="13886049" author="hudson" created="Thu, 30 Jan 2014 00:09:01 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5063 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5063/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5063/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5845&quot; title=&quot;SecondaryNameNode dies when checkpointing with cache pools&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5845&quot;&gt;&lt;del&gt;HDFS-5845&lt;/del&gt;&lt;/a&gt;. SecondaryNameNode dies when checkpointing with cache pools. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886495" author="hudson" created="Thu, 30 Jan 2014 11:13:31 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #466 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5845&quot; title=&quot;SecondaryNameNode dies when checkpointing with cache pools&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5845&quot;&gt;&lt;del&gt;HDFS-5845&lt;/del&gt;&lt;/a&gt;. SecondaryNameNode dies when checkpointing with cache pools. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886561" author="hudson" created="Thu, 30 Jan 2014 13:29:55 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1683 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5845&quot; title=&quot;SecondaryNameNode dies when checkpointing with cache pools&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5845&quot;&gt;&lt;del&gt;HDFS-5845&lt;/del&gt;&lt;/a&gt;. SecondaryNameNode dies when checkpointing with cache pools. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886579" author="hudson" created="Thu, 30 Jan 2014 13:49:10 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1658 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5845&quot; title=&quot;SecondaryNameNode dies when checkpointing with cache pools&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5845&quot;&gt;&lt;del&gt;HDFS-5845&lt;/del&gt;&lt;/a&gt;. SecondaryNameNode dies when checkpointing with cache pools. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562644&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625772" name="hdfs-5845-1.patch" size="11886" author="andrew.wang" created="Wed, 29 Jan 2014 02:41:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 23:52:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370535</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370527</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5844] Fix broken link in WebHDFS.apt.vm</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5844</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;There is one broken link in WebHDFS.apt.vm.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
{{{RemoteException JSON Schema}}}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;should be&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
{{RemoteException JSON Schema}}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691578">HDFS-5844</key>
            <summary>Fix broken link in WebHDFS.apt.vm</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ajisakaa">Akira AJISAKA</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Tue, 28 Jan 2014 07:40:26 +0000</created>
                <updated>Wed, 29 Jan 2014 13:30:20 +0000</updated>
                            <resolved>Wed, 29 Jan 2014 05:01:25 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13883876" author="ajisakaa" created="Tue, 28 Jan 2014 08:00:42 +0000"  >&lt;p&gt;Attaching a patch.&lt;/p&gt;</comment>
                            <comment id="13883974" author="hadoopqa" created="Tue, 28 Jan 2014 10:29:55 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625540/HDFS-5844.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625540/HDFS-5844.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+0 tests included&lt;/font&gt;.  The patch appears to be a documentation patch that doesn&apos;t require tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5961//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5961//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5961//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5961//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13885005" author="arpitagarwal" created="Wed, 29 Jan 2014 05:01:25 +0000"  >&lt;p&gt;+1 for the patch. Generated site and verified it fixes the link. I committed this to trunk, branch-2 and branch-2.3&lt;/p&gt;

&lt;p&gt;Thanks for the contribution &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajisakaa&quot; class=&quot;user-hover&quot; rel=&quot;ajisakaa&quot;&gt;Akira AJISAKA&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13885013" author="hudson" created="Wed, 29 Jan 2014 05:15:12 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5057 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5057/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5057/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5844&quot; title=&quot;Fix broken link in WebHDFS.apt.vm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5844&quot;&gt;&lt;del&gt;HDFS-5844&lt;/del&gt;&lt;/a&gt;. Fix broken link in WebHDFS.apt.vm (Contributed by Akira Ajisaka) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/WebHDFS.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885032" author="ajisakaa" created="Wed, 29 Jan 2014 05:53:32 +0000"  >&lt;p&gt;Thank you for committing, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="13885240" author="hudson" created="Wed, 29 Jan 2014 11:13:46 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #465 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/465/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/465/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5844&quot; title=&quot;Fix broken link in WebHDFS.apt.vm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5844&quot;&gt;&lt;del&gt;HDFS-5844&lt;/del&gt;&lt;/a&gt;. Fix broken link in WebHDFS.apt.vm (Contributed by Akira Ajisaka) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/WebHDFS.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885331" author="hudson" created="Wed, 29 Jan 2014 13:29:38 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1682 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1682/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1682/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5844&quot; title=&quot;Fix broken link in WebHDFS.apt.vm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5844&quot;&gt;&lt;del&gt;HDFS-5844&lt;/del&gt;&lt;/a&gt;. Fix broken link in WebHDFS.apt.vm (Contributed by Akira Ajisaka) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/WebHDFS.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885336" author="hudson" created="Wed, 29 Jan 2014 13:30:20 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1657 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1657/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1657/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5844&quot; title=&quot;Fix broken link in WebHDFS.apt.vm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5844&quot;&gt;&lt;del&gt;HDFS-5844&lt;/del&gt;&lt;/a&gt;. Fix broken link in WebHDFS.apt.vm (Contributed by Akira Ajisaka) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562357&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/WebHDFS.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12672235">HDFS-5297</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625540" name="HDFS-5844.patch" size="690" author="ajisakaa" created="Tue, 28 Jan 2014 08:00:42 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 10:29:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370329</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370332</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325255</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5843] DFSClient.getFileChecksum() throws IOException if checksum is disabled</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5843</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;If a file is created with checksum disabled (using &lt;tt&gt;ChecksumOpt.disabled()&lt;/tt&gt; for example), calling &lt;tt&gt;FileSystem.getFileChecksum()&lt;/tt&gt; throws the following IOException:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.io.IOException: Fail to get block MD5 for BP-341493254-192.168.1.10-1390888724459:blk_1073741825_1001
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksum(DFSClient.java:1965)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksum(DFSClient.java:1771)
	at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1186)
	at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1194)
[...]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From the logs, the datanode is doing some wrong arithmetics because of the crcPerBlock:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-01-27 21:58:46,329 ERROR datanode.DataNode (DataXceiver.java:run(225)) - 127.0.0.1:52398:DataXceiver error processing BLOCK_CHECKSUM operation  src: /127.0.0.1:52407 dest: /127.0.0.1:52398
java.lang.ArithmeticException: / by zero
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockChecksum(DataXceiver.java:658)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opBlockChecksum(Receiver.java:169)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:77)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:221)
	at java.lang.Thread.run(Thread.java:695)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691565">HDFS-5843</key>
            <summary>DFSClient.getFileChecksum() throws IOException if checksum is disabled</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="laurentgo">Laurent Goujon</assignee>
                                    <reporter username="laurentgo">Laurent Goujon</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jan 2014 06:05:16 +0000</created>
                <updated>Fri, 31 Jan 2014 13:39:15 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 19:24:27 +0000</resolved>
                                                    <fixVersion>2.4.0</fixVersion>
                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13883803" author="laurentgo" created="Tue, 28 Jan 2014 06:08:52 +0000"  >&lt;p&gt;Attaching patch to fix the issue + test case to verify. Thanks for reviewing&lt;/p&gt;</comment>
                            <comment id="13883894" author="hadoopqa" created="Tue, 28 Jan 2014 08:26:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625529/hdfs-5843.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625529/hdfs-5843.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.TestPersistBlocks&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5960//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5960//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5960//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5960//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13885793" author="hadoopqa" created="Wed, 29 Jan 2014 20:44:28 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625529/hdfs-5843.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625529/hdfs-5843.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5978//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5978//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5978//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5978//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886913" author="jingzhao" created="Thu, 30 Jan 2014 18:54:13 +0000"  >&lt;p&gt;+1. I will commit the patch shortly. Thanks for the fix Laurent!&lt;/p&gt;</comment>
                            <comment id="13886948" author="jingzhao" created="Thu, 30 Jan 2014 19:24:27 +0000"  >&lt;p&gt;I&apos;ve committed this to trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13886954" author="hudson" created="Thu, 30 Jan 2014 19:26:19 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5071 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5071/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5071/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5843&quot; title=&quot;DFSClient.getFileChecksum() throws IOException if checksum is disabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5843&quot;&gt;&lt;del&gt;HDFS-5843&lt;/del&gt;&lt;/a&gt;. DFSClient.getFileChecksum() throws IOException if checksum is disabled. Contributed by Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFSOutputSummer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887650" author="hudson" created="Fri, 31 Jan 2014 11:14:08 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #467 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5843&quot; title=&quot;DFSClient.getFileChecksum() throws IOException if checksum is disabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5843&quot;&gt;&lt;del&gt;HDFS-5843&lt;/del&gt;&lt;/a&gt;. DFSClient.getFileChecksum() throws IOException if checksum is disabled. Contributed by Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFSOutputSummer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887734" author="hudson" created="Fri, 31 Jan 2014 13:29:54 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1684 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5843&quot; title=&quot;DFSClient.getFileChecksum() throws IOException if checksum is disabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5843&quot;&gt;&lt;del&gt;HDFS-5843&lt;/del&gt;&lt;/a&gt;. DFSClient.getFileChecksum() throws IOException if checksum is disabled. Contributed by Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFSOutputSummer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887748" author="hudson" created="Fri, 31 Jan 2014 13:39:15 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1659 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5843&quot; title=&quot;DFSClient.getFileChecksum() throws IOException if checksum is disabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5843&quot;&gt;&lt;del&gt;HDFS-5843&lt;/del&gt;&lt;/a&gt;. DFSClient.getFileChecksum() throws IOException if checksum is disabled. Contributed by Laurent Goujon. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562927&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFSOutputSummer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625529" name="hdfs-5843.patch" size="3261" author="laurentgo" created="Tue, 28 Jan 2014 06:08:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 08:26:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370316</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370319</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5842] Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5842</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Noticed this while debugging issues in another application. We saw an error when trying to do a FileSystem.get using an hftp file system on a secure cluster using a proxy user ugi.&lt;/p&gt;

&lt;p&gt;This is a small snippet used&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 FileSystem testFS = ugi.doAs(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PrivilegedExceptionAction&amp;lt;FileSystem&amp;gt;() {
            @Override
            &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; FileSystem run() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
                &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; FileSystem.get(hadoopConf);
            }
        });
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The same code worked for hdfs and webhdfs but not for hftp when the ugi used was UserGroupInformation.createProxyUser&lt;/p&gt;</description>
                <environment></environment>
        <key id="12687999">HDFS-5842</key>
            <summary>Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="arpitgupta">Arpit Gupta</reporter>
                        <labels>
                    </labels>
                <created>Thu, 9 Jan 2014 05:06:39 +0000</created>
                <updated>Thu, 30 Jan 2014 13:49:11 +0000</updated>
                            <resolved>Wed, 29 Jan 2014 22:14:24 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13866323" author="arpitgupta" created="Thu, 9 Jan 2014 05:07:46 +0000"  >&lt;p&gt;Here is the stack trace from a simple test i wrote&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ava.io.IOException: Unable to obtain remote token
        at org.apache.hadoop.hdfs.tools.DelegationTokenFetcher.getDTfromRemote(DelegationTokenFetcher.java:233)
        at org.apache.hadoop.hdfs.HftpFileSystem$2.run(HftpFileSystem.java:265)
        at org.apache.hadoop.hdfs.HftpFileSystem$2.run(HftpFileSystem.java:259)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
        at org.apache.hadoop.hdfs.HftpFileSystem.getDelegationToken(HftpFileSystem.java:259)
        at org.apache.hadoop.hdfs.HftpFileSystem.initDelegationToken(HftpFileSystem.java:205)
        at org.apache.hadoop.hdfs.HftpFileSystem.initialize(HftpFileSystem.java:194)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2433)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:88)
        at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2467)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2449)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:367)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:166)
        at org.hw.tests.ProxyUserTests$1.run(ProxyUserTests.java:122)
        at org.hw.tests.ProxyUserTests$1.run(ProxyUserTests.java:119)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
        at org.hw.tests.ProxyUserTests.getFileSystem(ProxyUserTests.java:119)
        at org.hw.tests.ProxyUserTests.testProxyUserFileSystems(ProxyUserTests.java:78)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
        at org.junit.runners.Suite.runChild(Suite.java:128)
        at org.junit.runners.Suite.runChild(Suite.java:24)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
        at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)
        at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)
        at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175)
        at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)
Caused by: java.io.IOException: Exception trying to open authenticated connection to http:/NN_HOST:50070/getDelegationToken
        at org.apache.hadoop.security.SecurityUtil.openSecureHttpConnection(SecurityUtil.java:514)
        at org.apache.hadoop.hdfs.tools.DelegationTokenFetcher.getDTfromRemote(DelegationTokenFetcher.java:222)
        ... 59 more
Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
        at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:300)
        at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:196)
        at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:232)
        at org.apache.hadoop.security.SecurityUtil.openSecureHttpConnection(SecurityUtil.java:512)
        ... 60 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
        at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:130)
        at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:106)
        at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:172)
        at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:209)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:195)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:162)
        at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:279)
        at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:255)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:255)
        ... 63 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;The same test created a hdfs, webhdfs and hftp file system and only the hftp file system failed.&lt;/p&gt;</comment>
                            <comment id="13867225" author="jingzhao" created="Thu, 9 Jan 2014 22:54:07 +0000"  >&lt;p&gt;Looks like we only need to check if the current user is a proxy user before getting a delegation token. If yes, we should use the real user. Upload a simple patch to fix.&lt;/p&gt;</comment>
                            <comment id="13867395" author="hadoopqa" created="Fri, 10 Jan 2014 01:28:15 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12622279/HADOOP-10215.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12622279/HADOOP-10215.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3417//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3417//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3417//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3417//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13879097" author="jingzhao" created="Wed, 22 Jan 2014 19:51:35 +0000"  >&lt;p&gt;Update the patch. The new patch makes sure that the DT is under the proxy user&apos;s name. &lt;/p&gt;

&lt;p&gt;I&apos;ve tested the patch in my local security setup and the patch works fine. The testing code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class TestHftpFSWithProxyUser {
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] argv) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (argv.length &amp;lt;= 1) {
      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Usage: TestHftpFSWithProxyUser fs-uri proxyUser&quot;&lt;/span&gt;);
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
    }
    
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; fsUri = argv[0];
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; proxyUserName = argv[1];
    
    UserGroupInformation real = UserGroupInformation.getCurrentUser();
    &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Get real ugi: &quot;&lt;/span&gt; + real.getShortUserName());
    
    UserGroupInformation proxy = UserGroupInformation.createProxyUser(
        proxyUserName, real);
    &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Create proxy ugi: &quot;&lt;/span&gt; + proxy.getShortUserName());
    
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Configuration conf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration();
    conf.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, fsUri);
    
    FileStatus[] status = proxy.doAs(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PrivilegedExceptionAction&amp;lt;FileStatus[]&amp;gt;() {
      @Override
      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; FileStatus[] run() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
        FileSystem fs = FileSystem.get(conf);
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; fs.listStatus(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(&lt;span class=&quot;code-quote&quot;&gt;&quot;/&quot;&lt;/span&gt;));
      }
    });
    &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;ls results: &quot;&lt;/span&gt; + Arrays.asList(status).toString());
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13879253" author="jingzhao" created="Wed, 22 Jan 2014 22:05:46 +0000"  >&lt;p&gt;Looks like HftpFileSystem#renewDelegationToken and HftpFileSystem#cancelDelegationToken need the similar fix. Update the patch to fix these two methods.&lt;/p&gt;</comment>
                            <comment id="13879277" author="hadoopqa" created="Wed, 22 Jan 2014 22:30:21 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624407/HADOOP-10215.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624407/HADOOP-10215.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3460//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3460//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3460//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3460//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883511" author="hadoopqa" created="Mon, 27 Jan 2014 23:24:11 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625416/HADOOP-10215.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625416/HADOOP-10215.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3480//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3480//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3480//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3480//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883650" author="hadoopqa" created="Tue, 28 Jan 2014 02:02:16 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625416/HADOOP-10215.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625416/HADOOP-10215.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.web.TestHttpsFileSystem&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5955//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5955//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5955//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5955//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13885626" author="jingzhao" created="Wed, 29 Jan 2014 18:28:06 +0000"  >&lt;p&gt;The failed test has been reported in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5718&quot; title=&quot;TestHttpsFileSystem intermittently fails with Port in use error&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5718&quot;&gt;HDFS-5718&lt;/a&gt; and should be unrelated.&lt;/p&gt;</comment>
                            <comment id="13885661" author="jnp" created="Wed, 29 Jan 2014 19:06:20 +0000"  >&lt;p&gt;checkTGTAndReloginFromKeytab is removed, it will cause issues once TGT expires.&lt;/p&gt;</comment>
                            <comment id="13885668" author="jingzhao" created="Wed, 29 Jan 2014 19:11:47 +0000"  >&lt;p&gt;Thanks for the review, Jitendra. So checkTGTAndReloginFromKeytab is always called in URLConnectionFactory#openConnection, which is called by getDT/renewDT/cancelDT. Thus I think we do not need to call checkTGTAndReloginFromKeytab multiple times here.&lt;/p&gt;</comment>
                            <comment id="13885685" author="jnp" created="Wed, 29 Jan 2014 19:25:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;URLConnectionFactory#openConnection, which is called by getDT/renewDT/cancelDT. Thus I think we do not need to call checkTGTAndReloginFromKeytab multiple times here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay, sounds good. +1 for the patch.&lt;/p&gt;</comment>
                            <comment id="13885893" author="hudson" created="Wed, 29 Jan 2014 22:11:53 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5061 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5061/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5061/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt;. Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/HftpFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885894" author="jingzhao" created="Wed, 29 Jan 2014 22:14:24 +0000"  >&lt;p&gt;Thanks for the review, Jitendra! I&apos;ve committed this to trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13885986" author="andrew.wang" created="Wed, 29 Jan 2014 23:25:02 +0000"  >&lt;p&gt;Should this be included in branch-2.3 as well?&lt;/p&gt;</comment>
                            <comment id="13886017" author="jingzhao" created="Wed, 29 Jan 2014 23:48:11 +0000"  >&lt;p&gt;Yeah, that will be great. Thanks Andrew!&lt;/p&gt;</comment>
                            <comment id="13886084" author="andrew.wang" created="Thu, 30 Jan 2014 00:32:39 +0000"  >&lt;p&gt;No prob, merged to branch-2.3. Thanks Jing!&lt;/p&gt;</comment>
                            <comment id="13886100" author="hudson" created="Thu, 30 Jan 2014 00:51:17 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5065 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5065/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5065/&lt;/a&gt;)&lt;br/&gt;
Update CHANGES.txt to move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt; to 2.3.0 (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886499" author="hudson" created="Thu, 30 Jan 2014 11:13:32 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #466 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&lt;/a&gt;)&lt;br/&gt;
Update CHANGES.txt to move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt; to 2.3.0 (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt;. Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/HftpFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886565" author="hudson" created="Thu, 30 Jan 2014 13:29:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1683 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&lt;/a&gt;)&lt;br/&gt;
Update CHANGES.txt to move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt; to 2.3.0 (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt;. Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/HftpFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886583" author="hudson" created="Thu, 30 Jan 2014 13:49:11 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1658 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&lt;/a&gt;)&lt;br/&gt;
Update CHANGES.txt to move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt; to 2.3.0 (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562656&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5842&quot; title=&quot;Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5842&quot;&gt;&lt;del&gt;HDFS-5842&lt;/del&gt;&lt;/a&gt;. Cannot create hftp filesystem when using a proxy user ugi and a doAs on a secure cluster. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562603&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/HftpFileSystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12622279" name="HADOOP-10215.000.patch" size="1059" author="jingzhao" created="Thu, 9 Jan 2014 22:54:07 +0000"/>
                            <attachment id="12624407" name="HADOOP-10215.001.patch" size="4159" author="jingzhao" created="Wed, 22 Jan 2014 19:51:35 +0000"/>
                            <attachment id="12625416" name="HADOOP-10215.002.patch" size="7406" author="jingzhao" created="Mon, 27 Jan 2014 20:00:41 +0000"/>
                            <attachment id="12624448" name="HADOOP-10215.002.patch" size="7406" author="jingzhao" created="Wed, 22 Jan 2014 22:05:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 9 Jan 2014 22:54:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367011</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367013</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5841] Update HDFS caching documentation with new changes</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5841</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The caching documentation is a little out of date, since it&apos;s missing description of features like TTL and expiration.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691470">HDFS-5841</key>
            <summary>Update HDFS caching documentation with new changes</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="andrew.wang">Andrew Wang</assignee>
                                    <reporter username="andrew.wang">Andrew Wang</reporter>
                        <labels>
                            <label>caching</label>
                    </labels>
                <created>Mon, 27 Jan 2014 21:18:26 +0000</created>
                <updated>Thu, 30 Jan 2014 13:49:11 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 00:18:57 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13883323" author="andrew.wang" created="Mon, 27 Jan 2014 21:20:33 +0000"  >&lt;p&gt;Patch attached, I also took the opportunity to reorg some of the content (hopefully for the better). The diff is kind of hard to review, just looking at it via &lt;tt&gt;mvn site:site&lt;/tt&gt; is probably easiest.&lt;/p&gt;</comment>
                            <comment id="13883549" author="hadoopqa" created="Tue, 28 Jan 2014 00:14:19 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625443/hdfs-5841-1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625443/hdfs-5841-1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;        &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5953//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5953//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5953//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5953//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5953//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5953//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13884561" author="cmccabe" created="Tue, 28 Jan 2014 20:29:56 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
This can also be manually specified by &lt;span class=&quot;code-quote&quot;&gt;&quot;never&quot;&lt;/span&gt;.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This seems awkward.  How about &quot;&apos;never&apos; specifies that there is no limit.&quot;&lt;/p&gt;

&lt;p&gt;+1 once that&apos;s addressed.&lt;/p&gt;</comment>
                            <comment id="13884681" author="andrew.wang" created="Tue, 28 Jan 2014 21:03:50 +0000"  >&lt;p&gt;Thanks for the review Colin, patch attached. I also updated the help text in CacheAdmin to match your recommendation.&lt;/p&gt;</comment>
                            <comment id="13884705" author="hadoopqa" created="Tue, 28 Jan 2014 21:22:38 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625660/hdfs-5841-2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625660/hdfs-5841-2.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5964//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5964//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13884716" author="andrew.wang" created="Tue, 28 Jan 2014 21:28:57 +0000"  >&lt;p&gt;Rebase, surprised this has gone stale already.&lt;/p&gt;</comment>
                            <comment id="13885838" author="cmccabe" created="Wed, 29 Jan 2014 21:32:17 +0000"  >&lt;p&gt;+1 pending jenkins&lt;/p&gt;</comment>
                            <comment id="13886027" author="hadoopqa" created="Wed, 29 Jan 2014 23:54:33 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625670/hdfs-5841-3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625670/hdfs-5841-3.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5982//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5982//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5982//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5982//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886060" author="andrew.wang" created="Thu, 30 Jan 2014 00:15:29 +0000"  >&lt;p&gt;No tests as this is a doc change. I&apos;m going to commit this shortly based on Colin&apos;s +1, thanks Colin!&lt;/p&gt;</comment>
                            <comment id="13886064" author="andrew.wang" created="Thu, 30 Jan 2014 00:18:57 +0000"  >&lt;p&gt;Committed to trunk, branch-2, branch-2.3.&lt;/p&gt;</comment>
                            <comment id="13886081" author="hudson" created="Thu, 30 Jan 2014 00:28:27 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5064 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5064/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5064/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5841&quot; title=&quot;Update HDFS caching documentation with new changes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5841&quot;&gt;&lt;del&gt;HDFS-5841&lt;/del&gt;&lt;/a&gt;. Update HDFS caching documentation with new changes. (wang) (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/CacheAdmin.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/CentralizedCacheManagement.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886501" author="hudson" created="Thu, 30 Jan 2014 11:13:32 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #466 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/466/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5841&quot; title=&quot;Update HDFS caching documentation with new changes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5841&quot;&gt;&lt;del&gt;HDFS-5841&lt;/del&gt;&lt;/a&gt;. Update HDFS caching documentation with new changes. (wang) (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/CacheAdmin.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/CentralizedCacheManagement.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886567" author="hudson" created="Thu, 30 Jan 2014 13:29:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1683 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1683/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5841&quot; title=&quot;Update HDFS caching documentation with new changes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5841&quot;&gt;&lt;del&gt;HDFS-5841&lt;/del&gt;&lt;/a&gt;. Update HDFS caching documentation with new changes. (wang) (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/CacheAdmin.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/CentralizedCacheManagement.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13886585" author="hudson" created="Thu, 30 Jan 2014 13:49:11 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1658 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1658/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5841&quot; title=&quot;Update HDFS caching documentation with new changes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5841&quot;&gt;&lt;del&gt;HDFS-5841&lt;/del&gt;&lt;/a&gt;. Update HDFS caching documentation with new changes. (wang) (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562649&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/CacheAdmin.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/CentralizedCacheManagement.apt.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625443" name="hdfs-5841-1.patch" size="15418" author="andrew.wang" created="Mon, 27 Jan 2014 21:20:33 +0000"/>
                            <attachment id="12625660" name="hdfs-5841-2.patch" size="1076712" author="andrew.wang" created="Tue, 28 Jan 2014 21:03:50 +0000"/>
                            <attachment id="12625670" name="hdfs-5841-3.patch" size="16359" author="andrew.wang" created="Tue, 28 Jan 2014 21:28:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 00:14:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370221</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370224</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5840] Follow-up to HDFS-5138 to improve error handling during partial upgrade failures</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5840</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Suresh posted some good comment in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5138&quot; title=&quot;Support HDFS upgrade in HA&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5138&quot;&gt;&lt;del&gt;HDFS-5138&lt;/del&gt;&lt;/a&gt; after that patch had already been committed to trunk. This JIRA is to address those. See the first comment of this JIRA for the full content of the review.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691464">HDFS-5840</key>
            <summary>Follow-up to HDFS-5138 to improve error handling during partial upgrade failures</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="atm">Aaron T. Myers</assignee>
                                    <reporter username="atm">Aaron T. Myers</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 20:51:07 +0000</created>
                <updated>Mon, 27 Jan 2014 20:52:11 +0000</updated>
                                            <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13883273" author="atm" created="Mon, 27 Jan 2014 20:52:11 +0000"  >&lt;p&gt;From Suresh:&lt;/p&gt;

&lt;p&gt;I am adding information about the design, the way I understand it. Let me know if I got it wrong.&lt;br/&gt;
&lt;b&gt;Upgrade preparation:&lt;/b&gt;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;New bits are installed on the cluster nodes.&lt;/li&gt;
	&lt;li&gt;The cluster is brought down.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;b&gt;Upgrade:&lt;/b&gt; For HA setup, choose one of the namenodes to initiate upgrade on and start it with -upgrade flag.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;NN performs preupgrade for all non shared storage directories by moving current to previous.tmp and creating new current.
	&lt;ul&gt;
		&lt;li&gt;Failure here is fine. NN start up fails. Next attempt at upgrade the storage directories are recovered.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;NN performs preupgrade of shared edits (NFS/JournalNodes) over RPC. JournalNodes current moved to previous.tmp and new current is created.
	&lt;ul&gt;
		&lt;li&gt;If one of the JN preupgrade fails and upgrade is reattempted, editlog directory could be lost on the JN. Restarting the JN does not fix the issue.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;NN performs upgrade of non shared edits by writing new CTIME to current and moving previous.tmp to previous.
	&lt;ul&gt;
		&lt;li&gt;If one of the JN preupgrade fails and upgrade is reattempted, editlog directory could be lost on the JN. Restarting the JN does not fix the issue.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;NN performs upgrade of shared edits (NFS/JournalNodes) over RPC. JournalNodes current has new CTIM and previous.tmp is moved to previous.&lt;/li&gt;
	&lt;li&gt;We need to document that all the JournalNodes must be up. If a JN is irrecoverably lost, configuration must be changed to exclude the JN.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;b&gt;Rollback:&lt;/b&gt; NN is started with rollback flag&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;For all the non shared directories, the NN checks for canRollBack, essentially ensures that previous directory with the right layout version exists.&lt;/li&gt;
	&lt;li&gt;For all the shared directories, the NN checks for canRollBack, essentially ensures that previous directory with the right layout version exists.&lt;/li&gt;
	&lt;li&gt;NN performs rollback for shared directories (moving previous to current)
	&lt;ul&gt;
		&lt;li&gt;If rollback of one of the JN fails, then directories are in inconsistent state. I think any attempt at retrying rollback will fail and will require manually moving files around. I do not think restarting JN fixes this.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;We need to document that all the JournalNodes must be up. If a JN is irrecoverably lost, configuration must be changed to exclude the JN.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;b&gt;Finalize:&lt;/b&gt; DFSAdmin command is run to finalize the upgrade.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Active NN performs finalizing of editlog. If JN&apos;s fail to finalize, active NN fails to finalize. However it is possible that standby finalizes, leaving the cluster in an inconsistent state.&lt;/li&gt;
	&lt;li&gt;We need to document that all the JournalNodes must be up. If a JN is irrecoverably lost, configuration must be changed to exclude the JN.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Comments on the code in the patch (this is almost complete):&lt;br/&gt;
Comments:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Minor nit: there are some white space changes&lt;/li&gt;
	&lt;li&gt;assertAllResultsEqual - for loop can just start with i = 1? Also if the collection objects is of size zero or one, the method can return early. Is there a need to do object.toArray() for these early checks? With that, perhaps the findbugs exclude may not be necessary.&lt;/li&gt;
	&lt;li&gt;Unit test can be added for methods isAtLeastOneActive, getRpcAddressesForNameserviceId and getProxiesForAllNameNodesInNameservice (I am okay if this is done in a separate jira)&lt;/li&gt;
	&lt;li&gt;Finalizing upgrade is quite tricky. Consider the following scenarios:
	&lt;ul&gt;
		&lt;li&gt;One NN is active and the other is standby - works fine&lt;/li&gt;
		&lt;li&gt;One NN is active and the other is down or all NNs - finalize command throws exception and the user will not know if it has succeeded or failed and what to do next&lt;/li&gt;
		&lt;li&gt;No active NN - throws an exception cannot finalize with no active&lt;/li&gt;
		&lt;li&gt;BlockPoolSliceStorage.java change seems unnecessary&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Why is &lt;tt&gt;throw new AssertionError(&quot;Unreachable code.&quot;);&lt;/tt&gt; in QuorumJournalManager.java methods?&lt;/li&gt;
	&lt;li&gt;FSImage#doRollBack() - when canRollBack is false after checking if non-share directories can rollback, an exception must be immediately thrown, instead of checking shared editlog. Also printing Log.info when storages can be rolled back will help in debugging.&lt;/li&gt;
	&lt;li&gt;FSEditlog#canRollBackSharedLog should accept StorageInfo instead of Storage&lt;/li&gt;
	&lt;li&gt;QuorumJournalManager#canRollBack and getJournalCTime can throw AssertionError (from DFSUtil.assertAllResultsEqual()). Is that the right exception to expose or IOException?&lt;/li&gt;
	&lt;li&gt;Namenode startup throws AssertionError with -rollback option. I think we should throw IOException, which is how all the other failures are indicated.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370215</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370218</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320356</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5839] TestWebHDFS#testNamenodeRestart fails with NullPointerException in trunk</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5839</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Here is test failure:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testNamenodeRestart(org.apache.hadoop.hdfs.web.TestWebHDFS)  Time elapsed: 45.206 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: There are 1 exception(s):
  Exception 0: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        at org.apache.hadoop.hdfs.web.JsonUtil.toRemoteException(JsonUtil.java:157)
        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:315)
        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$700(WebHdfsFileSystem.java:104)
        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.getResponse(WebHdfsFileSystem.java:615)
        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:532)
        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$OffsetUrlOpener.connect(WebHdfsFileSystem.java:878)
        at org.apache.hadoop.hdfs.web.ByteRangeInputStream.openInputStream(ByteRangeInputStream.java:119)
        at org.apache.hadoop.hdfs.web.ByteRangeInputStream.getInputStream(ByteRangeInputStream.java:103)
        at org.apache.hadoop.hdfs.web.ByteRangeInputStream.read(ByteRangeInputStream.java:180)
        at java.io.FilterInputStream.read(FilterInputStream.java:83)
        at org.apache.hadoop.hdfs.TestDFSClientRetries$5.run(TestDFSClientRetries.java:954)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:724)

        at org.junit.Assert.fail(Assert.java:93)
        at org.apache.hadoop.hdfs.TestDFSClientRetries.assertEmpty(TestDFSClientRetries.java:1083)
        at org.apache.hadoop.hdfs.TestDFSClientRetries.namenodeRestartTest(TestDFSClientRetries.java:1003)
        at org.apache.hadoop.hdfs.web.TestWebHDFS.testNamenodeRestart(TestWebHDFS.java:216)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;From test output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2014-01-27 17:55:59,388 WARN  resources.ExceptionHandler (ExceptionHandler.java:toResponse(92)) - INTERNAL_SERVER_ERROR
java.lang.NullPointerException
        at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.chooseDatanode(NamenodeWebHdfsMethods.java:166)
        at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.redirectURI(NamenodeWebHdfsMethods.java:231)
        at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:658)
        at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.access$400(NamenodeWebHdfsMethods.java:116)
        at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$3.run(NamenodeWebHdfsMethods.java:631)
        at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$3.run(NamenodeWebHdfsMethods.java:626)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1560)
        at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:626)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)
        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)
        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)
        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)
        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691445">HDFS-5839</key>
            <summary>TestWebHDFS#testNamenodeRestart fails with NullPointerException in trunk</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 19:17:04 +0000</created>
                <updated>Mon, 27 Jan 2014 19:19:57 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                            <attachment id="12625409" name="org.apache.hadoop.hdfs.web.TestWebHDFS-output.txt" size="497404" author="yuzhihong@gmail.com" created="Mon, 27 Jan 2014 19:19:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370196</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370199</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5838] TestCacheDirectives#testCreateAndModifyPools fails</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5838</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testCreateAndModifyPools generates an assertion fail when it runs after testBasicPoolOperations.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Running org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 5.045 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives
test(org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives)  Time elapsed: 4.649 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected no cache pools after deleting pool
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.junit.Assert.assertFalse(Assert.java:68)
	at org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.testCreateAndModifyPools(TestCacheDirectives.java:334)
	at org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.test(TestCacheDirectives.java:160)


Results :

Failed tests: 
  TestCacheDirectives.test:160-&amp;gt;testCreateAndModifyPools:334 expected no cache pools after deleting pool
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691440">HDFS-5838</key>
            <summary>TestCacheDirectives#testCreateAndModifyPools fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="mitdesai">Mit Desai</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                            <label>java7</label>
                    </labels>
                <created>Mon, 27 Jan 2014 18:58:39 +0000</created>
                <updated>Mon, 27 Jan 2014 21:50:27 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 21:50:27 +0000</resolved>
                                    <version>3.0.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13883120" author="mitdesai" created="Mon, 27 Jan 2014 19:04:29 +0000"  >&lt;p&gt;testBasicPoolOperations creates a pool &quot;pool2&quot; which gets never removed.&lt;/p&gt;

&lt;p&gt;This pool pops up in the when the testCreateAndModifyPools checks for existing pools and gets an assertion fail&lt;/p&gt;</comment>
                            <comment id="13883130" author="mitdesai" created="Mon, 27 Jan 2014 19:10:14 +0000"  >&lt;p&gt;I think the failure will be intermittent. If these tests would run in opposite order the assertion error may not pop up. Adding a label &quot;java7&quot; so that it can be tracked as a JDK7 issue&lt;/p&gt;</comment>
                            <comment id="13883341" author="hadoopqa" created="Mon, 27 Jan 2014 21:28:21 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625405/HDFS-5838.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625405/HDFS-5838.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 eclipse:eclipse&lt;/font&gt;.  The patch failed to build with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;        &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5951//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5951//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5951//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5951//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5951//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5951//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883385" author="mitdesai" created="Mon, 27 Jan 2014 21:50:27 +0000"  >&lt;p&gt;The setup and teardown functions that run before and after the tests respectively happens to solve the problem.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625405" name="HDFS-5838.patch" size="703" author="mitdesai" created="Mon, 27 Jan 2014 19:04:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Jan 2014 21:28:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370191</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370194</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5837] dfs.namenode.replication.considerLoad does not consider decommissioned nodes</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5837</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In DefaultBlockPlacementPolicy, there is a setting dfs.namenode.replication.considerLoad which tries to balance the load of the cluster when choosing replica locations.  This code does not take into account decommissioned nodes.&lt;/p&gt;

&lt;p&gt;The code for considerLoad calculates the load by doing:  TotalClusterLoad / numNodes.  However, numNodes includes decommissioned nodes (which have 0 load).  Therefore, the average load is artificially low.  Example:&lt;/p&gt;

&lt;p&gt;TotalLoad = 250&lt;br/&gt;
numNodes = 100&lt;br/&gt;
decommissionedNodes = 70&lt;br/&gt;
remainingNodes = numNodes - decommissionedNodes = 30&lt;/p&gt;

&lt;p&gt;avgLoad = 250/100 = 2.50&lt;br/&gt;
trueAvgLoad = 250 / 30 = 8.33&lt;/p&gt;

&lt;p&gt;If the real load of the remaining 30 nodes is (on average) 8.33, this is more than 2x the calculated average load of 2.50.  This causes these nodes to be rejected as replica locations. The final result is that all nodes are rejected, and no replicas can be placed.  &lt;/p&gt;

&lt;p&gt;See exceptions printed from client during this scenario: &lt;a href=&quot;https://gist.github.com/bbeaudreault/49c8aa4bb231de54e9c1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://gist.github.com/bbeaudreault/49c8aa4bb231de54e9c1&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691438">HDFS-5837</key>
            <summary>dfs.namenode.replication.considerLoad does not consider decommissioned nodes</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="taoluo">Tao Luo</assignee>
                                    <reporter username="bbeaudreault">Bryan Beaudreault</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 18:45:42 +0000</created>
                <updated>Fri, 31 Jan 2014 00:30:30 +0000</updated>
                                            <version>2.0.0-alpha</version>
                    <version>2.0.6-alpha</version>
                    <version>2.2.0</version>
                                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370189</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370192</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5836] TestHASafeMode#testBlocksAddedWhenStandbyIsDown fails intermittently on Branch2</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5836</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This is an intermittent failure. Seems like a JDK7 issue. I did some initial research and found that the test always fails when it runs the following tests in order.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;	  testBlocksRemovedBeforeStandbyRestart
	  testSafeBlockTracking
	  testBlocksAddedWhileStandbyIsDown
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The test fails with the following error&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Running org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 20.115 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
test(org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode)  Time elapsed: 19802 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: Bad safemode status: &apos;Safe mode is ON. The reported blocks 21 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 3 has reached the minimum number 0. Safe mode will be turned off automatically in 28 seconds.&apos;
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.assertSafeMode(TestHASafeMode.java:493)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testBlocksAddedWhileStandbyIsDown(TestHASafeMode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.test(TestHASafeMode.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:242)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:137)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)


Results :

Failed tests:   test(org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode): Bad safemode status: &apos;Safe mode is ON. The reported blocks 21 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 3 has reached the minimum number 0. Safe mode will be turned off automatically in 28 seconds.&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691413">HDFS-5836</key>
            <summary>TestHASafeMode#testBlocksAddedWhenStandbyIsDown fails intermittently on Branch2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                            <label>java7</label>
                    </labels>
                <created>Mon, 27 Jan 2014 16:35:12 +0000</created>
                <updated>Mon, 27 Jan 2014 16:35:12 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370164</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370167</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5835] Add a new option for starting standby NN when rolling upgrade is in progress</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5835</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;When rolling upgrade is already in-progress and the standby NN is not yet started up, a new startup option is needed for the standby NN to initialize the upgrade status.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691323">HDFS-5835</key>
            <summary>Add a new option for starting standby NN when rolling upgrade is in progress</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12680353">HDFS-5535</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="szetszwo">Tsz Wo (Nicholas), SZE</assignee>
                                    <reporter username="szetszwo">Tsz Wo (Nicholas), SZE</reporter>
                        <labels>
                    </labels>
                <created>Mon, 27 Jan 2014 07:34:07 +0000</created>
                <updated>Thu, 30 Jan 2014 16:08:18 +0000</updated>
                            <resolved>Tue, 28 Jan 2014 05:41:50 +0000</resolved>
                                                    <fixVersion>HDFS-5535 (Rolling upgrades)</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13882618" author="szetszwo" created="Mon, 27 Jan 2014 07:38:26 +0000"  >&lt;p&gt;h5835_20130127.patch: add a new &quot;started&quot; rolling upgrade startup option.&lt;/p&gt;

&lt;p&gt;Note that document will be updated in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5778&quot; title=&quot;Document new commands and parameters for improved rolling upgrades&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5778&quot;&gt;HDFS-5778&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13883512" author="arpitagarwal" created="Mon, 27 Jan 2014 23:25:15 +0000"  >&lt;p&gt;+1 for the patch.&lt;/p&gt;</comment>
                            <comment id="13883558" author="jingzhao" created="Tue, 28 Jan 2014 00:23:55 +0000"  >&lt;p&gt;+1 the Patch looks good to me.&lt;/p&gt;

&lt;p&gt;Some questions not related to the patch: &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;So when we start the SBN, the SBN already has been upgraded?&lt;/li&gt;
	&lt;li&gt;Is it possible that the NN failover just happens when we start the SBN? Or the other NN is in standby state at this time, and this NN will become active in the end? In that case this &quot;STARTED&apos; option may also be applied to the ANN?&lt;/li&gt;
	&lt;li&gt;If we allow SBN to do checkpoint during the rolling upgrade, the SBN may not hit the upgrade marker in the editlog when it restarts. Thus the current document said we would disable the checkpoint. But this may also cause issue if the time between &quot;start&quot; and &quot;finalize&quot; is long. Since we do not delete old editlog and fsimage during checkpointing, an alternative way is to scan the editlog even across the fsimage?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13883627" author="szetszwo" created="Tue, 28 Jan 2014 01:40:20 +0000"  >&lt;p&gt;Thanks Arpit and Jing for reviewing the patch.&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;Yes.  See also #2 below.&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;Suppose NN1 is active and NN2 is standby.  NN2 will be updated first.  Then NN1 will failover to NN2.  And then NN1 will be updated.&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;SBN should do checkpoint only before the update marker.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I add tests for the cases above.&lt;/p&gt;</comment>
                            <comment id="13883786" author="szetszwo" created="Tue, 28 Jan 2014 05:41:50 +0000"  >&lt;p&gt;I have committed this.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12692303">HDFS-5855</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12688961">HDFS-5778</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625331" name="h5835_20130127.patch" size="12555" author="szetszwo" created="Mon, 27 Jan 2014 07:38:26 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Jan 2014 23:25:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370074</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370077</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5834] TestCheckpoint#testCheckpoint may fail due to Bad value assertion</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5834</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;I saw the following when running test suite on Linux:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testCheckpoint(org.apache.hadoop.hdfs.server.namenode.TestCheckpoint)  Time elapsed: 3.058 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: Bad value &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; metric GetImageNumOps
Expected: gt(0)
     got: &amp;lt;0L&amp;gt;

        at org.junit.Assert.assertThat(Assert.java:780)
        at org.apache.hadoop.test.MetricsAsserts.assertCounterGt(MetricsAsserts.java:318)
        at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpoint(TestCheckpoint.java:1058)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691277">HDFS-5834</key>
            <summary>TestCheckpoint#testCheckpoint may fail due to Bad value assertion</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Sun, 26 Jan 2014 17:36:33 +0000</created>
                <updated>Sun, 26 Jan 2014 17:36:33 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370028</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370031</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5833] SecondaryNameNode have an incorrect java doc</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5833</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;SecondaryNameNode have an incorrect java doc, actually the SecondaryNameNode uses the &lt;b&gt;NamenodeProtocol&lt;/b&gt; to talk to the primary NameNode, not the &lt;b&gt;ClientProtocol&lt;/b&gt;&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12691264">HDFS-5833</key>
            <summary>SecondaryNameNode have an incorrect java doc</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="zhoubangtao">Bangtao Zhou</reporter>
                        <labels>
                    </labels>
                <created>Sun, 26 Jan 2014 09:43:10 +0000</created>
                <updated>Tue, 28 Jan 2014 13:40:16 +0000</updated>
                            <resolved>Tue, 28 Jan 2014 05:15:23 +0000</resolved>
                                    <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13882247" author="zhoubangtao" created="Sun, 26 Jan 2014 09:50:20 +0000"  >&lt;p&gt;amend the Javadoc&lt;/p&gt;</comment>
                            <comment id="13882251" author="zhoubangtao" created="Sun, 26 Jan 2014 10:01:53 +0000"  >&lt;p&gt;amend Javadoc of SecondaryNameNode&lt;/p&gt;</comment>
                            <comment id="13883610" author="hadoopqa" created="Tue, 28 Jan 2014 01:17:54 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625248/HDFS-5833-1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625248/HDFS-5833-1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.TestDistributedFileSystem&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5954//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5954//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5954//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5954//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883766" author="arpitagarwal" created="Tue, 28 Jan 2014 05:15:23 +0000"  >&lt;p&gt;Thanks for the patch Bangtao. I committed this to trunk, branch-2 and branch-2.3.&lt;/p&gt;</comment>
                            <comment id="13883770" author="hudson" created="Tue, 28 Jan 2014 05:16:24 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5049 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5049/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5049/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5833&quot; title=&quot;SecondaryNameNode have an incorrect java doc&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5833&quot;&gt;&lt;del&gt;HDFS-5833&lt;/del&gt;&lt;/a&gt;. Fix incorrect javadoc in SecondaryNameNode. (Contributed by Bangtao Zhou) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884012" author="hudson" created="Tue, 28 Jan 2014 11:09:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5833&quot; title=&quot;SecondaryNameNode have an incorrect java doc&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5833&quot;&gt;&lt;del&gt;HDFS-5833&lt;/del&gt;&lt;/a&gt;. Fix incorrect javadoc in SecondaryNameNode. (Contributed by Bangtao Zhou) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884118" author="hudson" created="Tue, 28 Jan 2014 13:29:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5833&quot; title=&quot;SecondaryNameNode have an incorrect java doc&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5833&quot;&gt;&lt;del&gt;HDFS-5833&lt;/del&gt;&lt;/a&gt;. Fix incorrect javadoc in SecondaryNameNode. (Contributed by Bangtao Zhou) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884135" author="hudson" created="Tue, 28 Jan 2014 13:40:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5833&quot; title=&quot;SecondaryNameNode have an incorrect java doc&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5833&quot;&gt;&lt;del&gt;HDFS-5833&lt;/del&gt;&lt;/a&gt;. Fix incorrect javadoc in SecondaryNameNode. (Contributed by Bangtao Zhou) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561938&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625248" name="HDFS-5833-1.patch" size="916" author="zhoubangtao" created="Sun, 26 Jan 2014 10:01:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 01:17:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370015</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370018</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325255</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5832] Deadlock found in NN between SafeMode#canLeave and DatanodeManager#handleHeartbeat</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5832</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Found the deadlock during the Namenode startup. Attached jcarder report which shows the cycles about the deadlock situation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691199">HDFS-5832</key>
            <summary>Deadlock found in NN between SafeMode#canLeave and DatanodeManager#handleHeartbeat</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="rakeshr">Rakesh R</assignee>
                                    <reporter username="rakeshr">Rakesh R</reporter>
                        <labels>
                    </labels>
                <created>Sat, 25 Jan 2014 14:01:22 +0000</created>
                <updated>Sun, 26 Jan 2014 08:03:28 +0000</updated>
                            <resolved>Sun, 26 Jan 2014 08:03:28 +0000</resolved>
                                    <version>3.0.0</version>
                                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13881905" author="rakeshr" created="Sat, 25 Jan 2014 14:22:57 +0000"  >&lt;p&gt;Attaching a proposal where I have moved the namesystem.isInSafeMode(); out of datanodeMap lock. Could someone help me to validate this case. Thanks&lt;/p&gt;</comment>
                            <comment id="13881912" author="umamaheswararao" created="Sat, 25 Jan 2014 14:43:42 +0000"  >&lt;p&gt;Is this same as &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5368&quot; title=&quot;Namenode deadlock during safemode extention&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5368&quot;&gt;&lt;del&gt;HDFS-5368&lt;/del&gt;&lt;/a&gt;? That was closed as dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5132&quot; title=&quot;Deadlock in NameNode between SafeModeMonitor#run and DatanodeManager#handleHeartbeat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5132&quot;&gt;&lt;del&gt;HDFS-5132&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13881927" author="rakeshr" created="Sat, 25 Jan 2014 15:43:32 +0000"  >&lt;p&gt;Thanks Uma for the interest.&lt;br/&gt;
Looks like similar, but I could see still there is a chance of reverse locking in the code. &lt;/p&gt;

&lt;p&gt;I&apos;m seeing the following code flow like,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In one side, when running SafeModeMonitor thread, it is invoking safeMode#canLeave() by acquiring &apos;safeMode.this&apos; lock and here it is asking for the DataNodeManger#getNumLiveDataNodes by trying to acquire &apos;datanodeMap&apos; lock.&lt;/li&gt;
	&lt;li&gt;On the other side, DN heartbeat comes and DatanodeManager#handleHeartbeat() has acquired &apos;datanodeMap&apos; lock and calling namesystem#isInSafeMode(), which inturn trying to acquire &apos;safeModeInfo.this&apos; lock&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881945" author="hadoopqa" created="Sat, 25 Jan 2014 16:44:34 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625184/HDFS-5832.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625184/HDFS-5832.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5943//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5943//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5943//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5943//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13881997" author="umamaheswararao" created="Sat, 25 Jan 2014 19:15:19 +0000"  >&lt;p&gt;I have read the comments from  &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5368&quot; title=&quot;Namenode deadlock during safemode extention&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5368&quot;&gt;&lt;del&gt;HDFS-5368&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5132&quot; title=&quot;Deadlock in NameNode between SafeModeMonitor#run and DatanodeManager#handleHeartbeat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5132&quot;&gt;&lt;del&gt;HDFS-5132&lt;/del&gt;&lt;/a&gt;. It was closed because, safemode checks done under fsn lock and hb also under fsn lock. So, they were protected with fsn lock. I think because of that fix, earlier issue closed. Do you see any cases, where they are running outside of fsn lock?&lt;/p&gt;</comment>
                            <comment id="13882189" author="vinayrpet" created="Sun, 26 Jan 2014 05:51:19 +0000"  >&lt;p&gt;As mentioned in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5132&quot; title=&quot;Deadlock in NameNode between SafeModeMonitor#run and DatanodeManager#handleHeartbeat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5132&quot;&gt;&lt;del&gt;HDFS-5132&lt;/del&gt;&lt;/a&gt;, &lt;br/&gt;
Moving SafemodeMonitor#run() checks under fsn write lock, will solve the issue. &lt;/p&gt;

&lt;p&gt;1. handleHeartbeat() is always done under fsn readlock&lt;br/&gt;
2. incrementSafeBlockCount() and getNumLivedatanodes() will always will be called under writeLock().&lt;/p&gt;

&lt;p&gt;By directly seeing the synchronization order it appears to be deadlock. But its avoided by the fsn lock.&lt;br/&gt;
 I think jcarder will not identify the read-write lock mechanism.&lt;/p&gt;

&lt;p&gt;For this reason only I have made &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5368&quot; title=&quot;Namenode deadlock during safemode extention&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5368&quot;&gt;&lt;del&gt;HDFS-5368&lt;/del&gt;&lt;/a&gt; duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5132&quot; title=&quot;Deadlock in NameNode between SafeModeMonitor#run and DatanodeManager#handleHeartbeat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5132&quot;&gt;&lt;del&gt;HDFS-5132&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13882223" author="rakeshr" created="Sun, 26 Jan 2014 08:03:28 +0000"  >&lt;p&gt;Thanks again Uma and Vinay for the insight. Yeah, jcarder is not recognising the read-write locks and is giving bad report. I&apos;m closing this issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12665626">HDFS-5132</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625184" name="HDFS-5832.patch" size="1100" author="rakeshr" created="Sat, 25 Jan 2014 14:22:57 +0000"/>
                            <attachment id="12625183" name="jcarder_nn_deadlock.gif" size="23374" author="rakeshr" created="Sat, 25 Jan 2014 14:20:38 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 25 Jan 2014 14:43:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369948</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369951</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5831] TestAuditLogs#testAuditAllowedStat sometimes fails in trunk</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5831</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Running TestAuditLogs on Linux, I got:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testAuditAllowedStat[1](org.apache.hadoop.hdfs.server.namenode.TestAuditLogs)  Time elapsed: 6.677 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        at org.junit.Assert.fail(Assert.java:92)
        at org.junit.Assert.assertTrue(Assert.java:43)
        at org.junit.Assert.assertNotNull(Assert.java:526)
        at org.junit.Assert.assertNotNull(Assert.java:537)
        at org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.verifyAuditLogsRepeat(TestAuditLogs.java:312)
        at org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.verifyAuditLogs(TestAuditLogs.java:295)
        at org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.testAuditAllowedStat(TestAuditLogs.java:163)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691095">HDFS-5831</key>
            <summary>TestAuditLogs#testAuditAllowedStat sometimes fails in trunk</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 18:59:05 +0000</created>
                <updated>Fri, 24 Jan 2014 19:03:38 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13881313" author="yuzhihong@gmail.com" created="Fri, 24 Jan 2014 19:03:38 +0000"  >&lt;p&gt;Test output.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625091" name="5831-org.apache.hadoop.hdfs.server.namenode.TestAuditLogs-output.txt" size="56948" author="yuzhihong@gmail.com" created="Fri, 24 Jan 2014 19:03:38 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369844</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369847</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5830] WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. </title>
                <link>https://issues.apache.org/jira/browse/HDFS-5830</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing a another cluster (that doesn&apos;t have caching support). &lt;/p&gt;

&lt;p&gt;java.lang.IllegalArgumentException: cachedLocs should not be null, use a different constructor&lt;br/&gt;
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)&lt;br/&gt;
at org.apache.hadoop.hdfs.protocol.LocatedBlock.&amp;lt;init&amp;gt;(LocatedBlock.java:79)&lt;br/&gt;
at org.apache.hadoop.hdfs.web.JsonUtil.toLocatedBlock(JsonUtil.java:414)&lt;br/&gt;
at org.apache.hadoop.hdfs.web.JsonUtil.toLocatedBlockList(JsonUtil.java:446)&lt;br/&gt;
at org.apache.hadoop.hdfs.web.JsonUtil.toLocatedBlocks(JsonUtil.java:479)&lt;br/&gt;
at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileBlockLocations(WebHdfsFileSystem.java:1067)&lt;br/&gt;
at org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1812)&lt;br/&gt;
at org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1797)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691094">HDFS-5830</key>
            <summary>WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yzhangal">Yongjun Zhang</assignee>
                                    <reporter username="yzhangal">Yongjun Zhang</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 18:55:28 +0000</created>
                <updated>Tue, 28 Jan 2014 13:40:16 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 22:26:35 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>caching</component>
                    <component>hdfs-client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13881535" author="kihwal" created="Fri, 24 Jan 2014 23:32:19 +0000"  >&lt;p&gt;Marking it as a blocker since WebHdfsFileSystem should remain compatible.  &lt;tt&gt;toLocatedBlock()&lt;/tt&gt; should use a different version of constructor if cached location is null.&lt;/p&gt;</comment>
                            <comment id="13882532" author="andrew.wang" created="Mon, 27 Jan 2014 02:43:35 +0000"  >&lt;p&gt;You can blame me for this one. I don&apos;t remember why that precondition check is there; all we&apos;re trying to enforce is that &lt;tt&gt;this.cachedLocs&lt;/tt&gt; is not null. I think we should just weaken it to set cachedLocs to EMPTY_LOCS if the input parameter is null or empty.&lt;/p&gt;</comment>
                            <comment id="13882941" author="yzhangal" created="Mon, 27 Jan 2014 16:28:36 +0000"  >&lt;p&gt;Thanks for the comments guys. &lt;/p&gt;

&lt;p&gt;I favour the solution of relaxing the constructor to handle null &quot;cacheLocs&quot; parameter. Since the same constructor also handles null &quot;locs&quot; parameter. I just uploaded a patch to handle &quot;cachedLocs&quot; in a similar fashion as &quot;locs&quot; parameter. Thanks for reviewing.&lt;/p&gt;

</comment>
                            <comment id="13883000" author="cmccabe" created="Mon, 27 Jan 2014 17:43:19 +0000"  >&lt;p&gt;+1.  Thanks, Yongjun.&lt;/p&gt;</comment>
                            <comment id="13883097" author="hadoopqa" created="Mon, 27 Jan 2014 18:48:42 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625374/HDFS-5830.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625374/HDFS-5830.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated -12 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;        &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5949//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5949//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5949//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5949//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5949//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5949//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883429" author="cmccabe" created="Mon, 27 Jan 2014 22:16:59 +0000"  >&lt;p&gt;release audit warning is a pid file-- not relevant.  committing.&lt;/p&gt;</comment>
                            <comment id="13883464" author="yzhangal" created="Mon, 27 Jan 2014 22:47:07 +0000"  >&lt;p&gt;Thanks a lot Colin! &lt;/p&gt;

&lt;p&gt;I planned to take a look at the -1 javadoc thing. Will update later when I find something.&lt;/p&gt;</comment>
                            <comment id="13883469" author="hudson" created="Mon, 27 Jan 2014 22:49:15 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5048 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5048/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5048/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5830&quot; title=&quot;WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5830&quot;&gt;&lt;del&gt;HDFS-5830&lt;/del&gt;&lt;/a&gt;. WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. (Yongjun Zhang via Colin Patrick McCabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884013" author="hudson" created="Tue, 28 Jan 2014 11:09:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5830&quot; title=&quot;WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5830&quot;&gt;&lt;del&gt;HDFS-5830&lt;/del&gt;&lt;/a&gt;. WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. (Yongjun Zhang via Colin Patrick McCabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884119" author="hudson" created="Tue, 28 Jan 2014 13:29:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5830&quot; title=&quot;WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5830&quot;&gt;&lt;del&gt;HDFS-5830&lt;/del&gt;&lt;/a&gt;. WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. (Yongjun Zhang via Colin Patrick McCabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884136" author="hudson" created="Tue, 28 Jan 2014 13:40:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5830&quot; title=&quot;WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5830&quot;&gt;&lt;del&gt;HDFS-5830&lt;/del&gt;&lt;/a&gt;. WebHdfsFileSystem.getFileBlockLocations throws IllegalArgumentException when accessing another cluster. (Yongjun Zhang via Colin Patrick McCabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561885&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LocatedBlock.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625374" name="HDFS-5830.001.patch" size="2044" author="yzhangal" created="Mon, 27 Jan 2014 16:25:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jan 2014 23:32:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369843</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369846</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325255</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5829] TestDNFencingWithReplication fails on branch2</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5829</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Running org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.097 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
testFencingStress(org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication)  Time elapsed: 6 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.ExceptionInInitializerError
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication.&amp;lt;clinit&amp;gt;(TestDNFencingWithReplication.java:49)
	... 28 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12691085">HDFS-5829</key>
            <summary>TestDNFencingWithReplication fails on branch2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="5">Cannot Reproduce</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 18:07:38 +0000</created>
                <updated>Fri, 24 Jan 2014 18:56:03 +0000</updated>
                            <resolved>Fri, 24 Jan 2014 18:56:03 +0000</resolved>
                                    <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369834</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369837</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5828] BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5828</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;When placing replicas using the replica placement policy BlockPlacementPolicyWithNodeGroup, the number of targets returned should be less than or equal to the number of node groups and no node group should get two replicas of the same block. The Junit test TestReplicationPolicyWithNodeGroup.testChooseMoreTargetsThanNodeGroups verifies this.&lt;/p&gt;

&lt;p&gt;However, if the conf property &quot;dfs.namenode.avoid.write.stale.datanode&quot; is set to true, then block placement policy will return more targets than node groups when the number of replicas requested exceeds the number of node groups.&lt;/p&gt;

&lt;p&gt;This can be seen by putting:&lt;br/&gt;
       CONF.setBoolean(DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY, true);&lt;/p&gt;

&lt;p&gt;in the setup method for TestReplicationPolicyWithNodeGroup. This will cause testChooseMoreTargetsThanNodeGroups to fail.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691050">HDFS-5828</key>
            <summary>BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="buddytaylor0">Buddy</assignee>
                                    <reporter username="buddytaylor0">Buddy</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 15:05:36 +0000</created>
                <updated>Mon, 3 Feb 2014 13:39:27 +0000</updated>
                            <resolved>Sun, 2 Feb 2014 15:54:16 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13884236" author="buddytaylor0" created="Tue, 28 Jan 2014 15:14:19 +0000"  >&lt;p&gt;The failure appears to be non-deterministic.&lt;br/&gt;
In some cases the first chooseLocalStorage throws an exception and we get the message:&lt;/p&gt;

&lt;p&gt;    2014-01-28 10:12:25,981 WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(309)) - Failed to place enough replicas, still in need of 10 to reach 10. For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy&lt;/p&gt;

&lt;p&gt;When that happens, the unit test succeeds.&lt;/p&gt;

&lt;p&gt;If chooseLocalStorage finds a local storage and does not throw an exception, then the above message is not logged and the unit test fails.&lt;/p&gt;

</comment>
                            <comment id="13884251" author="buddytaylor0" created="Tue, 28 Jan 2014 15:30:49 +0000"  >&lt;p&gt;The reason that it was sometimes succeeding for me is that I was in the debugger and the node was sometimes going stale (30 seconds). If the node is not stale, then it always fails.&lt;/p&gt;

&lt;p&gt;Also node that logNodeIsNotChosen does not actually log anything, it just builds the message. The message is not logged in this case.&lt;/p&gt;

</comment>
                            <comment id="13884466" author="buddytaylor0" created="Tue, 28 Jan 2014 19:27:29 +0000"  >&lt;p&gt;The problem was BlockPlacementPolicyDefault.chooseTarget was manually adding the nodes in the results list to the excluded nodes list instead of using the addToExcludedNodes method. &lt;/p&gt;

&lt;p&gt;The addToExcludedNodes method is overridden by BlockPlacementPolicyWithNodeGroup to also exclude other nodes in the same node group.&lt;/p&gt;</comment>
                            <comment id="13886356" author="sureshms" created="Thu, 30 Jan 2014 07:30:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=djp&quot; class=&quot;user-hover&quot; rel=&quot;djp&quot;&gt;Junping Du&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szetszwo&quot; class=&quot;user-hover&quot; rel=&quot;szetszwo&quot;&gt;Tsz Wo (Nicholas), SZE&lt;/a&gt;, can you please help with this?&lt;/p&gt;</comment>
                            <comment id="13887509" author="djp" created="Fri, 31 Jan 2014 06:26:47 +0000"  >&lt;p&gt;Thanks for nice catch, Buddy! &lt;br/&gt;
Patch looks good to me overall, only a tiny thing for change on test file:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
CONF.setBoolean(DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Would you replace it to something below, so we can remove the unnecessary import as keeping consistent with other places?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
CONF.setBoolean(DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Will +1 once this is addressed.&lt;/p&gt;</comment>
                            <comment id="13887787" author="buddytaylor0" created="Fri, 31 Jan 2014 14:23:27 +0000"  >&lt;p&gt;Good point. I made the change and uploaded a new patch.&lt;br/&gt;
Thanks Junping.&lt;/p&gt;
</comment>
                            <comment id="13888513" author="djp" created="Sat, 1 Feb 2014 10:30:16 +0000"  >&lt;p&gt;Kick off Jenkins to see the test result.&lt;br/&gt;
Buddy, thanks for working on this. Next time, you can submit patch to see the test result.&lt;/p&gt;</comment>
                            <comment id="13888565" author="hadoopqa" created="Sat, 1 Feb 2014 12:56:27 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626306/HDFS-5828a.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626306/HDFS-5828a.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6008//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6008//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6008//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6008//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888905" author="hadoopqa" created="Sun, 2 Feb 2014 11:58:32 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626306/HDFS-5828a.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626306/HDFS-5828a.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6009//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6009//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6009//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6009//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13888955" author="hudson" created="Sun, 2 Feb 2014 15:46:41 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5092 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5092/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5092/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5828&quot; title=&quot;BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5828&quot;&gt;&lt;del&gt;HDFS-5828&lt;/del&gt;&lt;/a&gt;. BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true. (Buddy via junping_du) (junping_du: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888957" author="djp" created="Sun, 2 Feb 2014 15:54:16 +0000"  >&lt;p&gt;Commit patch to trunk and branch-2. Thanks Buddy for the work!&lt;/p&gt;</comment>
                            <comment id="13889107" author="szetszwo" created="Sun, 2 Feb 2014 23:38:49 +0000"  >&lt;p&gt;Buddy and Junping, thanks a lot for working on this!&lt;/p&gt;</comment>
                            <comment id="13889388" author="hudson" created="Mon, 3 Feb 2014 11:13:52 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #470 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/470/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/470/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5828&quot; title=&quot;BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5828&quot;&gt;&lt;del&gt;HDFS-5828&lt;/del&gt;&lt;/a&gt;. BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true. (Buddy via junping_du) (junping_du: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13889467" author="hudson" created="Mon, 3 Feb 2014 13:30:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1687 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1687/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1687/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5828&quot; title=&quot;BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5828&quot;&gt;&lt;del&gt;HDFS-5828&lt;/del&gt;&lt;/a&gt;. BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true. (Buddy via junping_du) (junping_du: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13889476" author="hudson" created="Mon, 3 Feb 2014 13:39:27 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1662 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1662/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1662/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5828&quot; title=&quot;BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5828&quot;&gt;&lt;del&gt;HDFS-5828&lt;/del&gt;&lt;/a&gt;. BlockPlacementPolicyWithNodeGroup can place multiple replicas on the same node group when dfs.namenode.avoid.write.stale.datanode is true. (Buddy via junping_du) (junping_du: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563640&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12625634" name="HDFS-5828.patch" size="2414" author="buddytaylor0" created="Tue, 28 Jan 2014 19:27:29 +0000"/>
                            <attachment id="12626306" name="HDFS-5828a.patch" size="2157" author="buddytaylor0" created="Fri, 31 Jan 2014 14:23:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 Jan 2014 07:30:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369799</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369802</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5827] Children are not inheriting parent&apos;s default ACLs</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5827</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Children are not inheriting the parent&apos;s default ACLs on creation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12691026">HDFS-5827</key>
            <summary>Children are not inheriting parent&apos;s default ACLs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="vinayrpet">Vinay</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 12:51:49 +0000</created>
                <updated>Sun, 26 Jan 2014 04:30:51 +0000</updated>
                            <resolved>Sun, 26 Jan 2014 04:30:51 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13880940" author="vinayrpet" created="Fri, 24 Jan 2014 12:53:17 +0000"  >&lt;p&gt;Following is the ACLs on parent and child in HDFS&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;# file: /dir1
# owner: vinay
# group: supergroup
user::rwx
mask::r-x
other::r-x
default:user::rwx
default:user:charlie:r-x
default:group::r-x
default:group:admin:rwx
default:mask::rwx
default:other::r-x

# file: /dir1/dir2
# owner: vinay
# group: supergroup
user::rwx
group::r-x
other::r-x

# file: /dir1/file
# owner: vinay
# group: supergroup
user::rw-
group::r--
other::r--&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Following is the output in linux ACL&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;# file: testAcl
# owner: vinay
# group: users
user::rwx
user:vinay:r--
group::r-x
group:users:r-x
mask::r-x
other::r-x
default:user::rwx
default:user:vinay:r-x
default:group::r-x
default:group:users:rwx
default:mask::rwx
default:other::r-x

# file: testAcl/hello
# owner: vinay
# group: users
user::rw-
user:vinay:r-x                  #effective:r--
group::r-x                      #effective:r--
group:users:rwx                 #effective:rw-
mask::rw-
other::r--
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13880942" author="vinayrpet" created="Fri, 24 Jan 2014 12:55:35 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cnauroth&quot; class=&quot;user-hover&quot; rel=&quot;cnauroth&quot;&gt;Chris Nauroth&lt;/a&gt;, Could you take a look at this.&lt;br/&gt;
This I found while writing xml tests. &lt;br/&gt;
Please correct me if I am wrong.&lt;/p&gt;</comment>
                            <comment id="13881194" author="cnauroth" created="Fri, 24 Jan 2014 17:43:42 +0000"  >&lt;p&gt;Thanks, Vinay.  You&apos;re right that this is incorrect behavior.  This is happening because default ACL handling hasn&apos;t been implemented on the NameNode side yet.  This is tracked in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5616&quot; title=&quot;NameNode: implement default ACL handling.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5616&quot;&gt;HDFS-5616&lt;/a&gt;, and I&apos;m planning on getting it done in the next few days.  Until then, this particular test won&apos;t pass.&lt;/p&gt;

&lt;p&gt;Do you mind if we resolve this as duplicate?  For &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5702&quot; title=&quot;FsShell Cli: Add XML based End-to-End test for getfacl and setfacl commands&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5702&quot;&gt;&lt;del&gt;HDFS-5702&lt;/del&gt;&lt;/a&gt;, I think we can just commit the failing tests, and then I&apos;ll verify later that my &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5616&quot; title=&quot;NameNode: implement default ACL handling.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5616&quot;&gt;HDFS-5616&lt;/a&gt; patch fixes them.  We&apos;re isolated on a feature branch, so having a couple of failing tests for a few days won&apos;t harm anyone else.  Sound good?&lt;/p&gt;</comment>
                            <comment id="13881221" author="cnauroth" created="Fri, 24 Jan 2014 18:05:45 +0000"  >&lt;p&gt;Assigning to myself for verification as part of working on &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5616&quot; title=&quot;NameNode: implement default ACL handling.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5616&quot;&gt;HDFS-5616&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13882169" author="vinayrpet" created="Sun, 26 Jan 2014 04:30:51 +0000"  >&lt;p&gt;This will be implemented in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5616&quot; title=&quot;NameNode: implement default ACL handling.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5616&quot;&gt;HDFS-5616&lt;/a&gt;&lt;br/&gt;
And tests are already added as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5702&quot; title=&quot;FsShell Cli: Add XML based End-to-End test for getfacl and setfacl commands&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5702&quot;&gt;&lt;del&gt;HDFS-5702&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
So closing this as duplicate.&lt;/p&gt;

&lt;p&gt;Thanks Chris for the update&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12682485">HDFS-5616</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12686502">HDFS-5702</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12642003">HDFS-4685</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                            <outwardlinks description="requires">
                                        <issuelink>
            <issuekey id="12682485">HDFS-5616</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jan 2014 17:43:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369775</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369776</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5826] Update the stored edit logs to be consistent with the changes in HDFS-5698 branch</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5826</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5698&quot; title=&quot;Use protobuf to serialize / deserialize FSImage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5698&quot;&gt;HDFS-5698&lt;/a&gt; bumps the LayoutVersion to indicate whether the file is in new format. The stored edit logs have to be updated in order to pass &lt;tt&gt;testOfflineEditsViewer&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690942">HDFS-5826</key>
            <summary>Update the stored edit logs to be consistent with the changes in HDFS-5698 branch</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jan 2014 00:53:38 +0000</created>
                <updated>Mon, 27 Jan 2014 18:37:55 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 18:37:55 +0000</resolved>
                                    <version>HDFS-5698 (FSImage in protobuf)</version>
                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13883078" author="jingzhao" created="Mon, 27 Jan 2014 18:37:55 +0000"  >&lt;p&gt;+1. I&apos;ve committed this patch.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624963" name="HDFS-5826.000.patch" size="1045" author="wheat9" created="Fri, 24 Jan 2014 00:55:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Jan 2014 18:37:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369688</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369689</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325854</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5825] Use FileUtils.copyFile() to implement DFSTestUtils.copyFile()</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5825</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;tt&gt;DFSTestUtils.copyFile()&lt;/tt&gt; is implemented by copying data through FileInputStream / FileOutputStream. Apache Common IO provides &lt;tt&gt;FileUtils.copyFile()&lt;/tt&gt;. It uses FileChannel which is more efficient.&lt;/p&gt;

&lt;p&gt;This jira proposes to implement &lt;tt&gt;DFSTestUtils.copyFile()&lt;/tt&gt; using &lt;tt&gt;FileUtils.copyFile()&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690894">HDFS-5825</key>
            <summary>Use FileUtils.copyFile() to implement DFSTestUtils.copyFile()</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 22:18:07 +0000</created>
                <updated>Tue, 28 Jan 2014 13:40:15 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 19:04:48 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13880584" author="arpitagarwal" created="Fri, 24 Jan 2014 01:07:38 +0000"  >&lt;p&gt;+1 (pending Jenkins).&lt;/p&gt;</comment>
                            <comment id="13882478" author="hadoopqa" created="Sun, 26 Jan 2014 23:36:39 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624927/HDFS-5825.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624927/HDFS-5825.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5945//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5945//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5945//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5945//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13882509" author="hadoopqa" created="Mon, 27 Jan 2014 02:05:17 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624927/HDFS-5825.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624927/HDFS-5825.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5946//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5946//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5946//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5946//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13882634" author="hadoopqa" created="Mon, 27 Jan 2014 08:38:12 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624927/HDFS-5825.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624927/HDFS-5825.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5947//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5947//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5947//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5947//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883121" author="arpitagarwal" created="Mon, 27 Jan 2014 19:04:48 +0000"  >&lt;p&gt;Thanks for the contribution Haohui!&lt;/p&gt;

&lt;p&gt;I committed this to trunk, branch-2 and branch-2.3.&lt;/p&gt;</comment>
                            <comment id="13883123" author="hudson" created="Mon, 27 Jan 2014 19:06:32 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5044 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5044/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5044/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5825&quot; title=&quot;Use FileUtils.copyFile() to implement DFSTestUtils.copyFile()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5825&quot;&gt;&lt;del&gt;HDFS-5825&lt;/del&gt;&lt;/a&gt;. Use FileUtils.copyFile() to implement DFSTestUtils.copyFile(). (Contributed by Haohui Mai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884009" author="hudson" created="Tue, 28 Jan 2014 11:09:03 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5825&quot; title=&quot;Use FileUtils.copyFile() to implement DFSTestUtils.copyFile()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5825&quot;&gt;&lt;del&gt;HDFS-5825&lt;/del&gt;&lt;/a&gt;. Use FileUtils.copyFile() to implement DFSTestUtils.copyFile(). (Contributed by Haohui Mai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884115" author="hudson" created="Tue, 28 Jan 2014 13:29:55 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5825&quot; title=&quot;Use FileUtils.copyFile() to implement DFSTestUtils.copyFile()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5825&quot;&gt;&lt;del&gt;HDFS-5825&lt;/del&gt;&lt;/a&gt;. Use FileUtils.copyFile() to implement DFSTestUtils.copyFile(). (Contributed by Haohui Mai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884132" author="hudson" created="Tue, 28 Jan 2014 13:40:15 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5825&quot; title=&quot;Use FileUtils.copyFile() to implement DFSTestUtils.copyFile()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5825&quot;&gt;&lt;del&gt;HDFS-5825&lt;/del&gt;&lt;/a&gt;. Use FileUtils.copyFile() to implement DFSTestUtils.copyFile(). (Contributed by Haohui Mai) (arp: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561792&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624927" name="HDFS-5825.000.patch" size="1685" author="wheat9" created="Thu, 23 Jan 2014 22:19:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Jan 2014 01:07:38 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369640</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369643</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325255</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5824] Add a Type field in Snapshot DiffEntry&apos;s protobuf definition</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5824</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;We need to add a Type field to differentiate FileDiff and DirectoryDiff in our  protobuf to enable the offline image viewer to parse the fsimage.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690837">HDFS-5824</key>
            <summary>Add a Type field in Snapshot DiffEntry&apos;s protobuf definition</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="jingzhao">Jing Zhao</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 18:26:16 +0000</created>
                <updated>Thu, 23 Jan 2014 19:11:19 +0000</updated>
                            <resolved>Thu, 23 Jan 2014 19:11:19 +0000</resolved>
                                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13880227" author="wheat9" created="Thu, 23 Jan 2014 19:04:00 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13880242" author="jingzhao" created="Thu, 23 Jan 2014 19:11:19 +0000"  >&lt;p&gt;Thanks for the review, Haohui! I&apos;ve committed this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624859" name="HDFS-5824.000.patch" size="12289" author="jingzhao" created="Thu, 23 Jan 2014 18:27:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Jan 2014 19:04:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369582</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369585</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5823] Document async audit logging</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5823</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5241&quot; title=&quot;Provide alternate queuing audit logger to reduce logging contention&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5241&quot;&gt;&lt;del&gt;HDFS-5241&lt;/del&gt;&lt;/a&gt; added an option for async log4j audit logging.  The option is considered semi-experimental and should be documented in hdfs-defaults.xml after it&apos;s stability under stress is proven.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690817">HDFS-5823</key>
            <summary>Document async audit logging</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="daryn">Daryn Sharp</assignee>
                                    <reporter username="daryn">Daryn Sharp</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 17:07:35 +0000</created>
                <updated>Thu, 23 Jan 2014 17:07:59 +0000</updated>
                                            <version>2.0.0-alpha</version>
                    <version>3.0.0</version>
                                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12669667">HDFS-5241</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369561</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369564</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320356</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5822] InterruptedException to thread sleep ignored</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5822</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java, there is the following code snippet in the run() method:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;156:      } catch (OutOfMemoryError ie) {
157:        IOUtils.cleanup(null, peer);
158:        // DataNode can run out of memory if there is too many transfers.
159:       // Log the event, Sleep for 30 seconds, other transfers may complete by
160:        // then.
161:        LOG.warn(&quot;DataNode is out of memory. Will retry in 30 seconds.&quot;, ie);
162:        try {
163:          Thread.sleep(30 * 1000);
164:        } catch (InterruptedException e) {
165:          // ignore
166:        }
167:      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that InterruptedException is completely ignored. This might not be safe since any potential events that lead to InterruptedException are lost?&lt;/p&gt;

&lt;p&gt;More info on why InterruptedException shouldn&apos;t be ignored: &lt;a href=&quot;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Ding&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690749">HDFS-5822</key>
            <summary>InterruptedException to thread sleep ignored</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="d.yuan">Ding Yuan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 11:21:22 +0000</created>
                <updated>Thu, 23 Jan 2014 11:45:01 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369493</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369496</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5821] TestHDFSCLI fails for user names with the dash character</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5821</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testHDFSConf.xml uses regexes inconsistently to match the username from &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-zA-z0-9]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-z]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. This by far does not cover the space of possible OS user names.  For us, it fails for a user name containing &lt;tt&gt;&apos;-&apos;&lt;/tt&gt;. Instead of keeping updating regex, we propose to use the macro USERNAME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690742">HDFS-5821</key>
            <summary>TestHDFSCLI fails for user names with the dash character</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 10:38:17 +0000</created>
                <updated>Fri, 31 Jan 2014 21:58:59 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13879837" author="jira.shegalov" created="Thu, 23 Jan 2014 10:42:07 +0000"  >&lt;p&gt;Patch with the proposed fix&lt;/p&gt;</comment>
                            <comment id="13888219" author="hadoopqa" created="Fri, 31 Jan 2014 21:58:59 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624780/HDFS-5821-trunk.v01.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624780/HDFS-5821-trunk.v01.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6002//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6002//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/6002//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/6002//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12690541">HDFS-5811</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12690548">HDFS-5812</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12690560">HDFS-5816</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12690561">HDFS-5817</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12690562">HDFS-5818</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12690566">HDFS-5819</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624780" name="HDFS-5821-trunk.v01.patch" size="385716" author="jira.shegalov" created="Thu, 23 Jan 2014 10:42:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 Jan 2014 21:58:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369485</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369488</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5820] TesHDFSCLI does not work for user names with &apos;-&apos;</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5820</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description></description>
                <environment></environment>
        <key id="12690628">HDFS-5820</key>
            <summary>TesHDFSCLI does not work for user names with &apos;-&apos;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 06:24:46 +0000</created>
                <updated>Thu, 23 Jan 2014 06:24:46 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369451</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369454</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5819] TestHDFSCLI fails for a user name with dash</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5819</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testHDFSConf.xml uses a regex to describe username. Regexes are used incosistently from &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-zA-z0-9]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-z]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. Clearly OS are less restrictive than that, and for us specifically the test fails for a build user having a &lt;tt&gt;-&lt;/tt&gt;. So instead of keeping updating regex, I propose to replace it with the macro USERNAME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690566">HDFS-5819</key>
            <summary>TestHDFSCLI fails for a user name with dash</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:55:04 +0000</created>
                <updated>Fri, 31 Jan 2014 19:39:58 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 19:39:58 +0000</resolved>
                                    <version>2.2.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13888065" author="jira.shegalov" created="Fri, 31 Jan 2014 19:39:58 +0000"  >&lt;p&gt;ASF JIRA was flaky and created duplicates while reporting an error to the frontend.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12690742">HDFS-5821</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369458</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369461</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5818] TestHDFSCLI fails for a user name with dash</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5818</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testHDFSConf.xml uses a regex to describe username. Regexes are used incosistently from &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-zA-z0-9]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-z]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. Clearly OS are less restrictive than that, and for us specifically the test fails for a build user having a &lt;tt&gt;-&lt;/tt&gt;. So instead of keeping updating regex, I propose to replace it with the macro USERNAME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690562">HDFS-5818</key>
            <summary>TestHDFSCLI fails for a user name with dash</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:27:25 +0000</created>
                <updated>Fri, 31 Jan 2014 19:39:00 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 19:39:00 +0000</resolved>
                                    <version>2.2.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13888062" author="jira.shegalov" created="Fri, 31 Jan 2014 19:39:00 +0000"  >&lt;p&gt;ASF JIRA was flaky and created duplicates while reporting an error to the frontend.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12690742">HDFS-5821</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369459</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369462</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5817] TestHDFSCLI fails for a user name with dash</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5817</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testHDFSConf.xml uses a regex to describe username. Regexes are used incosistently from &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-zA-z0-9]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-z]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. Clearly OS are less restrictive than that, and for us specifically the test fails for a build user having a &lt;tt&gt;-&lt;/tt&gt;. So instead of keeping updating regex, I propose to replace it with the macro USERNAME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690561">HDFS-5817</key>
            <summary>TestHDFSCLI fails for a user name with dash</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:23:31 +0000</created>
                <updated>Fri, 31 Jan 2014 19:38:23 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 19:38:23 +0000</resolved>
                                    <version>2.2.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13888060" author="jira.shegalov" created="Fri, 31 Jan 2014 19:38:23 +0000"  >&lt;p&gt;ASF JIRA was flaky and created duplicates while reporting an error to the frontend.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12690742">HDFS-5821</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369460</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369463</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5816] TestHDFSCLI fails for a user name with dash</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5816</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testHDFSConf.xml uses a regex to describe username. Regexes are used incosistently from &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-zA-z0-9]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-z]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. Clearly OS are less restrictive than that, and for us specifically the test fails for a build user having a &lt;tt&gt;-&lt;/tt&gt;. So instead of keeping updating regex, I propose to replace it with the macro USERNAME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690560">HDFS-5816</key>
            <summary>TestHDFSCLI fails for a user name with dash</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:22:17 +0000</created>
                <updated>Fri, 31 Jan 2014 19:37:22 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 19:37:22 +0000</resolved>
                                    <version>2.2.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13888057" author="jira.shegalov" created="Fri, 31 Jan 2014 19:37:22 +0000"  >&lt;p&gt;ASF JIRA was flaky and created duplicates while reporting an error to the frontend.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12690742">HDFS-5821</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369461</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369464</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5815] InterruptedException to thread sleep ignored </title>
                <link>https://issues.apache.org/jira/browse/HDFS-5815</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java, there is the following code snippet in the run() method:&lt;/p&gt;

&lt;p&gt;156:      } catch (OutOfMemoryError ie) {&lt;br/&gt;
157:        IOUtils.cleanup(null, peer);&lt;br/&gt;
158:        // DataNode can run out of memory if there is too many transfers.&lt;br/&gt;
159:       // Log the event, Sleep for 30 seconds, other transfers may complete by&lt;br/&gt;
160:        // then.&lt;br/&gt;
161:        LOG.warn(&quot;DataNode is out of memory. Will retry in 30 seconds.&quot;, ie);&lt;br/&gt;
162:        try &lt;/p&gt;
{
163:          Thread.sleep(30 * 1000);
164:        }
&lt;p&gt; catch (InterruptedException e) &lt;/p&gt;
{
165:          // ignore
166:        }
&lt;p&gt;167:      }&lt;/p&gt;

&lt;p&gt;Note that InterruptedException is completely ignored. This might not be safe since any potential events that lead to InterruptedException are lost?&lt;/p&gt;

&lt;p&gt;More info: &lt;a href=&quot;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Ding&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690559">HDFS-5815</key>
            <summary>InterruptedException to thread sleep ignored </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="d.yuan">Ding Yuan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:21:30 +0000</created>
                <updated>Thu, 23 Jan 2014 03:21:30 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369462</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369465</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5814] InterruptedException to thread.sleep ignored </title>
                <link>https://issues.apache.org/jira/browse/HDFS-5814</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java, there is the following code snippet in the run() method:&lt;/p&gt;

&lt;p&gt;156:      } catch (OutOfMemoryError ie) {&lt;br/&gt;
157:        IOUtils.cleanup(null, peer);&lt;br/&gt;
158:        // DataNode can run out of memory if there is too many transfers.&lt;br/&gt;
159:       // Log the event, Sleep for 30 seconds, other transfers may complete by&lt;br/&gt;
160:        // then.&lt;br/&gt;
161:        LOG.warn(&quot;DataNode is out of memory. Will retry in 30 seconds.&quot;, ie);&lt;br/&gt;
162:        try &lt;/p&gt;
{
163:          Thread.sleep(30 * 1000);
164:        }
&lt;p&gt; catch (InterruptedException e) &lt;/p&gt;
{
165:          // ignore
166:        }
&lt;p&gt;167:      }&lt;/p&gt;

&lt;p&gt;Note that InterruptedException is completely ignored. This might not be safe since any potential events that lead to InterruptedException are lost?&lt;/p&gt;

&lt;p&gt;More info: &lt;a href=&quot;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Ding&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690558">HDFS-5814</key>
            <summary>InterruptedException to thread.sleep ignored </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="d.yuan">Ding Yuan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:20:12 +0000</created>
                <updated>Thu, 23 Jan 2014 03:20:12 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369463</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369466</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5813] InterruptedException to thread.sleep ignored </title>
                <link>https://issues.apache.org/jira/browse/HDFS-5813</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java, there is the following code snippet in the run() method:&lt;/p&gt;

&lt;p&gt;156:      } catch (OutOfMemoryError ie) {&lt;br/&gt;
157:        IOUtils.cleanup(null, peer);&lt;br/&gt;
158:        // DataNode can run out of memory if there is too many transfers.&lt;br/&gt;
159:       // Log the event, Sleep for 30 seconds, other transfers may complete by&lt;br/&gt;
160:        // then.&lt;br/&gt;
161:        LOG.warn(&quot;DataNode is out of memory. Will retry in 30 seconds.&quot;, ie);&lt;br/&gt;
162:        try &lt;/p&gt;
{
163:          Thread.sleep(30 * 1000);
164:        }
&lt;p&gt; catch (InterruptedException e) &lt;/p&gt;
{
165:          // ignore
166:        }
&lt;p&gt;167:      }&lt;/p&gt;

&lt;p&gt;Note that InterruptedException is completely ignored. This might not be safe since any potential events that lead to InterruptedException are lost?&lt;/p&gt;

&lt;p&gt;More info: &lt;a href=&quot;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/1087475/when-does-javas-thread-sleep-throw-interruptedexception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Ding&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690557">HDFS-5813</key>
            <summary>InterruptedException to thread.sleep ignored </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="d.yuan">Ding Yuan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:19:29 +0000</created>
                <updated>Thu, 23 Jan 2014 03:19:29 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369464</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369467</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5812] TestHDFSCLI fails for a user name with dash</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5812</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testHDFSConf.xml uses a regex to describe username. Regexes are used incosistently from &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-zA-z0-9]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-z]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. Clearly OS are less restrictive than that, and for us specifically the test fails for a build user having a &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. So instead of keeping updating regex, I propose to replace it with the macro USERNAME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690548">HDFS-5812</key>
            <summary>TestHDFSCLI fails for a user name with dash</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:13:13 +0000</created>
                <updated>Fri, 31 Jan 2014 19:36:29 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 19:36:28 +0000</resolved>
                                    <version>2.2.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13888056" author="jira.shegalov" created="Fri, 31 Jan 2014 19:36:29 +0000"  >&lt;p&gt;ASF JIRA was flaky and created duplicates while reporting an error to the frontend.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12690742">HDFS-5821</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369465</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369468</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5811] TestHDFSCLI fails for a user name with dash</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5811</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;testHDFSConf.xml uses a regex to describe username. Regexes are used incosistently from &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-zA-z0-9]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[a-z]*&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. Clearly OS are less restrictive than that, and for us specifically the test fails for a build user having a &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. So instead of keeping updating regex, I propose to replace it with the macro USERNAME.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690541">HDFS-5811</key>
            <summary>TestHDFSCLI fails for a user name with dash</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jira.shegalov">Gera Shegalov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Jan 2014 03:12:22 +0000</created>
                <updated>Fri, 31 Jan 2014 19:35:18 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 19:35:18 +0000</resolved>
                                    <version>2.2.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13888054" author="jira.shegalov" created="Fri, 31 Jan 2014 19:35:18 +0000"  >&lt;p&gt;ASF JIRA was flaky and created duplicates while reporting an error to the frontend.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12690742">HDFS-5821</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369466</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369469</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5810] Unify mmap cache and short-circuit file descriptor cache</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5810</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;We should unify the client mmap cache and the client file descriptor cache.  Since mmaps are granted corresponding to file descriptors in the cache (currently FileInputStreamCache), they have to be tracked together to do &quot;smarter&quot; things like &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5182&quot; title=&quot;BlockReaderLocal must allow zero-copy  reads only when the DN believes it&amp;#39;s valid&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5182&quot;&gt;HDFS-5182&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690349">HDFS-5810</key>
            <summary>Unify mmap cache and short-circuit file descriptor cache</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12667954">HDFS-5182</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="cmccabe">Colin Patrick McCabe</assignee>
                                    <reporter username="cmccabe">Colin Patrick McCabe</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jan 2014 19:06:44 +0000</created>
                <updated>Thu, 30 Jan 2014 06:21:04 +0000</updated>
                                            <version>2.3.0</version>
                                                    <component>hdfs-client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13879059" author="cmccabe" created="Wed, 22 Jan 2014 19:23:43 +0000"  >&lt;p&gt;This patch unifies &lt;tt&gt;FileInputStreamCache&lt;/tt&gt; and &lt;tt&gt;ClientMmapManager&lt;/tt&gt; into a single cache called &lt;tt&gt;ShortCircuitCache&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Along the way, I noticed that our current caches were being destroyed and re-created constantly when using &lt;tt&gt;FileContext&lt;/tt&gt;.  Because &lt;tt&gt;FileContext&lt;/tt&gt; destroys and re-creates a &lt;tt&gt;DFSClient&lt;/tt&gt; with each operation it does, the &lt;tt&gt;DFSClient&lt;/tt&gt; is not the right place for caches to live.  Instead, they need to have global scope, like &lt;tt&gt;PeerCache&lt;/tt&gt; does currently.  I created &lt;tt&gt;ClientCacheContext&lt;/tt&gt; for this purpose and moved &lt;tt&gt;ShortCircuitCache&lt;/tt&gt;, &lt;tt&gt;PeerCache&lt;/tt&gt;, and &lt;tt&gt;DomainSocketFactory&lt;/tt&gt; into it.&lt;/p&gt;

&lt;p&gt;I wanted to give threads the choice to use a different cache if they so desired.  So I created the &lt;tt&gt;dfs.client.cache.context&lt;/tt&gt;.  When looking up the relevant &lt;tt&gt;ClientCacheContext&lt;/tt&gt;, we look up the value of this key in a global map.  This allows clients to (for example) create separate &lt;tt&gt;FileSystem&lt;/tt&gt; or &lt;tt&gt;FileContext&lt;/tt&gt; instances that don&apos;t share a socket cache, by setting different values for this configuration key at the time of creation.  It is also handy for unit tests, to avoid cross-test contamination.&lt;/p&gt;

&lt;p&gt;With this change, two &lt;tt&gt;DFSInputStream&lt;/tt&gt; instances reading the same local replica via short-circuit reads now use the same file descriptor.  This has an obvious advantage in keeping down the number of open file descriptors we have.  It also has some more subtle advantages.  For example, we no longer re-read the first part of the block metadata header over and over, since we only have one ShortCircuitReplica for that block in the cache.  We only make one &lt;tt&gt;REQUEST_SHORT_CIRCUIT_FDS&lt;/tt&gt; RPC to the DataNode, rather than two.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;BlockReaderFactory&lt;/tt&gt; was previously a place for static methods to hang out.  Now it&apos;s a &quot;real class&quot; that takes care of the work of building a block reader.  It&apos;s nice to have better encapsulation of this functionality.  &lt;tt&gt;BlockReaderFactory#build&lt;/tt&gt; only throws an IOException if there was a security problem that requires that the stream do something (like refetch block tokens), or if no block reader at all could be created.&lt;/p&gt;</comment>
                            <comment id="13879255" author="hadoopqa" created="Wed, 22 Jan 2014 22:08:22 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624399/HDFS-5810.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624399/HDFS-5810.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 17 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestClientBlockVerification&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestPipelines&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.datanode.TestDatanodeJsp&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestFsck&lt;br/&gt;
                  org.apache.hadoop.fs.TestEnhancedByteBufferAccess&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestDataTransferKeepalive&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestParallelShortCircuitReadUnCached&lt;/p&gt;

&lt;p&gt;                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hdfs.TestShortCircuitCache&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5935//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5935//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5935//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5935//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5935//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5935//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883771" author="hadoopqa" created="Tue, 28 Jan 2014 05:16:45 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625506/HDFS-5810.004.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625506/HDFS-5810.004.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 18 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestShortCircuitCache&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestParallelShortCircuitReadUnCached&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5958//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5958//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5958//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5958//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5958//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5958//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13885966" author="cmccabe" created="Wed, 29 Jan 2014 23:05:31 +0000"  >&lt;ul&gt;
	&lt;li&gt;ShortCircuitCache#fetchOrCreate: retry here if we get a stale replica.&lt;/li&gt;
	&lt;li&gt;ShortCircuitCache#obliterate: must set refCount to 0 here.&lt;/li&gt;
	&lt;li&gt;fix up some logs, add more trace logs&lt;/li&gt;
	&lt;li&gt;fix findbugs issues&lt;/li&gt;
	&lt;li&gt;add more descriptive failure message to some asserts&lt;/li&gt;
	&lt;li&gt;TestBlockTokenWithDFS: fix test control flow.  fix longstanding DFSClient leak.&lt;/li&gt;
	&lt;li&gt;move getConfiguration and getUGI out of the RemotePeerFactory interface.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885998" author="hadoopqa" created="Wed, 29 Jan 2014 23:34:05 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626008/HDFS-5810.006.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626008/HDFS-5810.006.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 18 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;&lt;/font&gt;-1 javac&lt;font color=&quot;red&quot;&gt;&lt;/font&gt;.  The patch appears to cause the build to fail.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5985//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5985//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886282" author="hadoopqa" created="Thu, 30 Jan 2014 06:21:04 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12626052/HDFS-5810.008.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12626052/HDFS-5810.008.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 19 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.TestBlockReaderFactory&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestPersistBlocks&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5987//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5987//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5987//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5987//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5987//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5987//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624399" name="HDFS-5810.001.patch" size="237355" author="cmccabe" created="Wed, 22 Jan 2014 19:08:29 +0000"/>
                            <attachment id="12625506" name="HDFS-5810.004.patch" size="254884" author="cmccabe" created="Tue, 28 Jan 2014 02:40:02 +0000"/>
                            <attachment id="12626008" name="HDFS-5810.006.patch" size="256295" author="cmccabe" created="Wed, 29 Jan 2014 23:05:31 +0000"/>
                            <attachment id="12626052" name="HDFS-5810.008.patch" size="265511" author="cmccabe" created="Thu, 30 Jan 2014 03:51:14 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 22:08:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369307</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369308</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5809] BlockPoolSliceScanner make datanode to drop into infinite loop</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5809</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Hello, everyone.&lt;/p&gt;

&lt;p&gt;When hadoop cluster starts, BlockPoolSliceScanner start scanning the blocks in my cluster.&lt;br/&gt;
Then, randomly one datanode drop into infinite loop as the log show, and finally all datanodes drop into infinite loop.&lt;br/&gt;
Every datanode just verify fail by one block. &lt;br/&gt;
When i check the fail block like this : hadoop fsck / -files -blocks | grep blk_1223474551535936089_4702249, no hdfs file contains the block.&lt;/p&gt;

&lt;p&gt;It seems that in while block of BlockPoolSliceScanner&apos;s scan method drop into infinite loop .&lt;br/&gt;
BlockPoolSliceScanner: 650&lt;/p&gt;

&lt;p&gt;while (datanode.shouldRun&lt;br/&gt;
&amp;amp;&amp;amp; !datanode.blockScanner.blockScannerThread.isInterrupted()&lt;br/&gt;
&amp;amp;&amp;amp; datanode.isBPServiceAlive(blockPoolId)) { ....&lt;/p&gt;

&lt;p&gt;The log finally printed in method verifyBlock(BlockPoolSliceScanner:453).&lt;/p&gt;

&lt;p&gt;Please excuse my poor English.&lt;br/&gt;
-------------------------------------------------------------------------------------------------------------------------------------------------&lt;br/&gt;
LOG: &lt;br/&gt;
2014-01-21 18:36:50,582 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification failed for BP-1040548460-58.229.158.13-1385606058039:blk_6833233229840997944_4702634 - may be due to race with write&lt;br/&gt;
2014-01-21 18:36:50,582 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification failed for BP-1040548460-58.229.158.13-1385606058039:blk_6833233229840997944_4702634 - may be due to race with write&lt;br/&gt;
2014-01-21 18:36:50,582 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification failed for BP-1040548460-58.229.158.13-1385606058039:blk_6833233229840997944_4702634 - may be due to race with write&lt;/p&gt;</description>
                <environment>&lt;p&gt;jdk1.6, centos6.4, 2.0.0-cdh4.5.0&lt;/p&gt;</environment>
        <key id="12690215">HDFS-5809</key>
            <summary>BlockPoolSliceScanner make datanode to drop into infinite loop</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ikweesung">ikweesung</reporter>
                        <labels>
                            <label>blockpoolslicescanner</label>
                            <label>datanode</label>
                            <label>infinite-loop</label>
                    </labels>
                <created>Wed, 22 Jan 2014 07:53:10 +0000</created>
                <updated>Mon, 27 Jan 2014 00:33:34 +0000</updated>
                                            <version>2.0.0-alpha</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13878380" author="ikweesung" created="Wed, 22 Jan 2014 07:53:35 +0000"  >&lt;p&gt;In BlockPoolSliceScanner, the code below&lt;/p&gt;

&lt;p&gt;if (((now - getEarliestScanTime()) &amp;gt;= scanPeriod) || ((!blockInfoSet.isEmpty()) &amp;amp;&amp;amp; !(this.isFirstBlockProcessed()))) &lt;/p&gt;
{ verifyFirstBlock(); }
&lt;p&gt; else &lt;/p&gt;
{ ....}

&lt;p&gt;may cause this problem in my opinion.&lt;br/&gt;
After three weeks from last block pool scanning, the condition : (now - getEarliestScanTime()) &amp;gt;= scanPeriod) will be true, and at this time, race between scanning and hdfs append may make the datanode drop into the infinite loop. Because code which update the EarliestScanTime place after the code which throw the FNFE.&lt;/p&gt;

&lt;p&gt;When i changed scanPeriod to 1 hour, the datanode drop into infinite loop in several minutes. &lt;br/&gt;
Then i changed scanPeriod to default : 504 hours, the datanode did not drop into infinite loop in a long time.&lt;/p&gt;</comment>
                            <comment id="13880700" author="ikweesung" created="Fri, 24 Jan 2014 04:14:45 +0000"  >&lt;p&gt;Please execute my poor English. : )&lt;br/&gt;
I found that int BlockPoolSliceScanner, blockInfoSet can contain two block which has the same block id, because BlockScanInfo compare by lastScanTime. &lt;br/&gt;
Then int method updateScanStatus, the BlockScanInfo can not be updated, so ((now - getEarliestScanTime()) &amp;gt;= scanPeriod) will be always true. &lt;br/&gt;
This cause datanode drop into infinite loop. &lt;/p&gt;</comment>
                            <comment id="13880702" author="ikweesung" created="Fri, 24 Jan 2014 04:18:25 +0000"  >&lt;p&gt;My ugly path like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ( info != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ) {
      delBlockInfo(info);
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(blockInfoSet.contains(block)){
        delBlockInfo(info);
        info = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BlockScanInfo(block);
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;code-comment&quot;&gt;// It might already be removed. Thats ok, it will be caught next time.
&lt;/span&gt;      info = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BlockScanInfo(block);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13882486" author="ikweesung" created="Mon, 27 Jan 2014 00:33:34 +0000"  >&lt;p&gt;After change code like above, datanode didn&apos;t drop into infinite loop last three days with scanPeriod set 1 hour.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369174</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369175</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5808] Implement cancellation when saving FSImage</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5808</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The code should be able to cancel the progress of saving fsimage / checkpointing. When fail over happens, the code needs to timely cancel the checkpoint operations so that the fail over sequences can proceed.&lt;/p&gt;

&lt;p&gt;The same functionality exists in the old code. This jira proposes to implement the same functionality in the new fsimage code.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690159">HDFS-5808</key>
            <summary>Implement cancellation when saving FSImage</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jan 2014 01:05:21 +0000</created>
                <updated>Thu, 23 Jan 2014 20:30:50 +0000</updated>
                            <resolved>Thu, 23 Jan 2014 19:20:54 +0000</resolved>
                                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13880245" author="wheat9" created="Thu, 23 Jan 2014 19:16:56 +0000"  >&lt;p&gt;Rebased&lt;/p&gt;</comment>
                            <comment id="13880250" author="jingzhao" created="Thu, 23 Jan 2014 19:20:54 +0000"  >&lt;p&gt;+1. I&apos;ve committed this.&lt;/p&gt;</comment>
                            <comment id="13880296" author="sureshms" created="Thu, 23 Jan 2014 20:03:06 +0000"  >&lt;p&gt;Can you please add description on why this is needed (use case) and what the patch does?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624244" name="HDFS-5808.000.patch" size="12032" author="wheat9" created="Wed, 22 Jan 2014 01:05:44 +0000"/>
                            <attachment id="12624878" name="HDFS-5808.001.patch" size="11111" author="wheat9" created="Thu, 23 Jan 2014 19:16:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Jan 2014 19:20:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369121</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369122</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325854</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5807] TestBalancerWithNodeGroup.testBalancerWithNodeGroup fails intermittently on Branch-2</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5807</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The test times out after some time.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.util.concurrent.TimeoutException: Rebalancing expected avg utilization to become 0.16, but on datanode 127.0.0.1:42451 it remains at 0.3 after more than 20000 msec.
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup.waitForBalancer(TestBalancerWithNodeGroup.java:151)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup.runBalancer(TestBalancerWithNodeGroup.java:178)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup.testBalancerWithNodeGroup(TestBalancerWithNodeGroup.java:302)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12690135">HDFS-5807</key>
            <summary>TestBalancerWithNodeGroup.testBalancerWithNodeGroup fails intermittently on Branch-2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 22:46:32 +0000</created>
                <updated>Tue, 21 Jan 2014 22:46:32 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369097</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369098</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5806] balancer should set SoTimeout to avoid indefinite hangs</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5806</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Simple patch to avoid the balancer hanging when datanode stops responding to requests. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12690129">HDFS-5806</key>
            <summary>balancer should set SoTimeout to avoid indefinite hangs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nroberts">Nathan Roberts</assignee>
                                    <reporter username="nroberts">Nathan Roberts</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 22:16:31 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:14 +0000</updated>
                            <resolved>Wed, 22 Jan 2014 22:35:40 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>balancer</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13877926" author="nroberts" created="Tue, 21 Jan 2014 22:22:25 +0000"  >&lt;p&gt;use setSoTimeout() to avoid read hangs.&lt;/p&gt;</comment>
                            <comment id="13878093" author="hadoopqa" created="Wed, 22 Jan 2014 00:59:44 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624203/HDFS-5806.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624203/HDFS-5806.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5928//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5928//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5928//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5928//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13879082" author="andrew.wang" created="Wed, 22 Jan 2014 19:36:45 +0000"  >&lt;p&gt;LGTM, +1. Nathan, I assume you tested this manually?&lt;/p&gt;</comment>
                            <comment id="13879273" author="nroberts" created="Wed, 22 Jan 2014 22:23:31 +0000"  >&lt;p&gt;Andrew, thanks for taking a look. Sorry about not mentioning the testing. &lt;/p&gt;

&lt;p&gt;Didn&apos;t have great ideas on how to test. Basically did the following&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed balancer so that sotimeout was 1 second&lt;/li&gt;
	&lt;li&gt;Changed balancer so that sleeptime between iterations was 2 seconds&lt;/li&gt;
	&lt;li&gt;Changed dispatch() within balancer to randomly not send the request - this causes the response read to timeout due to sotimeout&lt;/li&gt;
	&lt;li&gt;Made sure TestBalancer still worked&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13879276" author="andrew.wang" created="Wed, 22 Jan 2014 22:29:46 +0000"  >&lt;p&gt;Sounds good to me, thanks Nathan. I&apos;ll commit shortly.&lt;/p&gt;</comment>
                            <comment id="13879286" author="andrew.wang" created="Wed, 22 Jan 2014 22:35:40 +0000"  >&lt;p&gt;Committed to trunk and branch-2, thanks again Nathan.&lt;/p&gt;</comment>
                            <comment id="13879303" author="hudson" created="Wed, 22 Jan 2014 22:47:12 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5035 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5035/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5035/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5806&quot; title=&quot;balancer should set SoTimeout to avoid indefinite hangs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5806&quot;&gt;&lt;del&gt;HDFS-5806&lt;/del&gt;&lt;/a&gt;. Balancer should set soTimeout to avoid indefinite hangs. Contributed by Nathan Roberts. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881836" author="hudson" created="Sat, 25 Jan 2014 12:27:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #461 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5806&quot; title=&quot;balancer should set SoTimeout to avoid indefinite hangs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5806&quot;&gt;&lt;del&gt;HDFS-5806&lt;/del&gt;&lt;/a&gt;. Balancer should set soTimeout to avoid indefinite hangs. Contributed by Nathan Roberts. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881863" author="hudson" created="Sat, 25 Jan 2014 13:27:42 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1678 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5806&quot; title=&quot;balancer should set SoTimeout to avoid indefinite hangs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5806&quot;&gt;&lt;del&gt;HDFS-5806&lt;/del&gt;&lt;/a&gt;. Balancer should set soTimeout to avoid indefinite hangs. Contributed by Nathan Roberts. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881881" author="hudson" created="Sat, 25 Jan 2014 13:38:04 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1653 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5806&quot; title=&quot;balancer should set SoTimeout to avoid indefinite hangs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5806&quot;&gt;&lt;del&gt;HDFS-5806&lt;/del&gt;&lt;/a&gt;. Balancer should set soTimeout to avoid indefinite hangs. Contributed by Nathan Roberts. (wang: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560548&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624203" name="HDFS-5806.patch" size="796" author="nroberts" created="Tue, 21 Jan 2014 22:22:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 00:59:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369091</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369092</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320356</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5805] TestCheckpoint.testCheckpoint fails intermittently on branch2</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5805</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.AssertionError: Bad value for metric GetEditAvgTime
Expected: gt(0.0)
     got: &amp;lt;0.0&amp;gt;

	at org.junit.Assert.assertThat(Assert.java:780)
	at org.apache.hadoop.test.MetricsAsserts.assertGaugeGt(MetricsAsserts.java:341)
	at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpoint(TestCheckpoint.java:1070)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12690109">HDFS-5805</key>
            <summary>TestCheckpoint.testCheckpoint fails intermittently on branch2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 21:02:08 +0000</created>
                <updated>Tue, 21 Jan 2014 21:02:08 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369071</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369072</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5804] HDFS NFS Gateway fails to mount and proxy when using Kerberos</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5804</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;When using HDFS nfs gateway with secure hadoop (hadoop.security.authentication: kerberos), mounting hdfs fails. &lt;br/&gt;
Additionally, there is no mechanism to support proxy user(nfs needs to proxy as the user invoking commands on the hdfs mount).&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;br/&gt;
1) start a hadoop cluster with kerberos enabled.&lt;br/&gt;
2) sudo su -l nfsserver and start an nfs server. This &apos;nfsserver&apos; account has a an account in kerberos.&lt;br/&gt;
3) Get the keytab for nfsserver, and issue the following mount command: mount -t nfs -o vers=3,proto=tcp,nolock $server:/  $mount_point&lt;br/&gt;
4) You&apos;ll see in the nfsserver logs that Kerberos is complaining about not having a TGT for root.&lt;br/&gt;
This is the stacktrace: &lt;br/&gt;
java.io.IOException: Failed on local exception: java.io.IOException: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:&lt;span class=&quot;error&quot;&gt;&amp;#91;TOKEN, KERBEROS&amp;#93;&lt;/span&gt;; Host Details : local host is: &quot;my-nfs-server-host.com/10.252.4.197&quot;; destination host is: &quot;my-namenode-host.com&quot;:8020; &lt;br/&gt;
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.call(Client.java:1351)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)&lt;br/&gt;
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)&lt;br/&gt;
	at com.sun.proxy.$Proxy9.getFileLinkInfo(Unknown Source)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:606)&lt;br/&gt;
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)&lt;br/&gt;
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)&lt;br/&gt;
	at com.sun.proxy.$Proxy9.getFileLinkInfo(Unknown Source)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileLinkInfo(ClientNamenodeProtocolTranslatorPB.java:664)&lt;br/&gt;
	at org.apache.hadoop.hdfs.DFSClient.getFileLinkInfo(DFSClient.java:1713)&lt;br/&gt;
	at org.apache.hadoop.hdfs.nfs.nfs3.Nfs3Utils.getFileStatus(Nfs3Utils.java:58)&lt;br/&gt;
	at org.apache.hadoop.hdfs.nfs.nfs3.Nfs3Utils.getFileAttr(Nfs3Utils.java:79)&lt;br/&gt;
	at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.fsinfo(RpcProgramNfs3.java:1643)&lt;br/&gt;
	at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.handleInternal(RpcProgramNfs3.java:1891)&lt;br/&gt;
	at org.apache.hadoop.oncrpc.RpcProgram.messageReceived(RpcProgram.java:143)&lt;br/&gt;
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)&lt;br/&gt;
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:281)&lt;br/&gt;
	at org.apache.hadoop.oncrpc.RpcUtil$RpcMessageParserStage.messageReceived(RpcUtil.java:132)&lt;br/&gt;
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)&lt;br/&gt;
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)&lt;br/&gt;
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)&lt;br/&gt;
	at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)&lt;br/&gt;
	at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)&lt;br/&gt;
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)&lt;br/&gt;
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:555)&lt;br/&gt;
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)&lt;br/&gt;
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)&lt;br/&gt;
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)&lt;br/&gt;
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)&lt;br/&gt;
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:744)&lt;br/&gt;
Caused by: java.io.IOException: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:&lt;span class=&quot;error&quot;&gt;&amp;#91;TOKEN, KERBEROS&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:620)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:583)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:667)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection.access$2600(Client.java:314)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1399)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.call(Client.java:1318)&lt;br/&gt;
	... 43 more&lt;br/&gt;
Caused by: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:&lt;span class=&quot;error&quot;&gt;&amp;#91;TOKEN, KERBEROS&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:170)&lt;br/&gt;
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:387)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:494)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:314)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:659)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:655)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:654)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12690101">HDFS-5804</key>
            <summary>HDFS NFS Gateway fails to mount and proxy when using Kerberos</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12680417">HDFS-5539</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ashahab">Abin Shahab</assignee>
                                    <reporter username="ashahab">Abin Shahab</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 20:09:41 +0000</created>
                <updated>Sat, 1 Feb 2014 13:40:00 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 23:13:42 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>nfs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13878036" author="brandonli" created="Tue, 21 Jan 2014 23:57:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashahab&quot; class=&quot;user-hover&quot; rel=&quot;ashahab&quot;&gt;Abin Shahab&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5539&quot; title=&quot;NFS gateway secuirty enhancement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5539&quot;&gt;HDFS-5539&lt;/a&gt; is filed to track the security enhancement. Currently NFS gateway can&apos;t work with secure cluster. I&apos;m moving this JIRA under &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5539&quot; title=&quot;NFS gateway secuirty enhancement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5539&quot;&gt;HDFS-5539&lt;/a&gt; to track the effort.&lt;/p&gt;</comment>
                            <comment id="13878045" author="ashahab" created="Wed, 22 Jan 2014 00:03:52 +0000"  >&lt;p&gt;This patch resolves the above-mentioned root-mounting problem.&lt;br/&gt;
However, it has to explicitly check for root. This is because, the nfs client mounts as root, and right after, it does a getFileAttr call on hdfs &apos;/&apos;. With kerberos on the root user does not have access to do this. If someone can advise on a way to avoid this root check, it would be great.&lt;/p&gt;</comment>
                            <comment id="13879264" author="ashahab" created="Wed, 22 Jan 2014 22:12:31 +0000"  >&lt;p&gt;This is patched against trunk.&lt;/p&gt;</comment>
                            <comment id="13879440" author="ashahab" created="Thu, 23 Jan 2014 05:02:14 +0000"  >&lt;p&gt;Patch emits some javadoc warnings, but there are no differences between the javadoc output of the version with the patch and version without the patch.&lt;/p&gt;</comment>
                            <comment id="13879445" author="ashahab" created="Thu, 23 Jan 2014 05:16:51 +0000"  >&lt;p&gt;The before and after logs of the call: mvn clean test javadoc:javadoc -DskipTests -Pdocs&lt;/p&gt;</comment>
                            <comment id="13879932" author="daryn" created="Thu, 23 Jan 2014 13:58:59 +0000"  >&lt;p&gt;I&apos;m unfamiliar with the nfs code to level set these comments.  My initial feeling is that the conditional logic is less than desirable.&lt;/p&gt;

&lt;p&gt;Relative to the provided patch, I think there&apos;s a clean way to avoid the explicit root check.  The check seems circumspect as in there shouldn&apos;t be a pre-condition that the fuse daemon run as &quot;root&quot;.  My basic understanding is that fuse runs as root to access user ticket caches.  However, there&apos;s no reason I couldn&apos;t map a different username to uid 0, allow a non-privileged user to access the ticket caches based on group perms, use SELinux capabilities to grant a fsuid of root to the fuse daemon, etc.&lt;/p&gt;

&lt;p&gt;Anyway, back to the patch.  A better way may be to check the given username against the current user.  Create a proxy user if they are different, else return the current user.  No isSecurityEnabled or root comparison needed.  Or better yet, just always create a proxy user.  A proxy will work with or w/o security, and proxy of the same user also/should work.&lt;/p&gt;

&lt;p&gt;I&apos;m unclear how this patch solves the issue of root cannot stat /.  A proxy is only being created if the user isn&apos;t root so how does this fix the issue?&lt;/p&gt;</comment>
                            <comment id="13880293" author="ashahab" created="Thu, 23 Jan 2014 20:00:39 +0000"  >&lt;p&gt;Updated patch does not have special case on root.&lt;br/&gt;
Tested with nfs-gateway running as a non-root kerberized user.&lt;/p&gt;</comment>
                            <comment id="13880366" author="ashahab" created="Thu, 23 Jan 2014 21:15:00 +0000"  >&lt;p&gt;This is the exception I get now. &lt;br/&gt;
ROOT is doing the mount of nfs.&lt;br/&gt;
As part of the mount, it issues an FSINFO call, which fails, and it fails the mount.&lt;/p&gt;

&lt;p&gt;I propose we catch and log the Access control exception for this failure, but not necessary fail the mount.&lt;/p&gt;</comment>
                            <comment id="13880379" author="jingzhao" created="Thu, 23 Jan 2014 21:26:02 +0000"  >&lt;p&gt;So I guess that idea here is that the nfs gateway acts a service, and authenticates itself through Kerberos to Hadoop/HDFS. Then for the clients of nfs, if a client can authenticate itself in the NFS gateway (currently we only support AUTH_UNIX, and we plan to support GSS in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5539&quot; title=&quot;NFS gateway secuirty enhancement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5539&quot;&gt;HDFS-5539&lt;/a&gt;), the nfs gateway will create a proxy user for the client and use the proxy user to communicate with HDFS.&lt;/p&gt;

&lt;p&gt;Back to the exception, I have not tested myself, but have you add the proxy user setting in your HDFS&apos;s configuration? Because I saw the exception msg is &quot;User: nfsserver/krb-nfs-desktop.my.company.com@KRB.ALTISCALE.COM is not allowed to impersonate root&quot;.&lt;/p&gt;</comment>
                            <comment id="13880395" author="ashahab" created="Thu, 23 Jan 2014 21:39:49 +0000"  >&lt;p&gt;Jing, Thanks a lot for looking at the issue. I think you&apos;ve captured what I&apos;m trying to do very well! Thanks for that.&lt;/p&gt;

&lt;p&gt;Yes. We specifically do not want nfsserver(the user running the nfs-gateway) to be able to impersonate root. We need root for one thing, and only one thing: to mount the filesystem. After that, root is irrelevant, and should not have any access to do anything. Regretably, it does an FSINFO as part of the mount.&lt;/p&gt;</comment>
                            <comment id="13880459" author="jingzhao" created="Thu, 23 Jan 2014 22:32:22 +0000"  >&lt;p&gt;Abin, I see your issue now. So from the nfs-gateway point of view, I think it should just simply impersonate any user who has passed its own authentication, thus should not have special case on root. In HDFS, why do you want to disable the proxy setting for root? HDFS does not respect root as a special user.&lt;/p&gt;</comment>
                            <comment id="13880491" author="ashahab" created="Thu, 23 Jan 2014 23:05:09 +0000"  >&lt;p&gt;Ah! I see your point. I think I can allow nfsserver to proxy root, and that&apos;d allow this patch to work properly(I&apos;ve removed the root check condition).&lt;/p&gt;

&lt;p&gt;BTW, this still allows any user in the proxied group to authenticate WITHOUT having a kerberos ticket. Do you have any advice on implementing the kerberos authentication on the nfs-gateway? We are kerberizing our clusters, and seems like nfs is allowing them to circumvent kerberos authentication.&lt;/p&gt;</comment>
                            <comment id="13880508" author="jingzhao" created="Thu, 23 Jan 2014 23:30:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;this still allows any user in the proxied group to authenticate WITHOUT having a kerberos ticket.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, currently nfs-gateway can only do simple AUTH_UNIX authentication, thus we need to finish &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5086&quot; title=&quot;Support RPCSEC_GSS authentication in NFSv3 gateway&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5086&quot;&gt;HDFS-5086&lt;/a&gt; so that nfs-gateway can authenticate clients based on kerberos. I have an in-progress patch long time ago, I will see if I can finish it recently. Also feel free to assign that jira to yourself if you want to work on it.&lt;/p&gt;</comment>
                            <comment id="13880550" author="ashahab" created="Fri, 24 Jan 2014 00:31:57 +0000"  >&lt;p&gt;May I take a look at your patch? I was planning to mimic how org.apache.hadoop.ipc.Client does the authentication.&lt;br/&gt;
Also, I don&apos;t have access to assign issues to myself. I would definitely like to assign this one to me.&lt;/p&gt;</comment>
                            <comment id="13880572" author="jingzhao" created="Fri, 24 Jan 2014 00:55:38 +0000"  >&lt;p&gt;Sure, I will post what I have to &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5086&quot; title=&quot;Support RPCSEC_GSS authentication in NFSv3 gateway&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5086&quot;&gt;HDFS-5086&lt;/a&gt;. In general, I was just trying to merge the GSS authentication part from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;&apos;s NFS4 implementation (&lt;a href=&quot;https://github.com/cloudera/hdfs-nfs-proxy&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/cloudera/hdfs-nfs-proxy&lt;/a&gt;) into the current NFS3-based implementation. You can directly check &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;&apos;s implementation also.&lt;/p&gt;</comment>
                            <comment id="13880577" author="ashahab" created="Fri, 24 Jan 2014 00:58:19 +0000"  >&lt;p&gt;BTW, I have a patch that gets rid off even checking whether we are in secure mode, but I&apos;m not sure if it&apos;s the right thing to submit that patch. That patch would require the nfs-gateway user(nfsserver in our case) be allowed to proxy root, even in non-secure mode. That&apos;s a big change.&lt;/p&gt;</comment>
                            <comment id="13881374" author="ashahab" created="Fri, 24 Jan 2014 20:10:49 +0000"  >&lt;p&gt;Updated documentation and param names&lt;/p&gt;</comment>
                            <comment id="13881375" author="ashahab" created="Fri, 24 Jan 2014 20:11:26 +0000"  >&lt;p&gt;Jing, let me know if you have any feedback on my patch.&lt;/p&gt;</comment>
                            <comment id="13881707" author="hadoopqa" created="Sat, 25 Jan 2014 06:20:26 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625100/HDFS-5804.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625100/HDFS-5804.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs-nfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5940//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5940//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5940//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5940//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13882853" author="daryn" created="Mon, 27 Jan 2014 14:53:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;BTW, I have a patch that gets rid off even checking whether we are in secure mode, but I&apos;m not sure if it&apos;s the right thing to submit that patch. That patch would require the nfs-gateway user(nfsserver in our case) be allowed to proxy root, even in non-secure mode. That&apos;s a big change.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it&apos;s the right thing to do and it&apos;s not large.  We ideally need to move away from all the &lt;tt&gt;isSecurityEnabled&lt;/tt&gt; checks.  They introduce additional code paths that lack coverage and sufficient testing.&lt;/p&gt;

&lt;p&gt;When you create a proxy user, it&apos;s not conferring the privileges of the real user (ex. root/nfsserver) to the effective user.  The real user is simply used to authenticate the connection on behalf of the effective user.  After that all permission checking uses the effective user.&lt;/p&gt;

&lt;p&gt;Even with security off, I&apos;m pretty sure proxy users need to be configured for components like oozie to work.&lt;/p&gt;</comment>
                            <comment id="13883495" author="ashahab" created="Mon, 27 Jan 2014 23:09:05 +0000"  >&lt;p&gt;This removes the isSecurityEnabled check.&lt;/p&gt;</comment>
                            <comment id="13883548" author="hadoopqa" created="Tue, 28 Jan 2014 00:13:49 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625470/HDFS-5804.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625470/HDFS-5804.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs-nfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.nfs.nfs3.TestWrites&lt;br/&gt;
                  org.apache.hadoop.hdfs.nfs.TestReaddir&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5956//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5956//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5956//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5956//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883739" author="ashahab" created="Tue, 28 Jan 2014 04:28:45 +0000"  >&lt;p&gt;Test fix&lt;/p&gt;</comment>
                            <comment id="13883750" author="hadoopqa" created="Tue, 28 Jan 2014 04:54:17 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625518/HDFS-5804.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625518/HDFS-5804.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs-nfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5959//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5959//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5959//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5959//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13884455" author="daryn" created="Tue, 28 Jan 2014 19:19:30 +0000"  >&lt;p&gt;Are the other &lt;tt&gt;isSecurityEnabled&lt;/tt&gt; checks still required?&lt;/p&gt;</comment>
                            <comment id="13884684" author="ashahab" created="Tue, 28 Jan 2014 21:06:46 +0000"  >&lt;p&gt;Removed all the security checks.&lt;/p&gt;</comment>
                            <comment id="13884715" author="hadoopqa" created="Tue, 28 Jan 2014 21:25:20 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625663/HDFS-5804.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625663/HDFS-5804.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated -14 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;        &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs-nfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5963//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5963//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5963//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5963//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5963//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5963//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13884827" author="daryn" created="Tue, 28 Jan 2014 22:57:28 +0000"  >&lt;p&gt;Looks good!  Just fix the javadoc and audit warnings.&lt;/p&gt;</comment>
                            <comment id="13884892" author="hadoopqa" created="Tue, 28 Jan 2014 23:17:37 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625685/HDFS-5804.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625685/HDFS-5804.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 3 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs-nfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5966//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5966//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5966//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5966//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886240" author="ashahab" created="Thu, 30 Jan 2014 04:16:55 +0000"  >&lt;p&gt;Hi Daryn,&lt;br/&gt;
Would you be able to merge the patch?&lt;/p&gt;</comment>
                            <comment id="13888262" author="jingzhao" created="Fri, 31 Jan 2014 22:52:50 +0000"  >&lt;p&gt;+1 for the latest patch. I will commit it shortly.&lt;/p&gt;</comment>
                            <comment id="13888277" author="hudson" created="Fri, 31 Jan 2014 23:05:56 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5087 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5087/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5087/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5804&quot; title=&quot;HDFS NFS Gateway fails to mount and proxy when using Kerberos&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5804&quot;&gt;&lt;del&gt;HDFS-5804&lt;/del&gt;&lt;/a&gt;. HDFS NFS Gateway fails to mount and proxy when using Kerberos. Contributed by Abin Shahab. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/TestReaddir.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestDFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestWrites.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888285" author="jingzhao" created="Fri, 31 Jan 2014 23:13:42 +0000"  >&lt;p&gt;I&apos;ve committed this to trunk and branch-2. Thanks for the contribution, Abin!&lt;/p&gt;</comment>
                            <comment id="13888528" author="hudson" created="Sat, 1 Feb 2014 11:04:49 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #468 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/468/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5804&quot; title=&quot;HDFS NFS Gateway fails to mount and proxy when using Kerberos&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5804&quot;&gt;&lt;del&gt;HDFS-5804&lt;/del&gt;&lt;/a&gt;. HDFS NFS Gateway fails to mount and proxy when using Kerberos. Contributed by Abin Shahab. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/TestReaddir.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestDFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestWrites.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888578" author="hudson" created="Sat, 1 Feb 2014 13:29:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1685 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1685/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5804&quot; title=&quot;HDFS NFS Gateway fails to mount and proxy when using Kerberos&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5804&quot;&gt;&lt;del&gt;HDFS-5804&lt;/del&gt;&lt;/a&gt;. HDFS NFS Gateway fails to mount and proxy when using Kerberos. Contributed by Abin Shahab. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/TestReaddir.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestDFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestWrites.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13888592" author="hudson" created="Sat, 1 Feb 2014 13:40:00 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1660 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1660/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5804&quot; title=&quot;HDFS NFS Gateway fails to mount and proxy when using Kerberos&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5804&quot;&gt;&lt;del&gt;HDFS-5804&lt;/del&gt;&lt;/a&gt;. HDFS NFS Gateway fails to mount and proxy when using Kerberos. Contributed by Abin Shahab. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1563323&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/TestReaddir.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestDFSClientCache.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestWrites.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12644504">HDFS-4750</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625685" name="HDFS-5804.patch" size="9370" author="ashahab" created="Tue, 28 Jan 2014 22:17:09 +0000"/>
                            <attachment id="12625663" name="HDFS-5804.patch" size="10443" author="ashahab" created="Tue, 28 Jan 2014 21:06:46 +0000"/>
                            <attachment id="12625518" name="HDFS-5804.patch" size="10725" author="ashahab" created="Tue, 28 Jan 2014 04:28:45 +0000"/>
                            <attachment id="12625470" name="HDFS-5804.patch" size="7572" author="ashahab" created="Mon, 27 Jan 2014 23:09:05 +0000"/>
                            <attachment id="12625100" name="HDFS-5804.patch" size="8081" author="ashahab" created="Fri, 24 Jan 2014 20:10:49 +0000"/>
                            <attachment id="12624889" name="HDFS-5804.patch" size="7685" author="ashahab" created="Thu, 23 Jan 2014 20:00:39 +0000"/>
                            <attachment id="12624574" name="HDFS-5804.patch" size="9006" author="ashahab" created="Thu, 23 Jan 2014 05:02:14 +0000"/>
                            <attachment id="12624914" name="exception-as-root.log" size="183704" author="ashahab" created="Thu, 23 Jan 2014 21:15:00 +0000"/>
                            <attachment id="12624576" name="javadoc-after-patch.log" size="1713687" author="ashahab" created="Thu, 23 Jan 2014 05:16:51 +0000"/>
                            <attachment id="12624577" name="javadoc-before-patch.log" size="1718879" author="ashahab" created="Thu, 23 Jan 2014 05:16:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 21 Jan 2014 23:57:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369063</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369064</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fixes NFS on Kerberized cluster.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5803] TestBalancer.testBalancer0 fails</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5803</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The test testBalancer0 fails on branch 2. Below is the stack trace&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.util.concurrent.TimeoutException: Cluster failed to reached expected values of totalSpace (current: 1500, expected: 1500), or usedSpace (current: 280, expected: 300), in more than 20000 msec.
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.waitForHeartBeat(TestBalancer.java:245)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:375)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:359)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.twoNodeTest(TestBalancer.java:404)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:448)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0(TestBalancer.java:442)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12690084">HDFS-5803</key>
            <summary>TestBalancer.testBalancer0 fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 18:54:38 +0000</created>
                <updated>Tue, 21 Jan 2014 18:54:38 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369046</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>369047</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5802] NameNode does not check for inode type before traversing down a path</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5802</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This came up during the discussion on a forum at &lt;a href=&quot;http://community.cloudera.com/t5/Batch-Processing-and-Workflow/Permission-denied-access-EXECUTE-on-getting-the-status-of-a-file/m-p/5049#M162&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://community.cloudera.com/t5/Batch-Processing-and-Workflow/Permission-denied-access-EXECUTE-on-getting-the-status-of-a-file/m-p/5049#M162&lt;/a&gt; surrounding an fs.exists(&#8230;) check running on a path /foo/bar, where /foo is a file and not a directory.&lt;/p&gt;

&lt;p&gt;In such a case, NameNode yields a user-confusing message of &lt;tt&gt;Permission denied: user=foo, access=EXECUTE, inode=&quot;/foo&quot;:foo:foo:&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-&lt;/tt&gt; instead of clearly saying (and realising) &quot;/foo is not a directory&quot; or &quot;/foo is a file&quot; before it tries to traverse further down to locate the requested path.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689950">HDFS-5802</key>
            <summary>NameNode does not check for inode type before traversing down a path</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="qwertymaniac">Harsh J</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 05:22:46 +0000</created>
                <updated>Tue, 21 Jan 2014 05:22:46 +0000</updated>
                                            <version>2.0.0-alpha</version>
                                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368921</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368922</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5801] HDFS rack-awareness for nodes outside of the cluster</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5801</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In some cases, user may setup HDFS clusters using part of the machines in one rack; in this case, the client may be outside of the HDFS cluster but still in the same rack with some of the datanodes; if we can provide the feature to enable the rack-awareness in this scenario, that will be great! &lt;/p&gt;</description>
                <environment></environment>
        <key id="12689942">HDFS-5801</key>
            <summary>HDFS rack-awareness for nodes outside of the cluster</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stanley_shi">stanley shi</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Jan 2014 03:39:18 +0000</created>
                <updated>Tue, 21 Jan 2014 03:39:18 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368913</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368914</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5800] Typo: soft-limit for hard-limit in DFSClient</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5800</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In DFSClient#renewLease, there is a log message as follows.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Failed to renew lease &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &quot;&lt;/span&gt; + clientName + &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &quot;&lt;/span&gt;
              + (elapsed/1000) + &lt;span class=&quot;code-quote&quot;&gt;&quot; seconds (&amp;gt;= soft-limit =&quot;&lt;/span&gt;
              + (HdfsConstants.LEASE_HARDLIMIT_PERIOD/1000) + &lt;span class=&quot;code-quote&quot;&gt;&quot; seconds.) &quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This log message includes &quot;soft-limit&quot; but, considering the context, I think it&apos;s typo for &quot;hard-limit&quot;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689772">HDFS-5800</key>
            <summary>Typo: soft-limit for hard-limit in DFSClient</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sarutak">Kousuke Saruta</assignee>
                                    <reporter username="sarutak">Kousuke Saruta</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Jan 2014 06:31:15 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:30 +0000</updated>
                            <resolved>Mon, 20 Jan 2014 14:10:48 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                    <component>hdfs-client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13876181" author="sarutak" created="Mon, 20 Jan 2014 06:34:18 +0000"  >&lt;p&gt;I&apos;ve attached a patch for this issue.&lt;/p&gt;</comment>
                            <comment id="13876238" author="ajisakaa" created="Mon, 20 Jan 2014 08:13:59 +0000"  >&lt;p&gt;+1, LGTM. Pending Jenkins.&lt;/p&gt;</comment>
                            <comment id="13876266" author="hadoopqa" created="Mon, 20 Jan 2014 09:04:20 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623906/HDFS-5800.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623906/HDFS-5800.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5917//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5917//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5917//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5917//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13876282" author="ajisakaa" created="Mon, 20 Jan 2014 09:32:06 +0000"  >&lt;p&gt;The test failure should be unrelated to the simple patch.&lt;/p&gt;</comment>
                            <comment id="13876458" author="szetszwo" created="Mon, 20 Jan 2014 14:10:48 +0000"  >&lt;p&gt;I have committed this.  Thanks Kousuke!&lt;/p&gt;

&lt;p&gt;Thanks also Akira for reviewing the patch.&lt;/p&gt;</comment>
                            <comment id="13876461" author="hudson" created="Mon, 20 Jan 2014 14:15:31 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5024 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5024/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5024/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5800&quot; title=&quot;Typo: soft-limit for hard-limit in DFSClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5800&quot;&gt;&lt;del&gt;HDFS-5800&lt;/del&gt;&lt;/a&gt;. Fix a typo in DFSClient.renewLease().  Contributed by Kousuke Saruta (szetszwo: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13877386" author="hudson" created="Tue, 21 Jan 2014 11:09:39 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #459 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/459/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/459/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5800&quot; title=&quot;Typo: soft-limit for hard-limit in DFSClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5800&quot;&gt;&lt;del&gt;HDFS-5800&lt;/del&gt;&lt;/a&gt;. Fix a typo in DFSClient.renewLease().  Contributed by Kousuke Saruta (szetszwo: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13877454" author="hudson" created="Tue, 21 Jan 2014 13:27:03 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1676 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1676/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1676/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5800&quot; title=&quot;Typo: soft-limit for hard-limit in DFSClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5800&quot;&gt;&lt;del&gt;HDFS-5800&lt;/del&gt;&lt;/a&gt;. Fix a typo in DFSClient.renewLease().  Contributed by Kousuke Saruta (szetszwo: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13877465" author="hudson" created="Tue, 21 Jan 2014 13:41:40 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1651 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1651/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1651/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5800&quot; title=&quot;Typo: soft-limit for hard-limit in DFSClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5800&quot;&gt;&lt;del&gt;HDFS-5800&lt;/del&gt;&lt;/a&gt;. Fix a typo in DFSClient.renewLease().  Contributed by Kousuke Saruta (szetszwo: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559701&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623906" name="HDFS-5800.patch" size="953" author="sarutak" created="Mon, 20 Jan 2014 06:34:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 20 Jan 2014 08:13:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368744</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368745</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5799] Make audit logging consistent across ACL APIs.</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5799</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Currently, the various ACL APIs are not writing to the audit log consistently.  This patch will ensure that all ACL APIs write to the audit log and finalize the information that they write.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689652">HDFS-5799</key>
            <summary>Make audit logging consistent across ACL APIs.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cnauroth">Chris Nauroth</assignee>
                                    <reporter username="cnauroth">Chris Nauroth</reporter>
                        <labels>
                    </labels>
                <created>Sat, 18 Jan 2014 17:42:39 +0000</created>
                <updated>Thu, 23 Jan 2014 17:43:12 +0000</updated>
                            <resolved>Thu, 23 Jan 2014 17:43:12 +0000</resolved>
                                    <version>HDFS ACLs (HDFS-4685)</version>
                                    <fixVersion>HDFS ACLs (HDFS-4685)</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13875708" author="cnauroth" created="Sat, 18 Jan 2014 17:43:15 +0000"  >&lt;p&gt;I have a patch in progress, so I&apos;m assigning this to myself.&lt;/p&gt;</comment>
                            <comment id="13877920" author="cnauroth" created="Tue, 21 Jan 2014 22:15:01 +0000"  >&lt;p&gt;I&apos;m uploading a patch.  This makes audit logging for the ACL APIs consistent with what we already do for &lt;tt&gt;setPermission&lt;/tt&gt;.  We&apos;ll log the path, the operation name, and the permissions after execution of the operation.  The existing audit logging relies on &lt;tt&gt;FsPermission#toString&lt;/tt&gt;, and we&apos;ve already updated that method in a prior patch to append &apos;+&apos; if there is an ACL present.  I also noticed that &lt;tt&gt;FSNamesystem#setAcl&lt;/tt&gt; was missing its edit log sync, so I added that.&lt;/p&gt;

&lt;p&gt;I also considered the possibility of putting the full ACL into the audit log entries.  However, that could cause some very long audit log lines.  I estimate an extra ~600 characters for an inode that uses the maximum of 32 ACL entries.  There is also the matter of changing a lot of existing operations to fetch the ACL just for the sake of logging.  Let&apos;s not do this right now, and we can always revisit it later if it&apos;s requested.&lt;/p&gt;</comment>
                            <comment id="13879400" author="arpitagarwal" created="Thu, 23 Jan 2014 03:07:15 +0000"  >&lt;p&gt;+1 for the patch. I agree that logging the full ACL is overkill. We could make it an option later.&lt;/p&gt;</comment>
                            <comment id="13880122" author="cnauroth" created="Thu, 23 Jan 2014 17:43:12 +0000"  >&lt;p&gt;Thanks for the review, Arpit.  I committed this to the feature branch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12642003">HDFS-4685</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624201" name="HDFS-5799.1.patch" size="4389" author="cnauroth" created="Tue, 21 Jan 2014 22:15:01 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Jan 2014 03:07:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368624</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368625</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325671</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5798] DFSClient uses non-valid data when computing file checksum</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5798</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;In DFSClient.java, when computing the checksum, all md5 checksums are fetched for each block and added to a DataOutputStream instance (md5out), and later final checksum is computed this way:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;DFSClient.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; MD5Hash fileMD5 = MD5Hash.digest(md5out.getData());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The problem is that getData() return you a buffer valid until md5out.getLength(), and fileMD5 is the MD5 of the MD5 of each block PLUS a bunch of random values (here, buffer is not reused so it should be 0) which depends on the Java implementation of the ByteArrayOutputStream.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689592">HDFS-5798</key>
            <summary>DFSClient uses non-valid data when computing file checksum</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="laurentgo">Laurent Goujon</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Jan 2014 23:09:30 +0000</created>
                <updated>Sat, 18 Jan 2014 05:53:29 +0000</updated>
                            <resolved>Sat, 18 Jan 2014 05:52:15 +0000</resolved>
                                    <version>1.1.2</version>
                    <version>2.0.5-alpha</version>
                                                    <component>hdfs-client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                    <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12440669">HDFS-772</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368564</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368565</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5797] Implement offline image viewer.</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5797</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The format of FSImage has changed dramatically therefore a new implementation of OfflineImageViewer is required.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689577">HDFS-5797</key>
            <summary>Implement offline image viewer.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Jan 2014 22:16:19 +0000</created>
                <updated>Mon, 27 Jan 2014 19:45:08 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 19:45:08 +0000</resolved>
                                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13880592" author="wheat9" created="Fri, 24 Jan 2014 01:16:07 +0000"  >&lt;p&gt;Fix an incorrect format string in LsrPBImage&lt;/p&gt;</comment>
                            <comment id="13883180" author="jingzhao" created="Mon, 27 Jan 2014 19:44:49 +0000"  >&lt;p&gt;I&apos;ve tested this patch and looks like a new oiv can work now. Some comments:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;The new FSImageUtil will add another util class for fsimage. Looks like we need to do some code refactoring here. But since we will finally need to remove all the old saver classes/methods, I think we can do it there.&lt;/li&gt;
	&lt;li&gt;The lsr part will cost memory. I guess we can create a separate jira in the future to improve it.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Thus I think we can commit this patch first and address the remaining issues later. +1&lt;/p&gt;</comment>
                            <comment id="13883182" author="jingzhao" created="Mon, 27 Jan 2014 19:45:08 +0000"  >&lt;p&gt;I&apos;ve committed this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624954" name="HDFS-5797.000.patch" size="76164" author="wheat9" created="Fri, 24 Jan 2014 00:02:40 +0000"/>
                            <attachment id="12624969" name="HDFS-5797.001.patch" size="76821" author="wheat9" created="Fri, 24 Jan 2014 01:16:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Jan 2014 19:44:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368549</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368550</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325854</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5796] The file system browser in the namenode UI requires SPNEGO.</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5796</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;After &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5382&quot; title=&quot;Implement the UI of browsing filesystems in HTML 5 page&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5382&quot;&gt;&lt;del&gt;HDFS-5382&lt;/del&gt;&lt;/a&gt;, the browser makes webhdfs REST calls directly, requiring SPNEGO to work between user&apos;s browser and namenode.  This won&apos;t work if the cluster&apos;s security infrastructure is isolated from the regular network.  Moreover, SPNEGO is not supposed to be required for user-facing web pages.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689518">HDFS-5796</key>
            <summary>The file system browser in the namenode UI requires SPNEGO.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="kihwal">Kihwal Lee</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Jan 2014 16:46:53 +0000</created>
                <updated>Thu, 30 Jan 2014 17:06:24 +0000</updated>
                                            <version>2.3.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13875192" author="wheat9" created="Fri, 17 Jan 2014 19:50:55 +0000"  >&lt;p&gt;WebHDFS is designed to be a gateway for all third-party services where SPNEGO might not be available. &lt;br/&gt;
In my opinion WebHDFS should support the same  authentication mechanisms as the one the web UI supports.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12687282">HDFS-5716</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12674362">HDFS-5382</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 17 Jan 2014 19:50:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368490</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368491</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12326143</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5795] RemoteBlockReader2#checkSuccess() shoud print error status </title>
                <link>https://issues.apache.org/jira/browse/HDFS-5795</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;RemoteBlockReader2#checkSuccess() doesn&apos;t print error status, which makes debug harder when the client can&apos;t read from DataNode.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689412">HDFS-5795</key>
            <summary>RemoteBlockReader2#checkSuccess() shoud print error status </summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="brandonli">Brandon Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Jan 2014 01:05:10 +0000</created>
                <updated>Fri, 17 Jan 2014 01:05:10 +0000</updated>
                                            <version>3.0.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368384</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368385</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5794] Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5794</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Currently in trunk, we have the layout version:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
EDITLOG_ADD_BLOCK(-48, ...),
CACHING(-49, ...),
ADD_DATANODE_AND_STORAGE_UUIDS(-50, ...);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And in branch-2, we have:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
EDITLOG_SUPPORT_RETRYCACHE(-47, ...),
ADD_DATANODE_AND_STORAGE_UUIDS(-49, -47, ...);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We plan to backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5704&quot; title=&quot;Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5704&quot;&gt;&lt;del&gt;HDFS-5704&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt; to branch-2, thus EDITLOG_ADD_BLOCK will also take -48 in branch-2. However, we cannot change ADD_DATANODE_AND_STORAGE_UUIDS to -50 in branch-2. Otherwise fsimages written by trunk and branch-2 have the same layout -50 but branch-2 cannot read the -50 fsimage if it is written by trunk.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689392">HDFS-5794</key>
            <summary>Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="jingzhao">Jing Zhao</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 23:07:56 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:31 +0000</updated>
                            <resolved>Fri, 17 Jan 2014 18:31:29 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>2.3.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13874129" author="jingzhao" created="Thu, 16 Jan 2014 23:15:48 +0000"  >&lt;p&gt;One solution for this issue is to switch CACHING and ADD_DATANODE_AND_STORAGE_UUIDS in trunk. Post a simple patch following this solution.&lt;/p&gt;</comment>
                            <comment id="13874306" author="cmccabe" created="Fri, 17 Jan 2014 01:54:44 +0000"  >&lt;p&gt;+1 for this approach of putting CACHING last, once you&apos;ve rebased and re-run jenkins.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5784&quot; title=&quot;reserve space in edit log header and fsimage header for feature flag section&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5784&quot;&gt;&lt;del&gt;HDFS-5784&lt;/del&gt;&lt;/a&gt; added another layout version which CACHING should come after.&lt;/p&gt;</comment>
                            <comment id="13874328" author="hadoopqa" created="Fri, 17 Jan 2014 02:18:29 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623524/HDFS-5794.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623524/HDFS-5794.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5905//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5905//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5905//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5905//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13874363" author="szetszwo" created="Fri, 17 Jan 2014 02:52:38 +0000"  >&lt;p&gt;+1 patch looks good.&lt;/p&gt;</comment>
                            <comment id="13874507" author="jingzhao" created="Fri, 17 Jan 2014 06:41:33 +0000"  >&lt;p&gt;Thanks for the review, Nicholas and Colin! Rebase the patch and put CACHING last.&lt;/p&gt;</comment>
                            <comment id="13874582" author="szetszwo" created="Fri, 17 Jan 2014 09:04:04 +0000"  >&lt;p&gt;+1 the new patch looks good.&lt;/p&gt;</comment>
                            <comment id="13874588" author="hadoopqa" created="Fri, 17 Jan 2014 09:12:38 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623592/HDFS-5794.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623592/HDFS-5794.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5909//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5909//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5909//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5909//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13875055" author="hudson" created="Fri, 17 Jan 2014 18:25:18 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5018 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5018/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5018/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5794&quot; title=&quot;Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5794&quot;&gt;&lt;del&gt;HDFS-5794&lt;/del&gt;&lt;/a&gt;. Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875064" author="jingzhao" created="Fri, 17 Jan 2014 18:31:29 +0000"  >&lt;p&gt;I&apos;ve committed this. The change is only needed in trunk. Layout version changes in branch-2 will later be covered by merging &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13875617" author="hudson" created="Sat, 18 Jan 2014 11:08:48 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #456 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5794&quot; title=&quot;Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5794&quot;&gt;&lt;del&gt;HDFS-5794&lt;/del&gt;&lt;/a&gt;. Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875645" author="hudson" created="Sat, 18 Jan 2014 13:26:06 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1648 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5794&quot; title=&quot;Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5794&quot;&gt;&lt;del&gt;HDFS-5794&lt;/del&gt;&lt;/a&gt;. Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875653" author="hudson" created="Sat, 18 Jan 2014 13:27:05 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1673 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5794&quot; title=&quot;Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5794&quot;&gt;&lt;del&gt;HDFS-5794&lt;/del&gt;&lt;/a&gt;. Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559209&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623524" name="HDFS-5794.000.patch" size="1140" author="jingzhao" created="Thu, 16 Jan 2014 23:15:48 +0000"/>
                            <attachment id="12623592" name="HDFS-5794.001.patch" size="1200" author="jingzhao" created="Fri, 17 Jan 2014 06:41:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 17 Jan 2014 01:54:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368364</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368366</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5793] Optimize the serialization of PermissionStatus</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5793</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;tt&gt;PermissionStatus&lt;/tt&gt; contains the user name, the group name and the permission. It is serialized into two strings and a short.&lt;/p&gt;

&lt;p&gt;Note that the size of unique user / groups names are relatively small, thus this format has some performance penalties. The names are stored multiple times, increasing both the storage size and the overhead of reconstructing the names.&lt;/p&gt;

&lt;p&gt;This jira proposes to serialize &lt;tt&gt;PermissionStatus&lt;/tt&gt; similar to its in-memory layout. The code can record a mapping between user / group names and ids, and pack user / group / permission into a single 64-bit long.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689378">HDFS-5793</key>
            <summary>Optimize the serialization of PermissionStatus</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 22:25:26 +0000</created>
                <updated>Sat, 18 Jan 2014 01:24:13 +0000</updated>
                            <resolved>Sat, 18 Jan 2014 01:24:13 +0000</resolved>
                                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13874061" author="wheat9" created="Thu, 16 Jan 2014 22:33:02 +0000"  >&lt;p&gt;I&apos;ve tested the impact of this patch using a 512M fsimage on my machine. This patch reduces the loading time from 14s to 12s. It also reduces the size of the fsimage by 7%, from 508M to 469M.&lt;/p&gt;</comment>
                            <comment id="13875458" author="wheat9" created="Sat, 18 Jan 2014 01:04:57 +0000"  >&lt;p&gt;Rebased.&lt;/p&gt;</comment>
                            <comment id="13875470" author="jingzhao" created="Sat, 18 Jan 2014 01:21:14 +0000"  >&lt;p&gt;I guess here we can also serialize the SerialNumberManager and directly use the original long number to represent the permission. But the current solution also looks fine to me. +1&lt;/p&gt;</comment>
                            <comment id="13875472" author="jingzhao" created="Sat, 18 Jan 2014 01:24:13 +0000"  >&lt;p&gt;I&apos;ve committed this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623500" name="HDFS-5793.000.patch" size="11467" author="wheat9" created="Thu, 16 Jan 2014 22:25:50 +0000"/>
                            <attachment id="12623760" name="HDFS-5793.001.patch" size="11381" author="wheat9" created="Sat, 18 Jan 2014 01:04:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 18 Jan 2014 01:21:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368350</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368352</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5792] DFSOutputStream.close() throws exceptions with unintuitive stacktraces</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5792</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Given the following client code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class Foo {
  void test() {
    FSDataOutputStream out = ...;
    out.write(...);
    out.close();
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A programmer would expect an exception thrown from &lt;tt&gt;out.close()&lt;/tt&gt; to include the stack trace of the calling thread:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;...
FSDataOutputStream.close()
Foo.test()
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Instead, it includes the stack trace from the &lt;tt&gt;DataStreamer&lt;/tt&gt; thread:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.io.IOException: All datanodes 127.0.0.1:49331 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1023)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:838)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:483)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This makes it difficult to debug the &lt;em&gt;client&lt;/em&gt; call stack that actually was unwinded when the exception was thrown.&lt;/p&gt;

&lt;p&gt;A simple fix seems to be modifying &lt;tt&gt;DFSOutputStream.close()&lt;/tt&gt; to wrap the &lt;tt&gt;lastException&lt;/tt&gt; from the &lt;tt&gt;DataStreamer&lt;/tt&gt; thread in a &lt;tt&gt;Exception&lt;/tt&gt;, thereby getting both stack traces.  &lt;/p&gt;

&lt;p&gt;I can work on a patch for this.  Can someone confirm that my approach is acceptable?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689362">HDFS-5792</key>
            <summary>DFSOutputStream.close() throws exceptions with unintuitive stacktraces</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="sirianni">Eric Sirianni</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 21:32:46 +0000</created>
                <updated>Thu, 16 Jan 2014 21:32:46 +0000</updated>
                                                                            <component>hdfs-client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368334</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368336</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5791] TestHttpsFileSystem should use a random port to avoid binding error during testing</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5791</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hdfs.web.TestHttpsFileSystem.org.apache.hadoop.hdfs.web.TestHttpsFileSystem
Failing for the past 1 build (Since Failed#5900 )
Took 2.7 sec.
Error Message

Port in use: localhost:50475

Stacktrace

java.net.BindException: Port in use: localhost:50475
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.PlainSocketImpl.bind(PlainSocketImpl.java:383)
	at java.net.ServerSocket.bind(ServerSocket.java:328)
	at java.net.ServerSocket.&amp;lt;init&amp;gt;(ServerSocket.java:194)
	at javax.net.ssl.SSLServerSocket.&amp;lt;init&amp;gt;(SSLServerSocket.java:106)
	at com.sun.net.ssl.internal.ssl.SSLServerSocketImpl.&amp;lt;init&amp;gt;(SSLServerSocketImpl.java:108)
	at com.sun.net.ssl.internal.ssl.SSLServerSocketFactoryImpl.createServerSocket(SSLServerSocketFactoryImpl.java:72)
	at org.mortbay.jetty.security.SslSocketConnector.newServerSocket(SslSocketConnector.java:478)
	at org.mortbay.jetty.bio.SocketConnector.open(SocketConnector.java:73)
	at org.apache.hadoop.http.HttpServer.openListeners(HttpServer.java:973)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:914)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startInfoServer(DataNode.java:413)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:770)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.&amp;lt;init&amp;gt;(DataNode.java:316)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1847)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1747)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1217)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:683)
	at org.apache.hadoop.hdfs.MiniDFSCluster.&amp;lt;init&amp;gt;(MiniDFSCluster.java:351)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:332)
	at org.apache.hadoop.hdfs.web.TestHttpsFileSystem.setUp(TestHttpsFileSystem.java:64)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12689360">HDFS-5791</key>
            <summary>TestHttpsFileSystem should use a random port to avoid binding error during testing</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="brandonli">Brandon Li</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 21:29:50 +0000</created>
                <updated>Thu, 16 Jan 2014 23:07:09 +0000</updated>
                                            <version>3.0.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368332</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368334</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5790] LeaseManager.findPath is very slow when many leases need recovery</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5790</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;We recently saw an issue where the NN restarted while tens of thousands of files were open. The NN then ended up spending multiple seconds for each commitBlockSynchronization() call, spending most of its time inside LeaseManager.findPath(). findPath currently works by looping over all files held for a given writer, and traversing the filesystem for each one. This takes way too long when tens of thousands of files are open by a single writer.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689348">HDFS-5790</key>
            <summary>LeaseManager.findPath is very slow when many leases need recovery</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tlipcon">Todd Lipcon</assignee>
                                    <reporter username="tlipcon">Todd Lipcon</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 20:50:58 +0000</created>
                <updated>Fri, 31 Jan 2014 13:39:15 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 21:21:43 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>namenode</component>
                    <component>performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13873917" author="tlipcon" created="Thu, 16 Jan 2014 20:52:03 +0000"  >&lt;p&gt;The handler threads were spending most of their time in this stack trace:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;IPC Server handler 1 on 8055&quot;&lt;/span&gt; daemon prio=10 tid=0x00002ab5c87bc800 nid=0x71dc runnable [0x0000000056e93000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
        at java.util.Collections.indexedBinarySearch(Collections.java:215)
        at java.util.Collections.binarySearch(Collections.java:201)
        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getChildINode(INodeDirectory.java:107)
        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getExistingPathINodes(INodeDirectory.java:211)
        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getNode(INodeDirectory.java:121)
        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getNode(INodeDirectory.java:130)
        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getINode(FSDirectory.java:1247)
        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getFileINode(FSDirectory.java:1234)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Lease.findPath(LeaseManager.java:256)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Lease.access$300(LeaseManager.java:225)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager.findPath(LeaseManager.java:186)
        - locked &amp;lt;0x00002aaac5a38b48&amp;gt; (a org.apache.hadoop.hdfs.server.namenode.LeaseManager)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitBlockSynchronization(FSNamesystem.java:3229)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.commitBlockSynchronization(NameNodeRpcServer.java:560)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(line numbers may be slightly off, since this is from an older release, but code appears to still be structured approximately the same in trunk)&lt;/p&gt;</comment>
                            <comment id="13873921" author="tlipcon" created="Thu, 16 Jan 2014 20:55:12 +0000"  >&lt;p&gt;Looking at the code, it&apos;s not obvious why we need to do:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      src = leaseManager.findPath(pendingFile);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;as opposed to something like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      src = pendingFile.getFullPathName();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;since in theory the inode path and the lease path should always be kept in sync. Same is true of the same call in commitOrCompleteLastBlock()&lt;/p&gt;</comment>
                            <comment id="13874219" author="tlipcon" created="Fri, 17 Jan 2014 00:37:50 +0000"  >&lt;p&gt;As a quick check of the above, I did the following patch:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java b/hadoop-hdfs-p
index 8b5fb81..62e60da 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java
@@ -40,6 +40,7 @@
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.util.Daemon;
 
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; com.google.common.annotations.VisibleForTesting;
+&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; com.google.common.base.Objects;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; com.google.common.base.Preconditions;
 
 /**
@@ -256,6 +257,16 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; expiredSoftLimit() {
      * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the path associated with the pendingFile and &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not found.
      */
     &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; findPath(INodeFile pendingFile) {
+      &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; retOrig = findPathOrig(pendingFile);
+      &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; retNew = pendingFile.getFullPathName();
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!Objects.equal(retOrig, retNew)) {
+        &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AssertionError(&lt;span class=&quot;code-quote&quot;&gt;&quot;orig implementation found: &quot;&lt;/span&gt; + retOrig +
+                                 &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; implementation found: &quot;&lt;/span&gt; + retNew);
+      }
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; retNew;
+    }
+
+    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; findPathOrig(INodeFile pendingFile) {
       &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
         &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; src : paths) {
           INode node = fsnamesystem.dir.getINode(src);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;that is to say, I try the suggested optimization, along with the original implementation, and verify that they return the same results. I ran all the HDFS tests and they all passed, indicating that it&apos;s likely this optimization wouldn&apos;t break anything. And, it should be much faster, since it&apos;s O(directory depth) instead of O(number of leases held by the client * those lease&apos;s directory depths).&lt;/p&gt;

&lt;p&gt;Anyone have opinions on this? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kihwal&quot; class=&quot;user-hover&quot; rel=&quot;kihwal&quot;&gt;Kihwal Lee&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=daryn&quot; class=&quot;user-hover&quot; rel=&quot;daryn&quot;&gt;Daryn Sharp&lt;/a&gt; maybe? (seem to recall both of you working in this area a few months back)&lt;/p&gt;</comment>
                            <comment id="13878024" author="tlipcon" created="Tue, 21 Jan 2014 23:47:17 +0000"  >&lt;p&gt;Attached patch gets rid of the slow method and just calls INode.getFullPathName() everywhere it was used. My local test results above indicates this ought to work, and I don&apos;t see why it wouldn&apos;t, but would appreciate some reviews.&lt;/p&gt;</comment>
                            <comment id="13878102" author="hadoopqa" created="Wed, 22 Jan 2014 01:07:02 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624229/hdfs-5790.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624229/hdfs-5790.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5932//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5932//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13878256" author="hadoopqa" created="Wed, 22 Jan 2014 04:46:35 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624258/hdfs-5790.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624258/hdfs-5790.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5933//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5933//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5933//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5933//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13878326" author="tlipcon" created="Wed, 22 Jan 2014 06:36:35 +0000"  >&lt;p&gt;This test has no new patches because it&apos;s just re-implementing an existing code path already covered by tests.&lt;/p&gt;</comment>
                            <comment id="13883409" author="kihwal" created="Mon, 27 Jan 2014 22:06:11 +0000"  >&lt;p&gt;I wondered why commitBlockSynchronization() sometimes takes long and this jira explains why.  When the original lease holders disappear, the lease holders are changed to namenode for block recovery. So if a lot of files get abandoned at around the same time, NN will be that writer with a large number of open files. &lt;/p&gt;

&lt;p&gt;The patch looks good. The paths managed by LeaseManager are supposed to be updated on deletions and renames, so there is no point in searching there when the reference to inode is already known. For all user-initiated calls, the inode is obtained using the user-supplied path and then checkLease() is called before calling findPath(). So if something is to fail in findPath(), it should fail earlier in the code path. The patch seems fine in terms of both consistency and correctness.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13883493" author="tlipcon" created="Mon, 27 Jan 2014 23:04:31 +0000"  >&lt;p&gt;Thanks for the analysis Kihwal. My logic was basically the same - glad to have it confirmed.&lt;/p&gt;

&lt;p&gt;Also, you&apos;re right - I&apos;m pretty sure the &quot;single writer&quot; was NN_Recovery in the production case we saw as well, though it wasn&apos;t easy to verify (we don&apos;t appear to have any way to dump the LeaseManager state at runtime, which is a shame)&lt;/p&gt;

&lt;p&gt;I&apos;ll commit this in a day or two if no one has further comments.&lt;/p&gt;</comment>
                            <comment id="13887078" author="sureshms" created="Thu, 30 Jan 2014 21:27:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tlipcon&quot; class=&quot;user-hover&quot; rel=&quot;tlipcon&quot;&gt;Todd Lipcon&lt;/a&gt;, should this go into 2.3 as well?&lt;/p&gt;</comment>
                            <comment id="13887083" author="hudson" created="Thu, 30 Jan 2014 21:28:45 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5075 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5075/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5075/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5790&quot; title=&quot;LeaseManager.findPath is very slow when many leases need recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5790&quot;&gt;&lt;del&gt;HDFS-5790&lt;/del&gt;&lt;/a&gt;. LeaseManager.findPath is very slow when many leases need recovery. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887110" author="tlipcon" created="Thu, 30 Jan 2014 21:47:20 +0000"  >&lt;p&gt;I was trying to follow the &quot;blockers only&quot; rule for 2.3. This is a bad problem when it happens, but it has been around for many years. So, given there is some risk associated with changing lease management, I figured I&apos;d put it only in branch-2 and not 2.3.0. But, if you think it&apos;s worth it, I&apos;m +0 on cherry-picking.&lt;/p&gt;</comment>
                            <comment id="13887213" author="sureshms" created="Thu, 30 Jan 2014 22:53:00 +0000"  >&lt;p&gt;I know that many of the HDFS restarts with running jobs that have opened many files run into this issue. In the past I had fixed a bug where namenode did editlog sync holding lock. Even with that I see that this issue slows down lease recovery and namenode in such restarts becomes unresponsive. That said, I am okay not putting this into 2.3.&lt;/p&gt;</comment>
                            <comment id="13887648" author="hudson" created="Fri, 31 Jan 2014 11:14:07 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #467 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/467/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5790&quot; title=&quot;LeaseManager.findPath is very slow when many leases need recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5790&quot;&gt;&lt;del&gt;HDFS-5790&lt;/del&gt;&lt;/a&gt;. LeaseManager.findPath is very slow when many leases need recovery. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887732" author="hudson" created="Fri, 31 Jan 2014 13:29:53 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1684 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1684/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5790&quot; title=&quot;LeaseManager.findPath is very slow when many leases need recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5790&quot;&gt;&lt;del&gt;HDFS-5790&lt;/del&gt;&lt;/a&gt;. LeaseManager.findPath is very slow when many leases need recovery. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13887746" author="hudson" created="Fri, 31 Jan 2014 13:39:15 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1659 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1659/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5790&quot; title=&quot;LeaseManager.findPath is very slow when many leases need recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5790&quot;&gt;&lt;del&gt;HDFS-5790&lt;/del&gt;&lt;/a&gt;. LeaseManager.findPath is very slow when many leases need recovery. Contributed by Todd Lipcon. (todd: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1562970&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12615841">HDFS-4183</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624258" name="hdfs-5790.txt" size="3782" author="tlipcon" created="Wed, 22 Jan 2014 02:13:18 +0000"/>
                            <attachment id="12624229" name="hdfs-5790.txt" size="4873" author="tlipcon" created="Tue, 21 Jan 2014 23:47:17 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Jan 2014 01:07:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368320</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368322</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Committed to branch-2 and trunk.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5789] Some of snapshot APIs missing checkOperation double check in fsn</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5789</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-4591&quot; title=&quot;HA clients can fail to fail over while Standby NN is performing long checkpoint&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-4591&quot;&gt;&lt;del&gt;HDFS-4591&lt;/del&gt;&lt;/a&gt; introduced double checked for HA state while taking fsn lock.&lt;br/&gt;
checkoperation made before actually taking lock and after the lock again.&lt;/p&gt;

&lt;p&gt;This pattern missed in some of the snapshot APIs and cache management related APIs.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689332">HDFS-5789</key>
            <summary>Some of snapshot APIs missing checkOperation double check in fsn</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="umamaheswararao">Uma Maheswara Rao G</assignee>
                                    <reporter username="umamaheswararao">Uma Maheswara Rao G</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 19:28:02 +0000</created>
                <updated>Sat, 25 Jan 2014 13:38:05 +0000</updated>
                            <resolved>Thu, 23 Jan 2014 16:42:05 +0000</resolved>
                                    <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13879964" author="umamaheswararao" created="Thu, 23 Jan 2014 14:47:59 +0000"  >&lt;p&gt;Attached a simple patch for review.&lt;/p&gt;</comment>
                            <comment id="13880001" author="szetszwo" created="Thu, 23 Jan 2014 15:51:23 +0000"  >&lt;p&gt;+1 patch looks good.&lt;/p&gt;</comment>
                            <comment id="13880059" author="umamaheswararao" created="Thu, 23 Jan 2014 16:42:06 +0000"  >&lt;p&gt;Thanks a lot, Nicholas for the review!&lt;br/&gt;
I have just committed this to trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13881678" author="hudson" created="Sat, 25 Jan 2014 05:48:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5036 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5036/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5036/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5789&quot; title=&quot;Some of snapshot APIs missing checkOperation double check in fsn&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5789&quot;&gt;&lt;del&gt;HDFS-5789&lt;/del&gt;&lt;/a&gt;. Some of snapshot APIs missing checkOperation double check in fsn. Contributed by Uma Maheswara Rao G. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881839" author="hudson" created="Sat, 25 Jan 2014 12:27:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #461 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5789&quot; title=&quot;Some of snapshot APIs missing checkOperation double check in fsn&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5789&quot;&gt;&lt;del&gt;HDFS-5789&lt;/del&gt;&lt;/a&gt;. Some of snapshot APIs missing checkOperation double check in fsn. Contributed by Uma Maheswara Rao G. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881866" author="hudson" created="Sat, 25 Jan 2014 13:27:42 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1678 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5789&quot; title=&quot;Some of snapshot APIs missing checkOperation double check in fsn&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5789&quot;&gt;&lt;del&gt;HDFS-5789&lt;/del&gt;&lt;/a&gt;. Some of snapshot APIs missing checkOperation double check in fsn. Contributed by Uma Maheswara Rao G. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881884" author="hudson" created="Sat, 25 Jan 2014 13:38:05 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1653 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5789&quot; title=&quot;Some of snapshot APIs missing checkOperation double check in fsn&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5789&quot;&gt;&lt;del&gt;HDFS-5789&lt;/del&gt;&lt;/a&gt;. Some of snapshot APIs missing checkOperation double check in fsn. Contributed by Uma Maheswara Rao G. (umamahesh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560731&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624803" name="HDFS-5789.patch" size="1595" author="umamaheswararao" created="Thu, 23 Jan 2014 14:47:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Jan 2014 15:51:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368304</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368306</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5788] listLocatedStatus response can be very large</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5788</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Currently we limit the size of listStatus requests to a default of 1000 entries. This works fine except in the case of listLocatedStatus where the location information can be quite large. As an example, a directory with 7000 entries, 4 blocks each, 3 way replication - a listLocatedStatus response is over 1MB. This can chew up very large amounts of memory in the NN if lots of clients try to do this simultaneously.&lt;/p&gt;

&lt;p&gt;Seems like it would be better if we also considered the amount of location information being returned when deciding how many files to return.&lt;/p&gt;

&lt;p&gt;Patch will follow shortly.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689266">HDFS-5788</key>
            <summary>listLocatedStatus response can be very large</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nroberts">Nathan Roberts</assignee>
                                    <reporter username="nroberts">Nathan Roberts</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 15:27:20 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:14 +0000</updated>
                            <resolved>Thu, 23 Jan 2014 17:04:35 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>0.23.10</version>
                    <version>2.2.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13873720" author="sureshms" created="Thu, 16 Jan 2014 18:35:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;a listLocatedStatus response is over 1MB&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;These are short lived objects and are garbage collected in young generation. This causes lot of issues?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Seems like it would be better if we also considered the amount of location information being returned when deciding how many files to return.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Can you please add details about the solution?&lt;/p&gt;</comment>
                            <comment id="13873839" author="jlowe" created="Thu, 16 Jan 2014 19:51:25 +0000"  >&lt;p&gt;They are usually short-lived but a bit longer-lived when we can&apos;t push them out the network in a timely manner.  Then due to lack of flow control in the RPC layer we can fill up the heap with these given a large enough average response buffer per call and enough clients.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8942&quot; title=&quot;Thundering herd of RPCs with large responses leads to OOM&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8942&quot;&gt;HADOOP-8942&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This change mitigates the issue for listLocatedStatus since a much smaller response payload means it takes a lot more simultaneous clients to consume an equal amount of heap space.&lt;/p&gt;</comment>
                            <comment id="13874082" author="sureshms" created="Thu, 16 Jan 2014 22:42:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Then due to lack of flow control in the RPC layer we can fill up the heap with these given a large enough average response buffer per call and enough clients.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jlowe&quot; class=&quot;user-hover&quot; rel=&quot;jlowe&quot;&gt;Jason Lowe&lt;/a&gt;, thanks for the pointer.&lt;/p&gt;

&lt;p&gt;We can certainly reduce the number of files returned in each iteration. But it would increase the number of requests to be processed by NameNode though.&lt;/p&gt;</comment>
                            <comment id="13874107" author="nroberts" created="Thu, 16 Jan 2014 22:59:19 +0000"  >&lt;p&gt;A simple solution is:&lt;br/&gt;
Restrict the size to dfs.ls.limit (default 1000) files OR dfs.ls.limit block locations, whichever comes first (obviously always returning only whole entries, so we could send more than this number of locations)&lt;/p&gt;

&lt;p&gt;Yes, it will require more RPCs. However, it would seem to lower the risk of a DoS.  &lt;/p&gt;</comment>
                            <comment id="13878879" author="nroberts" created="Wed, 22 Jan 2014 17:36:17 +0000"  >&lt;p&gt;patch for trunk.&lt;/p&gt;</comment>
                            <comment id="13879225" author="hadoopqa" created="Wed, 22 Jan 2014 21:48:39 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624374/HDFS-5788.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624374/HDFS-5788.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5936//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5936//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5936//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5936//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13880062" author="daryn" created="Thu, 23 Jan 2014 16:45:25 +0000"  >&lt;p&gt;For a bit more context, we had about ~6-7k tasks (erroneously) issuing listLocatedStatus.  Each limited response was over 1M.  The handler attempts a non-blocking write for the response.  If the entire response cannot be written, the call is added to the background responder thread.  The kernel accepts well below 1M for a non-blocking write so all the responses were added to the responder thread.&lt;/p&gt;

&lt;p&gt;The call response byte buffers track the position of the last write, thus the entire response buffer is retained until the full response is sent.  Re-allocating a buffer with the unsent response will likely introduce additional memory pressure, so the most logical/simplistic change is limiting the response size of the located status.&lt;/p&gt;

&lt;p&gt;The end result in our case was the heap bloating by over 8G.  Full GC kicked in.  The NN was unresponsive for up to 5m at a time.  Each time it woke up it marked DNs as dead, causing a flurry of replications which further aggravated the memory issue.  Due to other exposed bugs, the NN required a restart.&lt;/p&gt;

&lt;p&gt;Although more RPCs are required to satisfy the large requests, I believe the tradeoff is reasonable.  It&apos;s also not likely to be a common occurrence.&lt;/p&gt;</comment>
                            <comment id="13880068" author="kihwal" created="Thu, 23 Jan 2014 16:51:38 +0000"  >&lt;p&gt;The location counting can be off if blocks are under-replicated or over-replicated, but spending more cycles to make it perfect will be a waste. So I am okay with this approach.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13880080" author="kihwal" created="Thu, 23 Jan 2014 17:04:35 +0000"  >&lt;p&gt;Thanks for working on the issue, Nathan. I&apos;ve committed it to trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13881679" author="hudson" created="Sat, 25 Jan 2014 05:48:17 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5036 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5036/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5036/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5788&quot; title=&quot;listLocatedStatus response can be very large&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5788&quot;&gt;&lt;del&gt;HDFS-5788&lt;/del&gt;&lt;/a&gt;. listLocatedStatus response can be very large. Contributed by Nathan Roberts. (kihwal: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881840" author="hudson" created="Sat, 25 Jan 2014 12:27:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #461 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/461/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5788&quot; title=&quot;listLocatedStatus response can be very large&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5788&quot;&gt;&lt;del&gt;HDFS-5788&lt;/del&gt;&lt;/a&gt;. listLocatedStatus response can be very large. Contributed by Nathan Roberts. (kihwal: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881867" author="hudson" created="Sat, 25 Jan 2014 13:27:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1678 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1678/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5788&quot; title=&quot;listLocatedStatus response can be very large&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5788&quot;&gt;&lt;del&gt;HDFS-5788&lt;/del&gt;&lt;/a&gt;. listLocatedStatus response can be very large. Contributed by Nathan Roberts. (kihwal: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13881885" author="hudson" created="Sat, 25 Jan 2014 13:38:05 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1653 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1653/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5788&quot; title=&quot;listLocatedStatus response can be very large&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5788&quot;&gt;&lt;del&gt;HDFS-5788&lt;/del&gt;&lt;/a&gt;. listLocatedStatus response can be very large. Contributed by Nathan Roberts. (kihwal: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1560750&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12612479">HADOOP-8942</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12624374" name="HDFS-5788.patch" size="6361" author="nroberts" created="Wed, 22 Jan 2014 17:36:17 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 16 Jan 2014 18:35:32 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368238</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368240</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320356</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5787] client Exception when in safemode does not have cause populated</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5787</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The Exception being thrown on the client side when HDFS is in safemode does not have the cause populated with a SafeModeException. &lt;/p&gt;

&lt;p&gt;It seems the Exception is not populated by calling initCause() when created.&lt;/p&gt;

&lt;p&gt;Because of this &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5724&quot; title=&quot;JobHistoryServer does not start if HDFS is not running&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5724&quot;&gt;&lt;del&gt;MAPREDUCE-5724&lt;/del&gt;&lt;/a&gt; has to grep the toString() of the thrown exception to determine if the issue is that HDFS is in safe mode.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689166">HDFS-5787</key>
            <summary>client Exception when in safemode does not have cause populated</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="tucu00">Alejandro Abdelnur</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 04:23:20 +0000</created>
                <updated>Thu, 16 Jan 2014 04:23:20 +0000</updated>
                                            <version>2.2.0</version>
                                                    <component>hdfs-client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368138</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368140</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5786] Support query and finalize rolling upgrade</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5786</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This is Namenode side implementation for supporting QUERY and FINALIZE actions of rolling upgrade.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689157">HDFS-5786</key>
            <summary>Support query and finalize rolling upgrade</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12680353">HDFS-5535</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="szetszwo">Tsz Wo (Nicholas), SZE</assignee>
                                    <reporter username="szetszwo">Tsz Wo (Nicholas), SZE</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 02:27:08 +0000</created>
                <updated>Sat, 18 Jan 2014 02:07:57 +0000</updated>
                            <resolved>Sat, 18 Jan 2014 02:07:57 +0000</resolved>
                                                    <fixVersion>HDFS-5535 (Rolling upgrades)</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13874847" author="szetszwo" created="Fri, 17 Jan 2014 15:14:39 +0000"  >&lt;p&gt;h5786_20140117.patch: implements QUERY and FINALIZE.&lt;/p&gt;</comment>
                            <comment id="13875276" author="jingzhao" created="Fri, 17 Jan 2014 21:28:10 +0000"  >&lt;p&gt;+1 Patch looks good to me.&lt;/p&gt;</comment>
                            <comment id="13875490" author="szetszwo" created="Sat, 18 Jan 2014 02:07:57 +0000"  >&lt;p&gt;Thanks Jing for reviewing the patch.&lt;/p&gt;

&lt;p&gt;I have committed this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623653" name="h5786_20140117.patch" size="14346" author="szetszwo" created="Fri, 17 Jan 2014 15:14:39 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 17 Jan 2014 21:28:10 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368129</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368131</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5785] Serialize symlink in protobuf</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5785</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This jira proposes to serialize symlink related information in protobuf format.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689154">HDFS-5785</key>
            <summary>Serialize symlink in protobuf</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 02:12:28 +0000</created>
                <updated>Sat, 18 Jan 2014 00:53:24 +0000</updated>
                            <resolved>Sat, 18 Jan 2014 00:53:24 +0000</resolved>
                                    <version>HDFS-5698 (FSImage in protobuf)</version>
                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13875451" author="jingzhao" created="Sat, 18 Jan 2014 00:53:24 +0000"  >&lt;p&gt;+1. I&apos;ve committed this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623294" name="HDFS-5785.000.patch" size="4589" author="wheat9" created="Thu, 16 Jan 2014 02:13:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 18 Jan 2014 00:53:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368126</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368128</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325854</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5784] reserve space in edit log header and fsimage header for feature flag section</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5784</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;We should reserve space in the edit log header and fsimage header so that we can add layout feature flags later in a compatible manner.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689149">HDFS-5784</key>
            <summary>reserve space in edit log header and fsimage header for feature flag section</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12669303">HDFS-5223</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cmccabe">Colin Patrick McCabe</assignee>
                                    <reporter username="cmccabe">Colin Patrick McCabe</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 02:01:14 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:22 +0000</updated>
                            <resolved>Fri, 17 Jan 2014 01:55:34 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13873027" author="hadoopqa" created="Thu, 16 Jan 2014 04:29:58 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623291/HDFS-5784.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623291/HDFS-5784.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.namenode.TestEditLogFileInputStream&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestDFSUpgradeFromImage&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader&lt;br/&gt;
                  org.apache.hadoop.hdfs.qjournal.server.TestJournalNode&lt;br/&gt;
                  org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer&lt;br/&gt;
                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestPersistBlocks&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestFileAppendRestart&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5892//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5892//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5892//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5892//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13873832" author="hadoopqa" created="Thu, 16 Jan 2014 19:43:45 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623450/HDFS-5784.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623450/HDFS-5784.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5902//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5902//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13873933" author="cmccabe" created="Thu, 16 Jan 2014 21:03:21 +0000"  >&lt;p&gt;rebase&lt;/p&gt;</comment>
                            <comment id="13874162" author="hadoopqa" created="Thu, 16 Jan 2014 23:42:00 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623472/HDFS-5784.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623472/HDFS-5784.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 2 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5903//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5903//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5903//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5903//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13874184" author="cmccabe" created="Fri, 17 Jan 2014 00:04:05 +0000"  >&lt;p&gt;The failure in TestOfflineEditsViewer is because jenkins can&apos;t update the binary editsStored file (it can&apos;t yet do binary diffs), and is expected.&lt;/p&gt;</comment>
                            <comment id="13874190" author="andrew.wang" created="Fri, 17 Jan 2014 00:07:55 +0000"  >&lt;p&gt;LGTM, +1&lt;/p&gt;</comment>
                            <comment id="13874307" author="cmccabe" created="Fri, 17 Jan 2014 01:55:05 +0000"  >&lt;p&gt;backport to branch-2 is pending the layout version fix in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5794&quot; title=&quot;Fix the inconsistency of layout version number of ADD_DATANODE_AND_STORAGE_UUIDS between trunk and branch-2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5794&quot;&gt;&lt;del&gt;HDFS-5794&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13874341" author="hudson" created="Fri, 17 Jan 2014 02:29:47 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5015 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5015/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5015/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5784&quot; title=&quot;reserve space in edit log header and fsimage header for feature flag section&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5784&quot;&gt;&lt;del&gt;HDFS-5784&lt;/del&gt;&lt;/a&gt;. Reserve space in edit log header and fsimage header for feature flag section (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutFlags.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13874672" author="hudson" created="Fri, 17 Jan 2014 11:10:44 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #455 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/455/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/455/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5784&quot; title=&quot;reserve space in edit log header and fsimage header for feature flag section&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5784&quot;&gt;&lt;del&gt;HDFS-5784&lt;/del&gt;&lt;/a&gt;. Reserve space in edit log header and fsimage header for feature flag section (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutFlags.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13874769" author="hudson" created="Fri, 17 Jan 2014 13:27:29 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1647 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1647/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1647/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5784&quot; title=&quot;reserve space in edit log header and fsimage header for feature flag section&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5784&quot;&gt;&lt;del&gt;HDFS-5784&lt;/del&gt;&lt;/a&gt;. Reserve space in edit log header and fsimage header for feature flag section (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutFlags.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13874780" author="hudson" created="Fri, 17 Jan 2014 13:28:51 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1672 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1672/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1672/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5784&quot; title=&quot;reserve space in edit log header and fsimage header for feature flag section&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5784&quot;&gt;&lt;del&gt;HDFS-5784&lt;/del&gt;&lt;/a&gt;. Reserve space in edit log header and fsimage header for feature flag section (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558974&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutFlags.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875430" author="cmccabe" created="Sat, 18 Jan 2014 00:19:09 +0000"  >&lt;p&gt;committed to 2.4&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623291" name="HDFS-5784.001.patch" size="7792" author="cmccabe" created="Thu, 16 Jan 2014 02:02:04 +0000"/>
                            <attachment id="12623450" name="HDFS-5784.002.patch" size="12022" author="cmccabe" created="Thu, 16 Jan 2014 19:39:49 +0000"/>
                            <attachment id="12623472" name="HDFS-5784.003.patch" size="11989" author="cmccabe" created="Thu, 16 Jan 2014 21:03:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 16 Jan 2014 04:29:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368121</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368123</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5783] Compute the digest before loading FSImage</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5783</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;When loading the fsimage, the current code computes its MD5 digest on-the-fly. It does not work when the code does not read all the sections in strictly sequential order.&lt;/p&gt;

&lt;p&gt;This jira proposes to compute the MD5 digest before loading fsimage.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689139">HDFS-5783</key>
            <summary>Compute the digest before loading FSImage</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jan 2014 00:46:53 +0000</created>
                <updated>Sat, 18 Jan 2014 00:48:33 +0000</updated>
                            <resolved>Sat, 18 Jan 2014 00:48:33 +0000</resolved>
                                    <version>HDFS-5698 (FSImage in protobuf)</version>
                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13872890" author="wheat9" created="Thu, 16 Jan 2014 00:53:17 +0000"  >&lt;p&gt;A preliminary experiment shows that there is little impact of loading time. I load a 512M fsimage on my laptop, here is the number:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Loading the FSImage, computing the digest with &lt;tt&gt;DigestInputStream&lt;/tt&gt;: 9920ms&lt;/li&gt;
	&lt;li&gt;Loading the FSImage, without computing the digest: 7467ms&lt;/li&gt;
	&lt;li&gt;Calculating MD5 independently: 1231ms&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The reason why (2) + (3) is slightly faster than (1) is because currently we cannot consume all I/O bandwidth when loading fsimage.&lt;/p&gt;</comment>
                            <comment id="13875435" author="jingzhao" created="Sat, 18 Jan 2014 00:32:21 +0000"  >&lt;p&gt;One quick comment: we need to shutdown the minidfscluster at the end of the unit test.&lt;/p&gt;</comment>
                            <comment id="13875438" author="wheat9" created="Sat, 18 Jan 2014 00:34:43 +0000"  >&lt;p&gt;Thanks Jing for the review. The v1 patch addresses Jing&apos;s comment.&lt;/p&gt;</comment>
                            <comment id="13875443" author="jingzhao" created="Sat, 18 Jan 2014 00:45:01 +0000"  >&lt;p&gt;The 001 patch looks good to me. +1&lt;/p&gt;

&lt;p&gt;Nit: we should add &quot;if (cluster != null)&quot; before we shutdown the cluster, and some unused imports can be removed. Since this is trivial, I just made this change and upload the 002 patch.&lt;/p&gt;</comment>
                            <comment id="13875444" author="jingzhao" created="Sat, 18 Jan 2014 00:48:33 +0000"  >&lt;p&gt;I&apos;ve committed this .&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623278" name="HDFS-5783.000.patch" size="17092" author="wheat9" created="Thu, 16 Jan 2014 01:04:34 +0000"/>
                            <attachment id="12623757" name="HDFS-5783.001.patch" size="19607" author="wheat9" created="Sat, 18 Jan 2014 00:34:43 +0000"/>
                            <attachment id="12623758" name="HDFS-5783.002.patch" size="19386" author="jingzhao" created="Sat, 18 Jan 2014 00:45:01 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 18 Jan 2014 00:32:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368111</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368113</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325854</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5782] BlockListAsLongs should take lists of Replicas rather than concrete classes</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5782</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;From &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5194&quot; title=&quot;Robust support for alternate FsDatasetSpi implementations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5194&quot;&gt;HDFS-5194&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;BlockListAsLongs&apos;s constructor takes a list of Blocks and a list of ReplicaInfos.  On the surface, the former is mildly irritating because it is a concrete class, while the latter is a greater concern due to being a File-based implementation of Replica.&lt;/p&gt;

&lt;p&gt;On deeper inspection, BlockListAsLongs passes members of both to an internal method that accepts just Blocks, which conditionally casts them &lt;b&gt;back&lt;/b&gt; to ReplicaInfos (this cast only happens to the latter, though this isn&apos;t immediately obvious to the reader).&lt;/p&gt;

&lt;p&gt;Conveniently, all methods called on these objects are found in the Replica interface, and all functional (i.e. non-test) consumers of this interface pass in Replica subclasses.  If this constructor took Lists of Replicas instead, it would be more generally useful and its implementation would be cleaner as well.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fixing this indeed makes the business end of BlockListAsLongs cleaner while requiring no changes to FsDatasetImpl.  As suggested by the above description, though, the HDFS tests use BlockListAsLongs differently from the production code &amp;#8211; they pretty much universally provide a list of actual Blocks.  To handle this:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In the case of SimulatedFSDataset, providing a list of Replicas is actually less work.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In the case of NNThroughputBenchmark, rewriting to use Replicas is fairly invasive.  Instead, the patch creates a second constructor in BlockListOfLongs specifically for the use of NNThrougputBenchmark.  It turns the stomach a little, but is clearer and requires less code than the alternatives (and isn&apos;t without precedent).&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12689095">HDFS-5782</key>
            <summary>BlockListAsLongs should take lists of Replicas rather than concrete classes</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12668366">HDFS-5194</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="dep">David Powell</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 21:30:13 +0000</created>
                <updated>Thu, 16 Jan 2014 00:41:34 +0000</updated>
                                            <version>3.0.0</version>
                                                    <component>datanode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13872880" author="hadoopqa" created="Thu, 16 Jan 2014 00:41:34 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623235/HDFS-5782.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623235/HDFS-5782.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 2 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5889//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5889//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5889//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5889//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623235" name="HDFS-5782.patch" size="5679" author="dep" created="Wed, 15 Jan 2014 21:31:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 16 Jan 2014 00:41:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368067</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368069</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320356</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5781] Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5781</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5674&quot; title=&quot;Editlog code cleanup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5674&quot;&gt;&lt;del&gt;HDFS-5674&lt;/del&gt;&lt;/a&gt; uses Enum.values and enum.ordinal to identify an editlog op for a given byte value. While improving the efficiency, it may cause issue. E.g., when several new editlog ops are added to trunk around the same time (for several different new features), it is hard to backport the editlog ops with larger byte values to branch-2 before those with smaller values, since there will be gaps in the byte values of the enum. &lt;/p&gt;

&lt;p&gt;This jira plans to still use an array to record the mapping between editlog ops and their byte values, and allow gap between valid ops. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12689073">HDFS-5781</key>
            <summary>Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="jingzhao">Jing Zhao</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 19:43:38 +0000</created>
                <updated>Wed, 29 Jan 2014 22:52:38 +0000</updated>
                            <resolved>Mon, 27 Jan 2014 19:05:35 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13872696" author="hadoopqa" created="Wed, 15 Jan 2014 22:26:09 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623205/HDFS-5781.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623205/HDFS-5781.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5886//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5886//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5886//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5886//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13876795" author="cmccabe" created="Mon, 20 Jan 2014 19:50:50 +0000"  >&lt;p&gt;I agree that using &lt;tt&gt;Enum#values&lt;/tt&gt; directly is not the right thing here.  It might make backports difficult, as you commented.&lt;/p&gt;

&lt;p&gt;How about just using an array that might contain some nulls?  A hash map looks like overkill because there aren&apos;t that many entries, and they key numbers are all close together.&lt;/p&gt;</comment>
                            <comment id="13876810" author="jingzhao" created="Mon, 20 Jan 2014 20:05:42 +0000"  >&lt;p&gt;Thanks for the comment Colin! The current patch simply uses the original implementation. I agree a hashmap may be overkill here. I will upload a new patch which uses an array instead.&lt;/p&gt;</comment>
                            <comment id="13877891" author="jingzhao" created="Tue, 21 Jan 2014 21:44:17 +0000"  >&lt;p&gt;Update the patch. The original TestFSEditLogLoader#testFSEditLogOpCodes can also cover this change.&lt;/p&gt;</comment>
                            <comment id="13878050" author="hadoopqa" created="Wed, 22 Jan 2014 00:06:27 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624192/HDFS-5781.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624192/HDFS-5781.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5927//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5927//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5927//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5927//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13878211" author="cmccabe" created="Wed, 22 Jan 2014 03:34:45 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; FSEditLogOpCodes[] VALUES = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FSEditLogOpCodes[256];
+  
+  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; {
+    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (FSEditLogOpCodes code : FSEditLogOpCodes.values()) {
+      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; codeValue = code.getOpCode() &amp;amp; 0xff;
+      VALUES[codeValue] = code;
+    }
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Sorry to nitpick, but it might be better to do a first pass through values() to determine how big the array should be.  That way we wouldn&apos;t have to use 256 all the time.&lt;/p&gt;

&lt;p&gt;+1 once this is addressed.&lt;/p&gt;</comment>
                            <comment id="13879285" author="jingzhao" created="Wed, 22 Jan 2014 22:35:18 +0000"  >&lt;p&gt;Thanks to Colin for the review. So 002 patch goes through the enum and determine the size based on the largest value. This will also limit the range of valid op code to 0~127.&lt;/p&gt;</comment>
                            <comment id="13879327" author="cmccabe" created="Wed, 22 Jan 2014 23:10:46 +0000"  >&lt;p&gt;+1.  Thanks, Jing.&lt;/p&gt;</comment>
                            <comment id="13880173" author="jingzhao" created="Thu, 23 Jan 2014 18:17:49 +0000"  >&lt;p&gt;Resubmit the patch to trigger Jenkins.&lt;/p&gt;</comment>
                            <comment id="13883060" author="jingzhao" created="Mon, 27 Jan 2014 18:29:48 +0000"  >&lt;p&gt;The Jenkins result (&lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5937):&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5937):&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624453/HDFS-5781.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624453/HDFS-5781.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;br/&gt;
    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5937//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5937//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5937//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5937//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;I will commit the patch shortly.&lt;/p&gt;</comment>
                            <comment id="13883105" author="daryn" created="Mon, 27 Jan 2014 18:51:31 +0000"  >&lt;p&gt;In general static block initializers are frowned upon - I&apos;ve been dinged for them in the past.  If they ever throw an exception it causes the jvm to misreport the exception in very bizarre ways.&lt;/p&gt;</comment>
                            <comment id="13883122" author="jingzhao" created="Mon, 27 Jan 2014 19:05:35 +0000"  >&lt;p&gt;Thanks for the review, Colin! I&apos;ve committed this to trunk and branch-2.&lt;/p&gt;</comment>
                            <comment id="13883124" author="hudson" created="Mon, 27 Jan 2014 19:06:33 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5044 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5044/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5044/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5781&quot; title=&quot;Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5781&quot;&gt;&lt;del&gt;HDFS-5781&lt;/del&gt;&lt;/a&gt;. Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13883131" author="jingzhao" created="Mon, 27 Jan 2014 19:10:27 +0000"  >&lt;p&gt;Thanks for the comment Daryn. In general, this patch just changes back to the original behavior, which also uses the static block initializer. I agree it will be a pain to debug static block initializers, that&apos;s why in my 001 patch I try to make the initializer simpler. I think we can create a separate jira to see if we can avoid using it.&lt;/p&gt;</comment>
                            <comment id="13883263" author="hadoopqa" created="Mon, 27 Jan 2014 20:44:37 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624851/HDFS-5781.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624851/HDFS-5781.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5950//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5950//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5950//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5950//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883443" author="cmccabe" created="Mon, 27 Jan 2014 22:30:10 +0000"  >&lt;p&gt;Yeah, perhaps we could have a separate JIRA to use a static function rather than a static block.&lt;/p&gt;</comment>
                            <comment id="13884011" author="hudson" created="Tue, 28 Jan 2014 11:09:03 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #464 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/464/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5781&quot; title=&quot;Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5781&quot;&gt;&lt;del&gt;HDFS-5781&lt;/del&gt;&lt;/a&gt;. Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884117" author="hudson" created="Tue, 28 Jan 2014 13:29:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1681 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1681/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5781&quot; title=&quot;Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5781&quot;&gt;&lt;del&gt;HDFS-5781&lt;/del&gt;&lt;/a&gt;. Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13884134" author="hudson" created="Tue, 28 Jan 2014 13:40:16 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1656 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1656/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5781&quot; title=&quot;Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5781&quot;&gt;&lt;del&gt;HDFS-5781&lt;/del&gt;&lt;/a&gt;. Use an array to record the mapping between FSEditLogOpCode and the corresponding byte value. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1561788&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13885947" author="andrew.wang" created="Wed, 29 Jan 2014 22:52:38 +0000"  >&lt;p&gt;JIRA fix versions are weird right now, I think this is only in branch-2 and not also branch-2.3. I think this is minor enough that it&apos;s okay to leave it out, but please merge it to branch-2.3 and update the fix version if you feel otherwise.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12685165">HDFS-5674</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12623205" name="HDFS-5781.000.patch" size="4108" author="jingzhao" created="Wed, 15 Jan 2014 19:52:19 +0000"/>
                            <attachment id="12624192" name="HDFS-5781.001.patch" size="1309" author="jingzhao" created="Tue, 21 Jan 2014 21:44:17 +0000"/>
                            <attachment id="12624851" name="HDFS-5781.002.patch" size="1900" author="jingzhao" created="Thu, 23 Jan 2014 18:17:49 +0000"/>
                            <attachment id="12624453" name="HDFS-5781.002.patch" size="1900" author="jingzhao" created="Wed, 22 Jan 2014 22:35:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 Jan 2014 22:26:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368045</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368047</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5780] TestRBWBlockInvalidation times out intemittently on branch-2</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5780</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;i recently found out that the test TestRBWBlockInvalidation#testBlockInvalidationWhenRBWReplicaMissedInDN times out intermittently.&lt;/p&gt;

&lt;p&gt;I am using Fedora, JDK7&lt;/p&gt;</description>
                <environment></environment>
        <key id="12689072">HDFS-5780</key>
            <summary>TestRBWBlockInvalidation times out intemittently on branch-2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="mitdesai">Mit Desai</assignee>
                                    <reporter username="mitdesai">Mit Desai</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 19:30:20 +0000</created>
                <updated>Tue, 28 Jan 2014 21:51:17 +0000</updated>
                                            <version>2.2.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368044</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>368046</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5779] Caused by: javax.security.auth.login.LoginException: java.lang.NullPointerException: invalid null input: name</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5779</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;xxxxxx@testhost:/home/xxxxxx/Lab/hdfs/namenodep$ hadoop namenode -format&lt;br/&gt;
Warning: $HADOOP_HOME is deprecated.&lt;/p&gt;

&lt;p&gt;14/01/15 04:51:38 INFO namenode.NameNode: STARTUP_MSG:&lt;br/&gt;
/************************************************************&lt;br/&gt;
STARTUP_MSG: Starting NameNode&lt;br/&gt;
STARTUP_MSG:   host = testhost.testhost1.net/xx.xxx.xxx.xxx&lt;br/&gt;
STARTUP_MSG:   args = &lt;span class=&quot;error&quot;&gt;&amp;#91;-format&amp;#93;&lt;/span&gt;&lt;br/&gt;
STARTUP_MSG:   version = 1.0.3&lt;br/&gt;
STARTUP_MSG:   build = &lt;a href=&quot;https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.0&lt;/a&gt; -r 1335192; compiled by &apos;hortonfo&apos; on Tue May  8 20:31:25 UTC 2012&lt;br/&gt;
************************************************************/&lt;br/&gt;
Re-format filesystem in /home/xxxxxx/Lab/hdfs/namenodep ? (Y or N) Y&lt;br/&gt;
14/01/15 04:51:40 INFO util.GSet: VM type       = 32-bit&lt;br/&gt;
14/01/15 04:51:40 INFO util.GSet: 2% max memory = 19.33375 MB&lt;br/&gt;
14/01/15 04:51:40 INFO util.GSet: capacity      = 2^22 = 4194304 entries&lt;br/&gt;
14/01/15 04:51:40 INFO util.GSet: recommended=4194304, actual=4194304&lt;br/&gt;
14/01/15 04:51:40 ERROR namenode.NameNode: java.io.IOException: failure to login&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:490)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:452)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setConfigurationParameters(FSNamesystem.java:475)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.&amp;lt;init&amp;gt;(FSNamesystem.java:464)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1162)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1271)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)&lt;br/&gt;
Caused by: javax.security.auth.login.LoginException: java.lang.NullPointerException: invalid null input: name&lt;br/&gt;
        at com.sun.security.auth.UnixPrincipal.&amp;lt;init&amp;gt;(Unknown Source)&lt;br/&gt;
        at com.sun.security.auth.module.UnixLoginModule.login(Unknown Source)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext.invoke(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext.access$000(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext$5.run(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext$5.run(Unknown Source)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.login.LoginContext.invokeCreatorPriv(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext.login(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:471)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:452)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setConfigurationParameters(FSNamesystem.java:475)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.&amp;lt;init&amp;gt;(FSNamesystem.java:464)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1162)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1271)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1288)&lt;/p&gt;

&lt;p&gt;        at javax.security.auth.login.LoginContext.invoke(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext.access$000(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext$5.run(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext$5.run(Unknown Source)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.login.LoginContext.invokeCreatorPriv(Unknown Source)&lt;br/&gt;
        at javax.security.auth.login.LoginContext.login(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:471)&lt;br/&gt;
        ... 6 more&lt;/p&gt;

&lt;p&gt;14/01/15 04:51:40 INFO namenode.NameNode: SHUTDOWN_MSG:&lt;br/&gt;
/************************************************************&lt;br/&gt;
SHUTDOWN_MSG: Shutting down NameNode at testhost.testhost1.net/10.129.254.129&lt;br/&gt;
************************************************************/&lt;/p&gt;</description>
                <environment>&lt;p&gt;Linux  2.6.32-220.13.1.el6.x86_64 #1 SMP Thu Mar 29 11:46:40 EDT 2012 x86_64 x86_64 x86_64 GNU/Linux&lt;/p&gt;

&lt;p&gt;This machine is KEONIZED ie., KEON BoKS security is implemented for this box&lt;/p&gt;</environment>
        <key id="12688982">HDFS-5779</key>
            <summary>Caused by: javax.security.auth.login.LoginException: java.lang.NullPointerException: invalid null input: name</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="vijay.lingagiri@gmail.com">Vijay</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 10:48:57 +0000</created>
                <updated>Wed, 15 Jan 2014 20:40:29 +0000</updated>
                            <resolved>Wed, 15 Jan 2014 14:17:09 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13871917" author="vijay.lingagiri@gmail.com" created="Wed, 15 Jan 2014 10:51:29 +0000"  >&lt;p&gt;As per this, I feel the login user Id is not getting picked .. Kindly help &lt;br/&gt;
&lt;a href=&quot;https://svn.apache.org/repos/asf/hadoop/common/branches/HADOOP-6685/src/java/org/apache/hadoop/security/UserGroupInformation.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://svn.apache.org/repos/asf/hadoop/common/branches/HADOOP-6685/src/java/org/apache/hadoop/security/UserGroupInformation.java&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13872105" author="stevel@apache.org" created="Wed, 15 Jan 2014 14:17:09 +0000"  >&lt;p&gt;A configuration problem, not a bug in hadoop, Closing as invalid. Sorry&lt;/p&gt;

&lt;p&gt;see: &lt;a href=&quot;https://wiki.apache.org/hadoop/InvalidJiraIssues&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://wiki.apache.org/hadoop/InvalidJiraIssues&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13872129" author="vijay.lingagiri@gmail.com" created="Wed, 15 Jan 2014 14:37:34 +0000"  >&lt;p&gt;Hi Steve,&lt;/p&gt;

&lt;p&gt;Can you suggest any workaround for my problem.&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Vijay&lt;/p&gt;

</comment>
                            <comment id="13872568" author="stevel@apache.org" created="Wed, 15 Jan 2014 20:40:29 +0000"  >&lt;p&gt;no. Follow the link for suggestions on how to go about addressing problems like that, the key one being: not via JIRA&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 Jan 2014 14:17:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367954</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367956</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5778] Document new commands and parameters for improved rolling upgrades</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5778</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&quot;hdfs dfsadmin -rollingUpgrade&quot; command was newly added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5752&quot; title=&quot;Add a new DFSAdminCommand for rolling upgrade&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5752&quot;&gt;&lt;del&gt;HDFS-5752&lt;/del&gt;&lt;/a&gt;, and some other commands and parameters will be added in the future. This issue exists to flag undocumented commands and parameters when &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5535&quot; title=&quot;Umbrella jira for improved HDFS rolling upgrades&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5535&quot;&gt;HDFS-5535&lt;/a&gt; branch is merging to trunk.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688961">HDFS-5778</key>
            <summary>Document new commands and parameters for improved rolling upgrades</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12680353">HDFS-5535</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ajisakaa">Akira AJISAKA</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 08:23:27 +0000</created>
                <updated>Mon, 27 Jan 2014 07:39:40 +0000</updated>
                                            <version>HDFS-5535 (Rolling upgrades)</version>
                                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13872357" author="sureshms" created="Wed, 15 Jan 2014 18:17:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajisakaa&quot; class=&quot;user-hover&quot; rel=&quot;ajisakaa&quot;&gt;Akira AJISAKA&lt;/a&gt;, this an many other commands will be added and documented during the development of this feature. This feature is still being developed in a feature branch. So please flag these, if they are not done, during merge to trunk. Creating these jiras during feature development will only serve as distraction and may not align with the plan the developers working on a feature branch may have.&lt;/p&gt;</comment>
                            <comment id="13872935" author="ajisakaa" created="Thu, 16 Jan 2014 01:40:46 +0000"  >&lt;p&gt;Thanks! I understand a feature branch documentation should be done during merge to trunk, not before.&lt;/p&gt;</comment>
                            <comment id="13876134" author="szetszwo" created="Mon, 20 Jan 2014 04:40:19 +0000"  >&lt;p&gt;Akira, thanks for filing this JIRA.  We should also document the the new NN startup option added by &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5753&quot; title=&quot;Add new NN startup options for downgrade and rollback using upgrade marker &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5753&quot;&gt;&lt;del&gt;HDFS-5753&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13882619" author="szetszwo" created="Mon, 27 Jan 2014 07:39:40 +0000"  >&lt;p&gt;Also &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5835&quot; title=&quot;Add a new option for starting standby NN when rolling upgrade is in progress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5835&quot;&gt;&lt;del&gt;HDFS-5835&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12688191">HDFS-5752</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12688192">HDFS-5753</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12691323">HDFS-5835</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 Jan 2014 18:17:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367933</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367935</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5777] Update LayoutVersion for the new editlog op OP_ADD_BLOCK</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5777</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5704&quot; title=&quot;Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5704&quot;&gt;&lt;del&gt;HDFS-5704&lt;/del&gt;&lt;/a&gt; adds a new editlog op OP_ADD_BLOCK. We need to update the LayoutVersion for this.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688948">HDFS-5777</key>
            <summary>Update LayoutVersion for the new editlog op OP_ADD_BLOCK</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="jingzhao">Jing Zhao</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 06:24:00 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:07 +0000</updated>
                            <resolved>Thu, 16 Jan 2014 02:28:39 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13871746" author="jingzhao" created="Wed, 15 Jan 2014 07:09:02 +0000"  >&lt;p&gt;Patch uploaded.&lt;/p&gt;</comment>
                            <comment id="13871895" author="hadoopqa" created="Wed, 15 Jan 2014 10:13:06 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623074/HDFS-5777.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623074/HDFS-5777.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated -14 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;        &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode&lt;br/&gt;
                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer&lt;br/&gt;
                  org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5880//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5880//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5880//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5880//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5880//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5880//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13872058" author="szetszwo" created="Wed, 15 Jan 2014 13:29:30 +0000"  >&lt;p&gt;Need to fix editsStored files for TestOfflineEditsViewer.  The other failed tests probably are not related.&lt;/p&gt;</comment>
                            <comment id="13872331" author="sureshms" created="Wed, 15 Jan 2014 17:59:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt;, alternatively we can move the LayoutVersion for this change to -48 and move other features down. Given the CACHING and ADD_DATANODE_AND_STORAGE_UUIDS are not release yet in Apache, this should not be an issue.&lt;/p&gt;</comment>
                            <comment id="13872472" author="jingzhao" created="Wed, 15 Jan 2014 19:26:19 +0000"  >&lt;p&gt;Thanks for the review Nicholas and Suresh! Update the patch to address your comments, i.e., the new patch moves the LayoutVersion for this change to -48 and move other features down.&lt;/p&gt;</comment>
                            <comment id="13872675" author="hadoopqa" created="Wed, 15 Jan 2014 22:11:34 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623199/HDFS-5777.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623199/HDFS-5777.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5883//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5883//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5883//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5883//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13872770" author="szetszwo" created="Wed, 15 Jan 2014 23:13:34 +0000"  >&lt;p&gt;&amp;gt; ... we can move the LayoutVersion for this change to -48 and move other features down. ...&lt;/p&gt;

&lt;p&gt;How about we also renumber the edit log op codes in the same way?&lt;/p&gt;</comment>
                            <comment id="13872794" author="jingzhao" created="Wed, 15 Jan 2014 23:28:54 +0000"  >&lt;p&gt;Update the patch to address Nicholas&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="13872798" author="szetszwo" created="Wed, 15 Jan 2014 23:32:49 +0000"  >&lt;p&gt;+1 patch looks good.  Thanks a lot, Jing!&lt;/p&gt;</comment>
                            <comment id="13872969" author="hadoopqa" created="Thu, 16 Jan 2014 02:12:53 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623257/HDFS-5777.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623257/HDFS-5777.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5890//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5890//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5890//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5890//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13872978" author="jingzhao" created="Thu, 16 Jan 2014 02:28:39 +0000"  >&lt;p&gt;Thanks for the review Nicholas! I&apos;ve committed this to trunk.&lt;/p&gt;</comment>
                            <comment id="13872980" author="jingzhao" created="Thu, 16 Jan 2014 02:29:35 +0000"  >&lt;p&gt;I will later upload a patch for backporting &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5704&quot; title=&quot;Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5704&quot;&gt;&lt;del&gt;HDFS-5704&lt;/del&gt;&lt;/a&gt; to branch-2.&lt;/p&gt;</comment>
                            <comment id="13872988" author="hudson" created="Thu, 16 Jan 2014 02:42:46 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5008 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5008/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5008/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt;. Update LayoutVersion for the new editlog op OP_ADD_BLOCK. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873067" author="jingzhao" created="Thu, 16 Jan 2014 05:54:36 +0000"  >&lt;p&gt;Upload the backported patch and the editStored binary file.&lt;/p&gt;</comment>
                            <comment id="13873278" author="hudson" created="Thu, 16 Jan 2014 11:10:20 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #454 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/454/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/454/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt;. Update LayoutVersion for the new editlog op OP_ADD_BLOCK. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873368" author="hudson" created="Thu, 16 Jan 2014 13:27:07 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1671 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1671/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1671/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt;. Update LayoutVersion for the new editlog op OP_ADD_BLOCK. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873390" author="hudson" created="Thu, 16 Jan 2014 13:41:37 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1646 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1646/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1646/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt;. Update LayoutVersion for the new editlog op OP_ADD_BLOCK. Contributed by Jing Zhao. (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558675&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/LayoutVersion.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875065" author="hudson" created="Fri, 17 Jan 2014 18:35:09 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5019 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5019/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5019/&lt;/a&gt;)&lt;br/&gt;
Move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5704&quot; title=&quot;Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5704&quot;&gt;&lt;del&gt;HDFS-5704&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt; to the correct section in CHANGES.txt (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875087" author="jingzhao" created="Fri, 17 Jan 2014 18:50:46 +0000"  >&lt;p&gt;Update the backporting patch.&lt;/p&gt;</comment>
                            <comment id="13875114" author="jingzhao" created="Fri, 17 Jan 2014 19:08:47 +0000"  >&lt;p&gt;I&apos;ve committed the merged patch to branch-2.&lt;/p&gt;</comment>
                            <comment id="13875619" author="hudson" created="Sat, 18 Jan 2014 11:08:48 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #456 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/456/&lt;/a&gt;)&lt;br/&gt;
Move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5704&quot; title=&quot;Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5704&quot;&gt;&lt;del&gt;HDFS-5704&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt; to the correct section in CHANGES.txt (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875647" author="hudson" created="Sat, 18 Jan 2014 13:26:07 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1648 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1648/&lt;/a&gt;)&lt;br/&gt;
Move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5704&quot; title=&quot;Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5704&quot;&gt;&lt;del&gt;HDFS-5704&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt; to the correct section in CHANGES.txt (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13875655" author="hudson" created="Sat, 18 Jan 2014 13:27:06 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1673 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1673/&lt;/a&gt;)&lt;br/&gt;
Move &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5704&quot; title=&quot;Change OP_UPDATE_BLOCKS  with a new OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5704&quot;&gt;&lt;del&gt;HDFS-5704&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5777&quot; title=&quot;Update LayoutVersion for the new editlog op OP_ADD_BLOCK&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5777&quot;&gt;&lt;del&gt;HDFS-5777&lt;/del&gt;&lt;/a&gt; to the correct section in CHANGES.txt (jing9: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1559210&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12686660">HDFS-5704</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12623706" name="HDFS-5704-5777-branch2.001.patch" size="45306" author="jingzhao" created="Fri, 17 Jan 2014 18:50:46 +0000"/>
                            <attachment id="12623317" name="HDFS-5704-5777-branch2.patch" size="45794" author="jingzhao" created="Thu, 16 Jan 2014 05:54:36 +0000"/>
                            <attachment id="12623074" name="HDFS-5777.000.patch" size="1988" author="jingzhao" created="Wed, 15 Jan 2014 07:09:02 +0000"/>
                            <attachment id="12623199" name="HDFS-5777.001.patch" size="17898" author="jingzhao" created="Wed, 15 Jan 2014 19:26:19 +0000"/>
                            <attachment id="12623257" name="HDFS-5777.002.patch" size="19636" author="jingzhao" created="Wed, 15 Jan 2014 23:28:54 +0000"/>
                            <attachment id="12623707" name="editsStored" size="3939" author="jingzhao" created="Fri, 17 Jan 2014 18:50:46 +0000"/>
                            <attachment id="12623318" name="editsStored" size="3946" author="jingzhao" created="Thu, 16 Jan 2014 05:54:36 +0000"/>
                            <attachment id="12623256" name="editsStored" size="4268" author="jingzhao" created="Wed, 15 Jan 2014 23:28:54 +0000"/>
                            <attachment id="12623198" name="editsStored" size="4275" author="jingzhao" created="Wed, 15 Jan 2014 19:26:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 Jan 2014 10:13:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367920</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367922</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5776] Support &apos;hedged&apos; reads in DFSClient</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5776</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This is a placeholder of hdfs related stuff backport from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7509&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-7509&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The quorum read ability should be helpful especially to optimize read outliers&lt;/p&gt;

&lt;p&gt;we can utilize &quot;dfs.dfsclient.quorum.read.threshold.millis&quot; &amp;amp; &quot;dfs.dfsclient.quorum.read.threadpool.size&quot; to enable/disable the hedged read ability from client side(e.g. HBase), and by using DFSQuorumReadMetrics, we could export the interested metric valus into client system(e.g. HBase&apos;s regionserver metric).&lt;/p&gt;

&lt;p&gt;The core logic is in pread code path, we decide to goto the original fetchBlockByteRange or the new introduced fetchBlockByteRangeSpeculative per the above config items.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688930">HDFS-5776</key>
            <summary>Support &apos;hedged&apos; reads in DFSClient</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png">Patch Available</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="xieliang007">Liang Xie</assignee>
                                    <reporter username="xieliang007">Liang Xie</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 03:39:50 +0000</created>
                <updated>Fri, 31 Jan 2014 01:01:19 +0000</updated>
                                            <version>3.0.0</version>
                                                    <component>hdfs-client</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>20</watches>
                                                                <comments>
                            <comment id="13871604" author="xieliang007" created="Wed, 15 Jan 2014 03:42:04 +0000"  >&lt;p&gt;I have made a raw patch against 2.0 branch yesterday, will upload the patch once testing done.&lt;/p&gt;</comment>
                            <comment id="13871654" author="sureshms" created="Wed, 15 Jan 2014 05:11:17 +0000"  >&lt;p&gt;Is this really quorum read or just reading in parallel? Can you please add more details to the description?&lt;/p&gt;</comment>
                            <comment id="13871660" author="stack" created="Wed, 15 Jan 2014 05:24:27 +0000"  >&lt;p&gt;Good on you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;  Is it // read or start up read on second replica if first is slow?  Thanks for working on this.&lt;/p&gt;</comment>
                            <comment id="13871670" author="xieliang007" created="Wed, 15 Jan 2014 05:35:31 +0000"  >&lt;p&gt;thanks for comments, probably &quot;quorum read&quot; is not accurate, just copy from fb-20 &amp;amp; 0.89-fb branches&apos; naming.&lt;br/&gt;
The core logic is in pread op, send a callable read request against dn1, if no response until a timeout reach, then chooseDN will pick another DN to send the similar read request.&lt;/p&gt;

&lt;p&gt;This idea is similar with Jeff Dean&apos;s : &amp;lt;The tail at scale-dean&amp;gt;, in that article, Jeff named a &quot;Hedged requests&quot;, and a clever defer sending request optimization to limit the additional load.&lt;/p&gt;</comment>
                            <comment id="13871671" author="xieliang007" created="Wed, 15 Jan 2014 05:37:34 +0000"  >&lt;p&gt;Please feel free to modify this JIRA&apos;s title and description, i&apos;m not a native speaker, probably not good at the detailed semantics&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13872402" author="stack" created="Wed, 15 Jan 2014 18:40:49 +0000"  >&lt;p&gt;I  had a go at the subject for you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;  I am a native speaker but when others read my writing or hear me talk, they wonder.&lt;/p&gt;</comment>
                            <comment id="13873131" author="xieliang007" created="Thu, 16 Jan 2014 07:52:28 +0000"  >&lt;p&gt;let&apos;s see what QA robot will say&lt;/p&gt;</comment>
                            <comment id="13873136" author="xieliang007" created="Thu, 16 Jan 2014 07:58:07 +0000"  >&lt;p&gt;&quot;mvn clean test -Dtest=TestPread&quot; passed locally&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13873239" author="hadoopqa" created="Thu, 16 Jan 2014 10:38:16 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623328/HDFS-5776.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623328/HDFS-5776.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;      &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 1546 javac compiler warnings (more than the trunk&apos;s current 1545 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5897//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5897//testReport/&lt;/a&gt;&lt;br/&gt;
Javac warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5897//artifact/trunk/patchprocess/diffJavacWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5897//artifact/trunk/patchprocess/diffJavacWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5897//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5897//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13874538" author="xieliang007" created="Fri, 17 Jan 2014 07:41:49 +0000"  >&lt;p&gt;v2 should address the javadoc and failed case&lt;/p&gt;</comment>
                            <comment id="13874620" author="hadoopqa" created="Fri, 17 Jan 2014 10:15:12 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623601/HDFS-5776-v2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623601/HDFS-5776-v2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5910//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5910//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5910//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5910//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13874818" author="xieliang007" created="Fri, 17 Jan 2014 14:15:07 +0000"  >&lt;p&gt;all are green now, nice&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13875161" author="stack" created="Fri, 17 Jan 2014 19:32:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Nit: The &apos;return null&apos; necessary in below given it Void return type:&lt;/p&gt;

&lt;p&gt;+      public Void call() throws IOException &lt;/p&gt;
{
+        pReadFile(fileSys, file);
+        return null;
+      }

&lt;p&gt;We should rename these methods given this is not &apos;quorum&apos; reading:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
testQuorumPreadDFSBasic
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... and here testMaxOutQuorumPool&lt;/p&gt;

&lt;p&gt;And this variable name needs changing? numQuorumPoolThreads... and here DFS_DFSCLIENT_QUORUM_READ_THREADPOOL_SIZE&lt;/p&gt;

&lt;p&gt;... more review to come (have to head out)&lt;/p&gt;</comment>
                            <comment id="13875453" author="stack" created="Sat, 18 Jan 2014 00:57:18 +0000"  >&lt;p&gt;This looks like copy paste issue:&lt;/p&gt;

&lt;p&gt;+      // assert that there were no quorum reads. 60ms + delta &amp;lt; 100ms&lt;br/&gt;
+      assertTrue(metrics.getParallelReadOps() &amp;gt; 0);&lt;/p&gt;

&lt;p&gt;Here you are asserting that there IS // &apos;hedged&apos; reads going on.&lt;/p&gt;

&lt;p&gt;I was wondering if &apos;hedged requests&apos; a good name for this feature and going by the definition from your citation, it is good by me:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hedged requests. A simple way to curb latency variability is to issue the same request to multiple replicas and use the results from whichever replica responds first. We term such requests &quot;hedged requests&quot; because a client first sends one request to the replica believed to be the most appropriate, but then falls back on sending a secondary request after some brief delay. The client cancels remaining outstanding requests once the first result is received. Although naive implementations of this technique typically add unacceptable additional load, many variations exist that give most of the latency-reduction effects while increasing load only modestly.&lt;/p&gt;

&lt;p&gt;One such approach is to defer sending a secondary request until the first request has been outstanding for more than the 95th-percentile expected latency for this class of requests. This approach limits the additional load to approximately 5% while substantially shortening the latency tail. ....&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We&apos;d change this to be allowHedgeReads?&lt;/p&gt;

&lt;p&gt;+  public volatile boolean allowParallelReads = false;&lt;/p&gt;

&lt;p&gt;This would be hedgedReadThresholdMillis&lt;/p&gt;

&lt;p&gt;+  private volatile long quorumReadThresholdMillis;&lt;/p&gt;

&lt;p&gt;... and so on.&lt;/p&gt;

&lt;p&gt;Or do you see parallel reads as different from hedged reads?  (&apos;Tied requests&apos; from your citation).&lt;/p&gt;

&lt;p&gt;These are public so clients like hbase can tinker with them:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void setQuorumReadTimeout(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timeoutMillis) {
+    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.quorumReadThresholdMillis = timeoutMillis;
+  }
+
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; getQuorumReadTimeout() {
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.quorumReadThresholdMillis;
+  }
+
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void enableParallelReads() {
+    allowParallelReads = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
+  }
+
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void disableParallelReads() {
+    allowParallelReads = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So if the requests are &amp;gt; the configured number, we run in the current thread which is better than rejecting the request... What happens when we go beyond this allowance?  We throw the rejected exception?  When would there be more than the configured number of // reads going on?&lt;/p&gt;

&lt;p&gt;Should these be public?&lt;/p&gt;

&lt;p&gt;+  public ThreadPoolExecutor getParallelReadsThreadPool() &lt;/p&gt;
{
+    return parallelReadsThreadPool;
+  }
&lt;p&gt;+&lt;br/&gt;
+  public DFSQuorumReadMetrics getQuorumReadMetrics() {&lt;/p&gt;


&lt;p&gt;Will have to rename this class? DFSQuorumReadMetrics&lt;/p&gt;

&lt;p&gt;Add class comment on +public class DFSQuorumReadMetrics { saying what the metric means (since there is no description for the metrics it seems).&lt;/p&gt;

&lt;p&gt;Need a space in here?  &quot;+public class DFSQuorumReadMetrics {&quot;&lt;/p&gt;

&lt;p&gt;I need to spend more time on the DFSClient changes but above should do for a first cut at a review.   Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13876289" author="xieliang007" created="Mon, 20 Jan 2014 09:44:21 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt; for your so detailed comments !&lt;br/&gt;
Attached v3 addressed the naming related comments firstly.&lt;br/&gt;
And i have got some perf number and would like to share here:&lt;/p&gt;

&lt;p&gt;Test Env:&lt;br/&gt;
Hadoop 2.0 + HBase 0.94.11&lt;br/&gt;
3 datanodes and each DN has only one disk for dfs read/write(yes, only one SATA disk, it&apos;s a little poor, haha, but very perfect for current test scenario, since we do want to see the result while bad pread performance occurs)&lt;br/&gt;
one regionserver instance is up and created ycsb test table, loaded 20m records, each row has 3 * 200 bytes, and finally did a major compaction, the webui showed only 1 storefile with 14493MB.&lt;br/&gt;
I use single process ycsb with 10 threads running to do the random read(get) request,  each run 10 minutes, and i do clear the hbase block cache and os cache(drop_caches) manually between each testing. the hedged reads thread pool size keeps 50. Here is the detailed result:&lt;/p&gt;

&lt;p&gt;1) dfs.dfsclient.hedged.read.threshold.millis = 500ms, dfs.dfsclient.hedged.read.sleep.interval.millis = 50ms, in deed, it should be very like the current existing impl since per the following result, almost all of response time are less than 500ms, so just very very a few requests probably go to the secondary DN:&lt;br/&gt;
Throughput(ops/sec), 221.8174849820451&lt;br/&gt;
AverageLatency(us), 45055.13540070315&lt;br/&gt;
50thPercentileLatency(us), 24049&lt;br/&gt;
95thPercentileLatency(us), 165905&lt;br/&gt;
99thPercentileLatency(us), 270578&lt;/p&gt;

&lt;p&gt;2) dfs.dfsclient.hedged.read.threshold.millis = 150ms, dfs.dfsclient.hedged.read.sleep.interval.millis = 50ms&lt;br/&gt;
Throughput(ops/sec), 257.6483818568037&lt;br/&gt;
AverageLatency(us), 38781.92033469773&lt;br/&gt;
50thPercentileLatency(us), 20534&lt;br/&gt;
95thPercentileLatency(us), 148194&lt;br/&gt;
99thPercentileLatency(us), 201110&lt;/p&gt;

&lt;p&gt;3) dfs.dfsclient.hedged.read.threshold.millis = 100ms, dfs.dfsclient.hedged.read.sleep.interval.millis = 50ms&lt;br/&gt;
Throughput(ops/sec), 254.35882053973887&lt;br/&gt;
AverageLatency(us), 39291.54205264606&lt;br/&gt;
50thPercentileLatency(us), 20585&lt;br/&gt;
95thPercentileLatency(us), 150998&lt;br/&gt;
99thPercentileLatency(us), 151446&lt;/p&gt;

&lt;p&gt;4) dfs.dfsclient.hedged.read.threshold.millis = 100ms, dfs.dfsclient.hedged.read.sleep.interval.millis = 20ms&lt;br/&gt;
Throughput(ops/sec), 237.20809410260168&lt;br/&gt;
AverageLatency(us), 42110.37126189875&lt;br/&gt;
50thPercentileLatency(us), 20246&lt;br/&gt;
95thPercentileLatency(us), 121147&lt;br/&gt;
99thPercentileLatency(us), 141207&lt;/p&gt;

&lt;p&gt;In summary, in my heavy io-bound random read test scenario, the 99th percentile latency was cut off from 270ms to 141ms via hedged read feature, but it doesn&apos;t helpful to improve the avg latency or throughput obviously, this is expected, the biggest benefit is against the long-tail random read latency issue, which is pretty common in HBase.&lt;/p&gt;</comment>
                            <comment id="13876388" author="hadoopqa" created="Mon, 20 Jan 2014 12:09:40 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623929/HDFS-5776-v3.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623929/HDFS-5776-v3.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5920//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5920//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5920//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5920//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13876733" author="stack" created="Mon, 20 Jan 2014 19:12:38 +0000"  >&lt;p&gt;Nice numbers &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When you get a chance, there were a few questions in the previous review notes.&lt;/p&gt;

&lt;p&gt;Nit: This seems extraneous in the new Callable:&lt;/p&gt;

&lt;p&gt;+        return null;&lt;/p&gt;

&lt;p&gt;Nit: No need of the intermediary &apos;instance&apos; assignment &amp;#8211; just assign to &apos;injector&apos;?&lt;/p&gt;

&lt;p&gt;+    // Set up the InjectionHandler&lt;br/&gt;
+    DFSClientFaultInjector.instance = Mockito&lt;br/&gt;
+        .mock(DFSClientFaultInjector.class);&lt;br/&gt;
+    DFSClientFaultInjector injector = DFSClientFaultInjector.instance;&lt;/p&gt;

&lt;p&gt;Nit: Should the &apos;60&apos; below here:&lt;/p&gt;

&lt;p&gt;+        Thread.sleep(60);&lt;/p&gt;

&lt;p&gt;Be more related to the the &apos;100&apos; you pass as the DFS_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS config?  Be half of whatever DFS_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS is?   My concern is that someone could change one of these settings not realizing they are related (they are, right)?&lt;/p&gt;

&lt;p&gt;Is it possible that on a slow machine &amp;#8211; such as apache jenkins &amp;#8211; that we may get a hedged read when we do not expect it ?&lt;/p&gt;

&lt;p&gt;+      // assert that there were no hedged reads. 60ms + delta &amp;lt; 100ms&lt;/p&gt;

&lt;p&gt;i.e. could this test turn flakey on a strained testing infrastructure?&lt;/p&gt;

&lt;p&gt;Shut down this executor in the finally?  Don&apos;t want it sticking around.&lt;/p&gt;

&lt;p&gt;+      ExecutorService executor = Executors.newFixedThreadPool(numHedgedReads);&lt;/p&gt;

&lt;p&gt;For sure this will always trigger though the number of futures == numHedgedReads (should futures == numHedgedReads + 1 to be sure?)&lt;/p&gt;

&lt;p&gt;+      assertTrue(metrics.getHedgedReadOpsInCurThread() &amp;gt; 0);&lt;/p&gt;

&lt;p&gt;Nice test.&lt;/p&gt;

&lt;p&gt;Your nice new metrics showed in your above test?  They made sense (I suppose they must basically work since your test relies on them).&lt;/p&gt;

&lt;p&gt;You need the below new log?&lt;/p&gt;

&lt;p&gt;+          DFSClient.LOG.warn(&quot;Could not obtain block &quot; + block + errMsg&lt;br/&gt;
+              + &quot;. Throw a BlockMissingException&quot;);&lt;/p&gt;

&lt;p&gt;s/Throw/Throwing/&lt;/p&gt;

&lt;p&gt;Make the above log message match the content of the BlockMissingException so it easier connecting the two emissions (Later in the patch you actually do this).&lt;/p&gt;

&lt;p&gt;Needs a space between ie and errMsg? &lt;/p&gt;

&lt;p&gt;+            + &quot; from any node: &quot; + ie + errMsg&lt;/p&gt;

&lt;p&gt;When we get to the end of the pipeline here; i.e. all datanodes have been tried, what happens?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) {
+      DNAddrPair retval = chooseDataNode(block);
+      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
+        actualGetFromOneDataNode(retval, block, start, end, buf, offset,
+            corruptedBlockMap);
+        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
+      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
+        &lt;span class=&quot;code-comment&quot;&gt;// Ignore. Already processed inside the function.
&lt;/span&gt;+        &lt;span class=&quot;code-comment&quot;&gt;// Loop through to &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; the next node.
&lt;/span&gt;+      }
+    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Seems like the above is a common idiom in DFSClient. &lt;/p&gt;

&lt;p&gt;Say why it is ok to ignore the IOE at this point in the comment.&lt;/p&gt;

&lt;p&gt;+            // ignore fetchBlockAt IOException&lt;/p&gt;

&lt;p&gt;This is good:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;DFSClient.LOG.debug(&quot;Connection failure &quot;, e);&lt;br/&gt;
+            DFSClient.LOG.debug(&quot;Connection failure: &quot; + msg, e);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I suppose moving this into finally would be messier than what you have done where you add it to the end of the if and the else clauses when exception:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Put chosen node into dead list, continue&lt;/li&gt;
	&lt;li&gt;addToDeadNodes(chosenNode);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Should fetchBlockByteRangeSpeculative be called fetchBlockByteRangeHedge or hedgedFetchBlockByteRange.... &apos;hedged&apos; fetches is what this patch introduces.  &apos;speculative&apos; may confuse.  At least add a comment that the method is about &apos;hedged&apos; fetches.&lt;/p&gt;

&lt;p&gt;So on a dfsclient instance, we can flip hedged reads on and off?&lt;br/&gt;
+  public void enableHedgedReads() &lt;/p&gt;
{
+    allowHedgedReads = true;
+  }

&lt;p&gt;ThreadPoolExecutor should make daemon threads?&lt;/p&gt;

&lt;p&gt;Is this a good idea?&lt;/p&gt;

&lt;p&gt;getHedgedReadsThreadPool&lt;/p&gt;

&lt;p&gt;Should be kept internal to DFSClient.&lt;/p&gt;

&lt;p&gt;Patch is great &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;&lt;/p&gt;






</comment>
                            <comment id="13876777" author="cmccabe" created="Mon, 20 Jan 2014 19:42:51 +0000"  >&lt;p&gt;Let&apos;s keep TestPread as a test of just pread, and have a separate test to test hedged reads.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; ByteBuffer getFirst(ArrayList&amp;lt;Future&amp;lt;ByteBuffer&amp;gt;&amp;gt; futures,
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Could we rename this to &lt;tt&gt;getFirstToComplete&lt;/tt&gt; or something like that?  getFirst just sounds like it&apos;s getting the first element in the ArrayList.&lt;/p&gt;

&lt;p&gt;I think that when the data being read is local, you will not want hedged reads.  Let&apos;s check for this case.&lt;/p&gt;

&lt;p&gt;Thanks, Liang.&lt;/p&gt;</comment>
                            <comment id="13876802" author="stack" created="Mon, 20 Jan 2014 19:57:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think that when the data being read is local, you will not want hedged reads. Let&apos;s check for this case.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You think Mighty &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;Colin Patrick McCabe&lt;/a&gt;?  Having hedged read on could ameliorate &apos;bad sector&apos; syndrome (and its many variants)?  Thanks.&lt;/p&gt;</comment>
                            <comment id="13876842" author="cmccabe" created="Mon, 20 Jan 2014 20:39:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;Having hedged read on could ameliorate &apos;bad sector&apos; syndrome (and its many variants)? Thanks.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess we probably don&apos;t need to special-case local reads, as long as we continue to prefer to read from local datanodes when possible.&lt;/p&gt;</comment>
                            <comment id="13877145" author="xieliang007" created="Tue, 21 Jan 2014 03:35:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;Colin Patrick McCabe&lt;/a&gt;,  hedged reads doesn&apos;t need to be aware of weather local read or not.&lt;br/&gt;
pread -&amp;gt; fetchBlockByteRange/fetchBlockByteRangeSpeculative -&amp;gt; actualGetFromOneDataNode -&amp;gt; getBlockReader&lt;br/&gt;
we don&apos;t need to handle weather local reader or not, the hedged reads only focus on picking a secondary dn, then wait the winner.&lt;/p&gt;

&lt;p&gt;In my test, the region server(rs) instance was in the same box with one dn(say dn1). Take my first case(dfs.dfsclient.hedged.read.threshold.millis = 500ms) for example, in that case, in deed, nearly all of the preads go to the local dn1, i could observe io util% always is 100%(really io bound, aha, btw, i filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5727&quot; title=&quot;introduce a self-maintaining io queue handling mechanism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5727&quot;&gt;HDFS-5727&lt;/a&gt;, hope with that we can alleviate the io somehow, i am planning to dig that jira after this done, if you guys have any comments, just put there) during the testing, and dn2/dn3&apos;s io util% keep 0%.    and in following cases, i could see the io util% of dn2/dn3 began to increment to around 5%~20%.&lt;/p&gt;</comment>
                            <comment id="13877146" author="xieliang007" created="Tue, 21 Jan 2014 03:37:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;I guess we probably don&apos;t need to special-case local reads, as long as we continue to prefer to read from local datanodes when possible.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, correct&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;   (hmm, i read several times then fully understant your meaning, my reading english needs to be improvement)&lt;/p&gt;</comment>
                            <comment id="13877154" author="xieliang007" created="Tue, 21 Jan 2014 03:51:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;Let&apos;s keep TestPread as a test of just pread, and have a separate test to test hedged reads.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;this&apos;s what i did, i only changed dfsPreadTest a bit, no creating new conf object, but repy on the input parameter, that&apos;s all,  i do have separate cases for hedged reads, see testHedgedPreadDFSBasic and testMaxOutHedgedReadPool&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Could we rename this to getFirstToComplete or something like that? getFirst just sounds like it&apos;s getting the first element in the ArrayList.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think that when the data being read is local, you will not want hedged reads. Let&apos;s check for this case.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;seems you have a different understanding with it, and the latter comments &quot;I guess we probably don&apos;t need to special-case local reads, as long as we continue to prefer to read from local datanodes when possible&quot; is correct, there&apos;s is no conflict between local read and hedged read.  The hedged read still try to request local read if possible, if no successful until the timeout reach, then request to the picked secondary dn, then wait the winner.&lt;/p&gt;
</comment>
                            <comment id="13877161" author="xieliang007" created="Tue, 21 Jan 2014 04:01:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Nit: This seems extraneous in the new Callable: + return null;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;the &quot;return null&quot; is needful, since we have a &quot;Future&amp;lt;Void&amp;gt;&quot; definition, if we remove the &quot;return null&quot;, the compiler will complain&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Nit: No need of the intermediary &apos;instance&apos; assignment &#8211; just assign to &apos;injector&apos;?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;we need, it returns a object,see Javadoc:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    /**
     * Creates mock object of given class or &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt;.
     * &amp;lt;p&amp;gt;
     * See examples in javadoc &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; {@link Mockito} class
     * 
     * @param classToMock class or &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; to mock
     * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; mock object
     */
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &amp;lt;T&amp;gt; T mock(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;T&amp;gt; classToMock) {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; mock(classToMock, withSettings().defaultAnswer(RETURNS_DEFAULTS));
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13877173" author="xieliang007" created="Tue, 21 Jan 2014 04:24:19 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Nit: Should the &apos;60&apos; below here:&lt;br/&gt;
+ Thread.sleep(60);&lt;br/&gt;
Be more related to the the &apos;100&apos; you pass as the DFS_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS config? Be half of whatever DFS_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS is? My concern is that someone could change one of these settings not realizing they are related (they are, right)?&lt;br/&gt;
Is it possible that on a slow machine &#8211; such as apache jenkins &#8211; that we may get a hedged read when we do not expect it ?&lt;br/&gt;
+ // assert that there were no hedged reads. 60ms + delta &amp;lt; 100ms&lt;br/&gt;
i.e. could this test turn flakey on a strained testing infrastructure?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;very good suggestion, i modfied the 100ms to 500ms and sleep interval now is 50ms, it should be enough at least to me&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13877177" author="xieliang007" created="Tue, 21 Jan 2014 04:35:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;Shut down this executor in the finally? Don&apos;t want it sticking around.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, add &quot;executor.shutdown()&quot; now, but i didn&apos;t put it into finally block, since no exception within it and i don&apos;t like to move the executor definition before the try block&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Your nice new metrics showed in your above test? They made sense (I suppose they must basically work since your test relies on them).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;the new metrics also useful for HBase side, in our HBase related change, we could gather these new metrics into RegionServerMetrics or some other place&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;s/Throw/Throwing/&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;done, thanks.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Needs a space between ie and errMsg?&lt;br/&gt;
+ + &quot; from any node: &quot; + ie + errMsg&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;good catch, added a space inside getBestNodeErrorString now&lt;/p&gt;</comment>
                            <comment id="13877231" author="xieliang007" created="Tue, 21 Jan 2014 05:51:35 +0000"  >&lt;blockquote&gt;
&lt;p&gt;getHedgedReadsThreadPool&lt;br/&gt;
Should be kept internal to DFSClient.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;changed from &quot;public&quot; to &quot;protected&quot;, since we need it in DFSInputStream for a sanity check.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So on a dfsclient instance, we can flip hedged reads on and off?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, will only take effect on that instance.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should fetchBlockByteRangeSpeculative be called fetchBlockByteRangeHedge or hedgedFetchBlockByteRange&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;ok, changed to &quot;hedgedFetchBlockByteRange&quot; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13877255" author="xieliang007" created="Tue, 21 Jan 2014 06:20:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;For sure this will always trigger though the number of futures == numHedgedReads (should futures == numHedgedReads + 1 to be sure?)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There&apos;s no guarantee about that, we cann&apos;t predict the detailed numHedgedReads count against futures size, there&apos;s no direct corelation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You need the below new log?&lt;br/&gt;
+ DFSClient.LOG.warn(&quot;Could not obtain block &quot; + block + errMsg&lt;br/&gt;
+ + &quot;. Throw a BlockMissingException&quot;);&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, it would be better if we have it once diagnoise sth.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Make the above log message match the content of the BlockMissingException so it easier connecting the two emissions (Later in the patch you actually do this).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;done&lt;/p&gt;</comment>
                            <comment id="13877263" author="xieliang007" created="Tue, 21 Jan 2014 06:28:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;When we get to the end of the pipeline here; i.e. all datanodes have been tried, what happens?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In bestNode(), if we can not find any candidate, will throw new IOException(&quot;No live nodes contain current block&quot;), then chooseDataNode will catch it and retry within a calculated timeWindow and dfsClient.getMaxBlockAcquireFailures limit.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Say why it is ok to ignore the IOE at this point in the comment.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;done&lt;/p&gt;</comment>
                            <comment id="13877268" author="xieliang007" created="Tue, 21 Jan 2014 06:34:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;I suppose moving this into finally would be messier than what you have done where you add it to the end of the if and the else clauses when exception:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;if we hit InvalidEncryptionKeyException or InvalidToken exception, we don&apos;t want to addToDeadNodes immediately before retry, so we could not move addToDeadNodes into a finally block,  FYI, you could refer to &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5766&quot; title=&quot;In DFSInputStream, do not add datanode to deadNodes after InvalidEncryptionKeyException in fetchBlockByteRange&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5766&quot;&gt;&lt;del&gt;HDFS-5766&lt;/del&gt;&lt;/a&gt; for the reason.&lt;/p&gt;

&lt;p&gt;seems i have answered all the above comments, am i missed anyone? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; let me upload the new one.&lt;/p&gt;
</comment>
                            <comment id="13877344" author="hadoopqa" created="Tue, 21 Jan 2014 09:03:10 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624084/HDFS-5776-v4.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624084/HDFS-5776-v4.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5924//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5924//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5924//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5924//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13877996" author="enis" created="Tue, 21 Jan 2014 23:21:28 +0000"  >&lt;p&gt;Nice work Liang. You have beat us to implement this! &lt;br/&gt;
A couple of higher level comments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The numbers look very promising. &lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/en/us/people/jeff/Berkeley-Latency-Mar2012.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://static.googleusercontent.com/media/research.google.com/en/us/people/jeff/Berkeley-Latency-Mar2012.pdf&lt;/a&gt; slides 50+ gives some numbers for increased RPC&apos;s caused by this. If will be great if we can get some info about this as well.&lt;/li&gt;
	&lt;li&gt;Regarding naming, FB branch calls this quorum reads (which is misleading), and google calls this backup requests. We preferred to use the name &quot;parallel&quot;, and &quot;parallel with delay&quot; in design doc for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10070&quot; title=&quot;HBase read high-availability using eventually consistent region replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10070&quot;&gt;HBASE-10070&lt;/a&gt; (a similar feature in HBase) and in the code we ended up calling it RPC with fallback. It will be very good to use a consistent naming across hdfs and hbase, but not sure which one is better.&lt;/li&gt;
	&lt;li&gt;In getFirstToComplete(), sleeping is not the best practice. It puts an arbitrary delay in returning back, and configuring the sleep timeout is non-trivial. Can we do smt like ExecutorService.invokeAny() or a wait/notify or a coundownLatch design?   See &lt;a href=&quot;http://stackoverflow.com/questions/117690/wait-until-any-of-futuret-is-done&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/117690/wait-until-any-of-futuret-is-done&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;Again in the Jeff Dean&apos;s slides, they talk about doing the 3rd requests with larger timeout does not buy a lot. Wondering whether we should limit this to only 2 requests or not. Without real-world usage it will be hard to choose one way or the other.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13878028" author="stack" created="Tue, 21 Jan 2014 23:50:35 +0000"  >&lt;p&gt;(Trying to help out w/ naming...)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt; You don&apos;t like &apos;hedged&apos;?  You saw the above citation where there is a &apos;definition&apos; of hedged reads and then the technique implemented by this patch here.  &apos;backup requests&apos; seems less formal being &apos;just&apos; a label on a slide.  // with delay is accurate but a mouthful.&lt;/p&gt;</comment>
                            <comment id="13878184" author="xieliang007" created="Wed, 22 Jan 2014 02:54:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enis&quot; class=&quot;user-hover&quot; rel=&quot;enis&quot;&gt;Enis Soztutar&lt;/a&gt;, thanks for your nice comments.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;sleeping is not the best practice&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Totally agree ! let me try to remove it&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13878371" author="xieliang007" created="Wed, 22 Jan 2014 07:46:15 +0000"  >&lt;p&gt;v5 began to use CountDownLatch now, from the test result, looks better for timeout=100ms:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;OVERALL&amp;#93;&lt;/span&gt;, Throughput(ops/sec), 275.0043323513337&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, Operations, 165040&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, AverageLatency(us), 36339.62364881241&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, MinLatency(us), 260&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, MaxLatency(us), 1375837&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 50thPercentileLatency(us), 20306&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 95thPercentileLatency(us), 115498&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 99thPercentileLatency(us), 124271&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13878382" author="xieliang007" created="Wed, 22 Jan 2014 07:56:39 +0000"  >&lt;p&gt;About naming, personally i&apos;d like to keep &quot;hedged&quot; unchanged, it&apos;s not a big issue if &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10070&quot; title=&quot;HBase read high-availability using eventually consistent region replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10070&quot;&gt;HBASE-10070&lt;/a&gt; use another naming, just my thought&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
About increased RPC, sure, it&apos;s just a tradeoff, we all know that&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  i can give a metric result against diff timeout setting, probably put into &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7509&quot; title=&quot;Enable RS to query a secondary datanode in parallel, if the primary takes too long&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7509&quot;&gt;HBASE-7509&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;doing the 3rd requests with larger timeout does not buy a lot&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Current patch just picks only one secondary dn, thats means there&apos;re no more than two requests under normal situation.&lt;/p&gt;

&lt;p&gt;BTW, is it possible let it go into &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-2&quot; title=&quot;Reused Keys and Values fail with a Combiner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-2&quot;&gt;&lt;del&gt;HADOOP-2&lt;/del&gt;&lt;/a&gt;.4 if all comments are done ?  i saw &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrew.wang&quot; class=&quot;user-hover&quot; rel=&quot;andrew.wang&quot;&gt;Andrew Wang&lt;/a&gt;&apos;s post from mail list that there&apos;s a plan to release 2.4 in the end of this month, right ?&lt;br/&gt;
If this patch could go in, then we can work immediately at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7509&quot; title=&quot;Enable RS to query a secondary datanode in parallel, if the primary takes too long&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7509&quot;&gt;HBASE-7509&lt;/a&gt; with bumping the according dependency version to 2.4,  otherwise we need to kick off once it goes into 2.5+, maybe need several weeks ?&lt;/p&gt;</comment>
                            <comment id="13878459" author="xieliang007" created="Wed, 22 Jan 2014 09:38:42 +0000"  >&lt;p&gt;Added a bit codes into YCSB to get 99.9thPercentile latency, here is the result:&lt;br/&gt;
dfs.dfsclient.hedged.read.threshold.millis=100ms:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 95thPercentileLatency(us), 115973&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 99thPercentileLatency(us), 124829&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 99.9thPercentileLatency(us), 217892&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;dfs.dfsclient.hedged.read.threshold.millis=600000ms(this&apos;s equals to disable hedged read feature, since my test duration is 600s):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 95thPercentileLatency(us), 149355&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 99thPercentileLatency(us), 256987&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;READ&amp;#93;&lt;/span&gt;, 99.9thPercentileLatency(us), 418950&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In practice, maybe we should set the threshold equals to 95/99th percentile latency, here just a test to make the difference more obviously...&lt;/p&gt;</comment>
                            <comment id="13878485" author="hadoopqa" created="Wed, 22 Jan 2014 10:09:22 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12624294/HDFS-5776-v5.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12624294/HDFS-5776-v5.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5934//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5934//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5934//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5934//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13878997" author="enis" created="Wed, 22 Jan 2014 18:48:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;About naming, personally i&apos;d like to keep &quot;hedged&quot; unchanged&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ok, honestly, I am not a native speaker so I had to look it up. But if this is common usage, fine with me.  &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;v5 began to use CountDownLatch now, from the test result, looks better for timeout=100ms&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Great, thanks. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Current patch just picks only one secondary dn, thats means there&apos;re no more than two requests under normal situation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I thought the while(true) loop will continue sending the rpc to 3rd replica. Let me check the patch again. &lt;/p&gt;</comment>
                            <comment id="13879324" author="cmccabe" created="Wed, 22 Jan 2014 23:06:54 +0000"  >&lt;p&gt;I like the idea of calling this &quot;hedged reads.&quot;  We already have a test called TestParallelReads in HDFS which is not related to this, and so it would be a bit confusing to call this feature &quot;parallel reads.&quot;&lt;/p&gt;</comment>
                            <comment id="13879326" author="arpitagarwal" created="Wed, 22 Jan 2014 23:10:36 +0000"  >&lt;p&gt;Hi Liang, thanks for this contribution to HDFS!&lt;/p&gt;

&lt;p&gt;I am still reviewing &lt;tt&gt;DFSInputStream#hedgedFetchBlockByteRange&lt;/tt&gt; and the tests but here is some initial feedback.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Does it make sense for &lt;tt&gt;DFSClient#hedgedReadsThreadPool&lt;/tt&gt; to be a static field? The concern is too many thread pools created by multiple clients on the same node.&lt;/li&gt;
	&lt;li&gt;Related to the previous - what do you think of not exposing the &lt;tt&gt;DFS_DFSCLIENT_HEDGED_READ_THREADPOOL_SIZE&lt;/tt&gt; setting at all? Maybe we can just expose a boolean setting to enable it. The reason I prefer not to surface such settings is because it invites abuse (the concern is not with trusted apps like HBase). If we do expose this setting we should at least have an internal upper bound.&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;DFSClient#allowHedgedReads&lt;/tt&gt; seems unnecessary since you can just use (&lt;tt&gt;hedgedReadsThreadPool == null&lt;/tt&gt;). Also you can remove &lt;tt&gt;#enableHedgedReads&lt;/tt&gt; and &lt;tt&gt;#disableHedgedReads&lt;/tt&gt;.&lt;/li&gt;
	&lt;li&gt;For &lt;tt&gt;DEFAULT_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS&lt;/tt&gt; - can we add an inbuilt minimum delay to defeat applications that set it too low or even zero?&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;DFSInputStream#chooseDataNode&lt;/tt&gt; - can the call to getBestNodeErrorString go inside the &quot;&lt;tt&gt;if (failures &amp;gt;=...&lt;/tt&gt;&quot; clause?&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;#fetchBlockByteRange&lt;/tt&gt; - can we rename &lt;tt&gt;retVal&lt;/tt&gt; to something like &lt;tt&gt;addressPair&lt;/tt&gt;?&lt;/li&gt;
	&lt;li&gt;Do we still need the &lt;tt&gt;while&lt;/tt&gt; loop still there in &lt;tt&gt;actualGetFromOneDataNode&lt;/tt&gt;? There is already a while loop in &lt;tt&gt;fetchBlockByteRange&lt;/tt&gt; enclosing the call to &lt;tt&gt;actualGetFromOneDataNode&lt;/tt&gt;. Now we have a nested loop.&lt;/li&gt;
	&lt;li&gt;Maybe I misunderstood the code flow but it looks like the way the while loops are nested it defeats the usage of &lt;tt&gt;refetchToken&lt;/tt&gt; and &lt;tt&gt;refetchEncryptionKey&lt;/tt&gt;. It looks like the intention was to limit the refetch to 1 across all retries, now we can refetch multiple times.&lt;/li&gt;
	&lt;li&gt;Related to the previous, &lt;tt&gt;#actualGetFromOneDataNode&lt;/tt&gt;, line 1026, - sorry I did not understand why the try-catch was added around the call to &lt;tt&gt;fetchBlockAt&lt;/tt&gt;.&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;#actualGetFromOneDataNode&lt;/tt&gt;, line 1010 - we are using an exception to signal retry to the caller. It might be better to return a &lt;tt&gt;boolean&lt;/tt&gt; instead.&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;#actualGetFromOneDataNode&lt;/tt&gt;, line 1033 - the call to &lt;tt&gt;DFSClient.LOG.warn&lt;/tt&gt; is deleted. Assume that was unintentional?&lt;/li&gt;
	&lt;li&gt;Nitpick - some lines have whitespace-only changes.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13879476" author="stack" created="Thu, 23 Jan 2014 06:11:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt; Great review (from a bystander).  One note on 1..  Is static ever a good idea for sharing resources?  But your point of being able to share amongst DFSClient instances is for sure something we should pursue (in another JIRA?).  We could pass a common executor in a shared context and we could also keep running lists of black-listed nodes rather than have each stream discover for themselves the dead... and so on&lt;/p&gt;</comment>
                            <comment id="13879680" author="xieliang007" created="Thu, 23 Jan 2014 08:27:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt;, thanks for your nice review!&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The concern is too many thread pools created by multiple clients on the same node&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;take it easy, the default configuration: pool=0, that means no extra new threads be created by default. if a end user/application enable hedged read, they should know about this&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;what do you think of not exposing the DFS_DFSCLIENT_HEDGED_READ_THREADPOOL_SIZE setting at all&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;IMHO, i personally prefer the current style, it&apos;s less risky, we had a bound queue and once reach the queue limit, we force to exec it in current thread. about the &quot;internal upper bound&quot;, how much?  5000? 500000? or sth else? i think if enabling this feature explicitly, the end user/application should know a little backgroud at least, right? just like lots of hadoop timeout config parameter, i never see any internal upper bound impl at all...   but if you strongly insist on it, i can add.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;DFSClient#allowHedgedReads seems unnecessary&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;let&apos;s keep it there, it&apos;s more easier to understand for developer or end user.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For DEFAULT_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS - can we add an inbuilt minimum delay to defeat applications that set it too low or even zero&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;my opinion is same as the above one. since we don&apos;t have any knowledge about end-user&apos;s storage configuration, just image if they have a fast flash(with &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2832&quot; title=&quot;Enable support for heterogeneous storages in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2832&quot;&gt;HDFS-2832&lt;/a&gt; enabled), say fusionio, probably one real disk read only cost tens of microseconds, how should we decide a good minimum defeat setting? so i don&apos;t like to add it, i totally get your kindly concern&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;DFSInputStream#chooseDataNode - can the call to getBestNodeErrorString go inside the &quot;if (failures &amp;gt;=...&quot; clause?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;another log statement also use it, see &quot;DFSClient.LOG.info(&quot;Could not obtain &quot; + block.getBlock...&quot;, so it&apos;s impossible here.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;#fetchBlockByteRange - can we rename retVal to something like addressPair?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;good. let me rename it&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do we still need the while loop still there in actualGetFromOneDataNode?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, but the loop is very very light,  only when some exceptions like AccessControlException/InvalidEncryptionKeyException/InvalidBlockTokenException happened, will do extra loop, and all those have a fast quit mechanism, like refetchToken/refetchEncryptionKey or disableLegacyBlockReaderLocal, so this loop will only be executed just a very few times&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;There is already a while loop in fetchBlockByteRange enclosing the call to actualGetFromOneDataNode. Now we have a nested loop.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In the loop inside fetchBlockByteRange, the responsibily is picking another dn if there&apos;s IOException thrown from actualGetFromOneDataNode,  so not a fearful nested loop at all, take it easy&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe I misunderstood the code flow but it looks like the way the while loops are nested it defeats the usage of refetchToken and refetchEncryptionKey. It looks like the intention was to limit the refetch to 1 across all retries, now we can refetch multiple times.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, you had a misunderstanding here. that&apos;s why i catch IOException fbae around fetchBlockAt. If we don&apos;t catch here, there will be always new refetch from outside loop and will have a spin loop&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Related to the previous, #actualGetFromOneDataNode, line 1026, - sorry I did not understand why the try-catch was added around the call to fetchBlockAt.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;hope the above answer could make you clear?  hope my poor english doesn&apos;t make everything worse, haha&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;#actualGetFromOneDataNode, line 1033 - the call to DFSClient.LOG.warn is deleted. Assume that was unintentional?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Gooood catch!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Nitpick - some lines have whitespace-only changes.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;i found several unnessessiry whitespaces existing, i just removed them to make more clear.&lt;/p&gt;

&lt;p&gt;Really thanks all for review!!!&lt;/p&gt;</comment>
                            <comment id="13880279" author="jingzhao" created="Thu, 23 Jan 2014 19:48:22 +0000"  >&lt;ol&gt;
	&lt;li&gt;In DFSClient, I agree with Arpit that we should remove the allowHedgedReads field and the enable/disable methods. In the current code, whether hedged read is enabled is determined by the initial setting of the hedgedReadThreadPool. If we provide these extra enable/disable methods, what if a user of DFSClient sets 0 to the thread pool size and later call the enableHedgedReads? Unless we have a clear use case to support the usage of the enable/disable methods, I guess we do not need to provide these flexibility here.&lt;br/&gt;
An alternative way to do this is to have an &quot;Allow-Hedged-Reads&quot; configuration, and if it is set to true, we load the number of thread pool and the threshold time. We will provide an isHedgedReadsEnabled method but we will not provide enable/disable methods. I guess this may be easier for users to understand.&lt;/li&gt;
	&lt;li&gt;Can this scenario be possible? In hedgedFetchBlockByteRange, if we hit the timeout for the first DN, we will add the DN to the ignore list, and call chooseDataNode again. If the first DN is the only DN we can read, we will get IOException from bestNode. Then we will run into a loop where we keep trying to get another DN multiple times (some NN rpc call will even be fired). And during this process the first DN can even return the data. In this scenario I guess we may get a worse performance? Thus I guess we should not trigger hedged read if we find that we cannot (easily) find the second DN for read?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13880280" author="cmccabe" created="Thu, 23 Jan 2014 19:48:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;One note on 1.. Is static ever a good idea for sharing resources? But your point of being able to share amongst DFSClient instances is for sure something we should pursue (in another JIRA?)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Unfortunately, the &lt;tt&gt;FileContext&lt;/tt&gt; API creates a new &lt;tt&gt;DFSClient&lt;/tt&gt; instance for each operation that it does.  (The older &lt;tt&gt;FileSystem&lt;/tt&gt; API doesn&apos;t have this problem, since the &lt;tt&gt;DistributedFileSystem&lt;/tt&gt; object hangs on to the &lt;tt&gt;DFSClient&lt;/tt&gt; for a while.)  This means that we do need to put this in a static, for now, or else &lt;tt&gt;FileContext&lt;/tt&gt; users will be constantly destroying and creating thread-pools.&lt;/p&gt;

&lt;p&gt;I have another change pending which creates the concept of a &quot;cache context,&quot; where different threads can use different contexts if they like.  For now, let&apos;s use a static variable, maybe with a TODO.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Related to the previous - what do you think of not exposing the DFS_DFSCLIENT_HEDGED_READ_THREADPOOL_SIZE setting at all? Maybe we can just expose a boolean setting to enable it. The reason I prefer not to surface such settings is because it invites abuse (the concern is not with trusted apps like HBase). If we do expose this setting we should at least have an internal upper bound.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t see why we wouldn&apos;t expose this setting.  It doesn&apos;t give the client the ability to do anything bad it couldn&apos;t already do.  You can already try to open a zillion files at once in order to attack the &lt;tt&gt;NameNode&lt;/tt&gt; / &lt;tt&gt;DataNodes&lt;/tt&gt;.  Preventing denial-of-service attacks is not currently something we try to do.  And in the future, if we ever do try to prevent denial-of-service attacks, I don&apos;t think having hedged reads makes that any more or less difficult than it would otherwise be.&lt;/p&gt;</comment>
                            <comment id="13880284" author="cmccabe" created="Thu, 23 Jan 2014 19:54:04 +0000"  >&lt;p&gt;By the way, my previous comment was assuming that the alternative proposed to making the thread-pool static was putting it in DFSClient (not a good option).  Another option would be making the thread-pool local to the DFSInputStream.  However, this seems like it will tend to create an enormous number of threads, especially for applications like HBase that open many files.  So again I would argue it should be static.&lt;/p&gt;</comment>
                            <comment id="13880746" author="stack" created="Fri, 24 Jan 2014 06:04:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;An alternative way to do this is to have an &quot;Allow-Hedged-Reads&quot; configuration, and if it is set to true, we load the number of thread pool and the threshold time. We will provide an isHedgedReadsEnabled method but we will not provide enable/disable methods.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The reviews are great.  On the above,  while I can see putting the on/off switch as a DN config., we should allow setting at least the config on when to start the hedge read per DFSCient instance.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This means that we do need to put this in a static, for now, or else FileContext users will be constantly destroying and creating thread-pools.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks Colin.  Makes sense.&lt;/p&gt;




</comment>
                            <comment id="13880753" author="xieliang007" created="Fri, 24 Jan 2014 06:16:06 +0000"  >&lt;p&gt;Attached v7 makes the pool static now, please review&lt;/p&gt;</comment>
                            <comment id="13880757" author="stack" created="Fri, 24 Jan 2014 06:22:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; what you think of the new comments above by the lads?&lt;/p&gt;

&lt;p&gt;Now the executor is static, the number of threads config needs to be NumberOfHBaseOpenFiles X 2 else the feature will not work for all files?  Thanks.&lt;/p&gt;</comment>
                            <comment id="13880762" author="xieliang007" created="Fri, 24 Jan 2014 06:30:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can this scenario be possible? In hedgedFetchBlockByteRange, if we hit the timeout for the first DN, we will add the DN to the ignore list, and call chooseDataNode again. If the first DN is the only DN we can read, we will get IOException from bestNode. Then we will run into a loop where we keep trying to get another DN multiple times (some NN rpc call will even be fired). And during this process the first DN can even return the data. In this scenario I guess we may get a worse performance? Thus I guess we should not trigger hedged read if we find that we cannot (easily) find the second DN for read?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes,there&apos;s possible happen about your case, nice! and a very easy handling method is just introduce a double-check function, say enoughNodesForHedgedRead(LocatedBlock block)  into the pread checking code branch&lt;/p&gt;</comment>
                            <comment id="13880783" author="xieliang007" created="Fri, 24 Jan 2014 07:15:37 +0000"  >&lt;p&gt;v8 add the enoughNodesForHedgedRead() function to sanity check, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;&apos;s comments is great, we definitely need a switch per DFSClient instance. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;the number of threads config needs to be NumberOfHBaseOpenFiles X 2 else the feature will not work for all files&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;still works, but probably lots of requests will execute in current thread, that means no latency benefit from hedged read feature.  this&apos;s is a good requirement that we need a per client instance&apos;s switch, such that we can let some instances use this feature,  we can control it on demand, right ? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13881281" author="stack" created="Fri, 24 Jan 2014 18:37:34 +0000"  >&lt;p&gt;So, to enable, we set DFS_DFSCLIENT_HEDGED_READ_THREADPOOL_SIZE in DN config.  Should the number of threads in the hbase case be greater than NUMBER_OF_HBASE_OPEN_FILES (though this is most often an unknown number, one that is changing over the life over the hbase process, and up in the thousands frequently)?  Otherwise we could set it some &apos;sensible&apos; number like 16 and then just watch the metrics this patch also adds.  If we are too often running the requests in the current thread because the executor has none to spare then we can up the number of pool threads (though it requires a DN restart, a PITA)?  That should work for the first cut at this feature.&lt;/p&gt;

&lt;p&gt;nit: You could declare and assign in the one go rather than postpone the assign to the constructor: HEDGED_READ_METRIC = new DFSHedgedReadMetrics();&lt;/p&gt;

&lt;p&gt;What is your thinking regards the boolean enabling/disabling hedge reads in DFSClient &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;?  On the one hand, there is a problem where the setting of pool size is done in DN config yet we have enable/disable hedge reads in the API; if the DN config has a pool size set to 0 then hedged reads are off (as was noted above), and though we may  &apos;enable&apos; hedge reads in the API, we won&apos;t be getting the behaviour we think we should be getting.  On the other hand, it looks like this boolean could be used &apos;conserving&apos; resources disabling hedged reads on a per request basis though hedged reads have been marked globally &apos;on&apos; in the DN?  Is that your thinking?  I&apos;m inclined to agree with the previous reviewers that this may verge on the &apos;exotic&apos;.  For the first cut at this feature, lets have a global on/off switch with number of threads being the means of constraining how much hedged reading we do?&lt;/p&gt;

&lt;p&gt;Otherwise patch looks great to me.&lt;/p&gt;
</comment>
                            <comment id="13881305" author="arpitagarwal" created="Fri, 24 Jan 2014 18:55:19 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I don&apos;t see why we wouldn&apos;t expose this setting. It doesn&apos;t give the client the ability to do anything bad it couldn&apos;t already do. You can already try to open a zillion files at once in order to attack the NameNode / DataNodes. Preventing denial-of-service attacks is not currently something we try to do. And in the future, if we ever do try to prevent denial-of-service attacks, I don&apos;t think having hedged reads makes that any more or less difficult than it would otherwise be.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;Colin Patrick McCabe&lt;/a&gt; I am thinking of carelessly configured settings, not a deliberate dos.&lt;/p&gt;</comment>
                            <comment id="13881341" author="arpitagarwal" created="Fri, 24 Jan 2014 19:28:35 +0000"  >&lt;p&gt;I reviewed the v8 patch. The implementation of &lt;tt&gt;hedgedFetchBlockByteRange&lt;/tt&gt; looks great. Nice use of synchronization tools to make the code easy to understand.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;how much? 5000? 500000? or sth else? i think if enabling this feature explicitly, the end user/application should know a little backgroud at least, right?&lt;br/&gt;
since we don&apos;t have any knowledge about end-user&apos;s storage configuration, just image if they have a fast flash(with &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2832&quot; title=&quot;Enable support for heterogeneous storages in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2832&quot;&gt;HDFS-2832&lt;/a&gt; enabled), say fusionio, probably one real disk read only cost tens of microseconds,&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;  #2 and #4 from my previous comment remain unaddressed.&lt;/p&gt;

&lt;p&gt;Threads are not free. If you really want to provide a user configurable setting for the thread count there should be a limit on the order of 64/128. I leave the exact number to you. The best approach is to use a small multiple of the processor count.&lt;/p&gt;

&lt;p&gt;If an app is not well behaved then the absence of limits can create a positive feedback loop. The slower the storage layer the more threads will get created when the correct behavior under load should be back off. Please add a thread count limit or ideally let&#8217;s not expose this setting at all.&lt;/p&gt;

&lt;p&gt;The same goes for the delay. Please add a lower bound. The exact value is up to you. We can always revisit the value if it turns out to be a bottleneck.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;let&apos;s keep it there, it&apos;s more easier to understand for developer or end user.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t think it helps to have these functions and as Jing pointed out there is no purpose for it. I think it would be best to leave a single config setting i.e. either a boolean or a thread count, and a single method &lt;tt&gt;#isHedgedReadsEnabled&lt;/tt&gt; to query the status of the feature.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;yes, but the loop is very very light, only when some exceptions like AccessControlException/InvalidEncryptionKeyException/InvalidBlockTokenException happened, will do extra loop, and all those have a fast quit mechanism, like refetchToken/refetchEncryptionKey or disableLegacyBlockReaderLocal, so this loop will only be executed just a very few times&lt;br/&gt;
...&lt;br/&gt;
yes, you had a misunderstanding here. that&apos;s why i catch IOException fbae around fetchBlockAt. If we don&apos;t catch here, there will be always new refetch from outside loop and will have a spin loop&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I still do not understand how you are guarding against multiple refetch. Previously these counters were initialized outside any loop, now they are being reinitialized inside a loop.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;chooseDataNode(LocatedBlock block)&lt;/tt&gt; function looks redundant and should be removed.&lt;/p&gt;</comment>
                            <comment id="13881661" author="cmccabe" created="Sat, 25 Jan 2014 04:56:41 +0000"  >&lt;p&gt;I might be misunderstanding, but it seems like this should be a client setting, not a datanode setting.  Right?&lt;/p&gt;</comment>
                            <comment id="13881827" author="hadoopqa" created="Sat, 25 Jan 2014 12:17:27 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625003/HDFS-5776-v8.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625003/HDFS-5776-v8.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 eclipse:eclipse&lt;/font&gt;.  The patch failed to build with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;        &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5941//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13882037" author="stack" created="Sat, 25 Jan 2014 20:36:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;I might be misunderstanding, but it seems like this should be a client setting, not a datanode setting. Right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;Colin Patrick McCabe&lt;/a&gt; You are correct.  I had it wrong.  s/restart DN/restart client/regionserver/ in the above.  Thanks C.&lt;/p&gt;</comment>
                            <comment id="13882606" author="xieliang007" created="Mon, 27 Jan 2014 06:52:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;If we are too often running the requests in the current thread because the executor has none to spare then we can up the number of pool threads (though it requires a DN restart, a PITA)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;we don&apos;t need to restart DN/RS or sth else, we can modify/introduce a hbase shell script to disable/enable the feature per instance or modify the thread number or other requirements, i think it&apos;s feasible, and those works, in deed, are the major task for supporting hedged read in HBase side&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;nit: You could declare and assign in the one go rather than postpone the assign to the constructor: HEDGED_READ_METRIC = new DFSHedgedReadMetrics();&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;good suggestion, let me fix it in patch v9.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Threads are not free. If you really want to provide a user configurable setting for the thread count there should be a limit on the order of 64/128. I leave the exact number to you.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Fine, let me introduce a hard code up-limit for DFS_DFSCLIENT_HEDGED_READ_THREADPOOL_SIZE to 128. &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The same goes for the delay. Please add a lower bound. The exact value is up to you. We can always revisit the value if it turns out to be a bottleneck.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Fine, let me introduce a hard code down-limit for DFS_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS to 1ms&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I think it would be best to leave a single config setting i.e. either a boolean or a thread count, and a single method #isHedgedReadsEnabled to query the status of the feature.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, that would be perfect sometimes, but not works for HBase scenario(the above Stack&apos;s consideration is great), since we made the pool &quot;static&quot;, and per client view, it&apos;s more flexible if we provide  instance level disable/enable APIs, so we can archive to use the hbase shell script to control the switch per dfs client instance, that&apos;ll be cooler&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I still do not understand how you are guarding against multiple refetch. Previously these counters were initialized outside any loop, now they are being reinitialized inside a loop.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In actualGetFromOneDatanode(), the refetchToken/refetchEncryptionKey is initialized outside the while (true) loop (see Line 993-996), when we hit InvalidEncryptionKeyException/InvalidBlockTokenException, the refetchToken and refetchEncryptionKey will be decreased by 1, (see refetchEncryptionKey-- and refetchToken-- statement), if the exceptions happened again, the check conditions will be failed definitely(see &quot;e instanceof InvalidEncryptionKeyException &amp;amp;&amp;amp; refetchEncryptionKey &amp;gt; 0&quot; and &quot;refetchToken &amp;gt; 0&quot;), so go to the else clause, that&apos;ll execute:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; msg = &lt;span class=&quot;code-quote&quot;&gt;&quot;Failed to connect to &quot;&lt;/span&gt; + targetAddr + &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; file &quot;&lt;/span&gt;
              + src + &lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block &quot;&lt;/span&gt; + block.getBlock() + &lt;span class=&quot;code-quote&quot;&gt;&quot;:&quot;&lt;/span&gt; + e;
          DFSClient.LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Connection failure: &quot;&lt;/span&gt; + msg, e);
          addToDeadNodes(chosenNode);
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(msg);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;so later, if we chooseDataNode, that dead node will be ignored.  Hopefully this time my description is more clear than before&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;chooseDataNode(LocatedBlock block) function looks redundant and should be removed.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;it still be called by blockSeekTo(long) and fetchBlockByteRange(...), yes, we can remove it, let me fix it in patch v9.&lt;/p&gt;</comment>
                            <comment id="13882655" author="hadoopqa" created="Mon, 27 Jan 2014 09:25:55 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625329/HDFS-5776-v9.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625329/HDFS-5776-v9.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5948//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5948//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5948//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5948//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883079" author="cmccabe" created="Mon, 27 Jan 2014 18:39:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;Fine, let me introduce a hard code up-limit for DFS_DFSCLIENT_HEDGED_READ_THREADPOOL_SIZE to 128.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Please don&apos;t.  There&apos;s no reason to put arbitrary limits into the code.  We don&apos;t do this with any other configuration settings.  At some point, you have to trust the configuration.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we don&apos;t need to restart DN/RS or sth else, we can modify/introduce a hbase shell script to disable/enable the feature per instance or modify the thread number or other requirements, i think it&apos;s feasible, and those works, in deed, are the major task for supporting hedged read in HBase side&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are you suggesting that we make the thread number setting changeable at runtime?  That seems like a good idea, but probably something we should do as a follow-on JIRA.&lt;/p&gt;</comment>
                            <comment id="13883663" author="xieliang007" created="Tue, 28 Jan 2014 02:14:46 +0000"  >&lt;p&gt;patch v10 removed the hard code limit per Colin&apos;s comments.&lt;br/&gt;
patch v9 has the hard code limit.&lt;br/&gt;
Any more comments or +1?  Personally i&apos;d like to let the first cut go to trunk and branch-2 asap, so i can kick off the HBase side change. More detailed disagreement could be resolved in other future JIRAs, right? and since the default pool size is 0, so no obvious foreseeable function/performance hurt against the current existing downstream application.&lt;/p&gt;</comment>
                            <comment id="13883666" author="jingzhao" created="Tue, 28 Jan 2014 02:21:37 +0000"  >&lt;p&gt;Thanks for the work &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;! I will review your latest patch and give my comments tonight (PST).&lt;/p&gt;</comment>
                            <comment id="13883685" author="arpitagarwal" created="Tue, 28 Jan 2014 02:45:12 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Yes, that would be perfect sometimes, but not works for HBase scenario(the above Stack&apos;s consideration is great), since we made the pool &quot;static&quot;, and per client view, it&apos;s more flexible if we provide instance level disable/enable APIs, so we can archive to use the hbase shell script to control the switch per dfs client instance, that&apos;ll be cooler&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Okay.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In actualGetFromOneDatanode(), the refetchToken/refetchEncryptionKey is initialized outside the while (true) loop (see Line 993-996), when we hit InvalidEncryptionKeyException/InvalidBlockTokenException, the refetchToken and refetchEncryptionKey will be decreased by 1, (see refetchEncryptionKey-- and refetchToken-- statement), if the exceptions happened again, the check conditions will be failed definitely(see &quot;e instanceof InvalidEncryptionKeyException &amp;amp;&amp;amp; refetchEncryptionKey &amp;gt; 0&quot; and &quot;refetchToken &amp;gt; 0&quot;), so go to the else clause, that&apos;ll execute:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Isn&apos;t the call to &lt;tt&gt;actualGetFromOneDataNode&lt;/tt&gt; wrapped in a loop itself? I am talking about the while loop in &lt;tt&gt;fetchBlockByteRange&lt;/tt&gt;. Will that not change the behavior? Maybe it is harmless, I am not sure. I just want us to be clear either way.&lt;/p&gt;

&lt;p&gt;Thanks for adding the thread count limit. If we need more than 128 threads per client process just for backup reads we (hdfs) need to think about proper async rpc. Suggesting a lack of limits ignores the point that it can double the DN load on an already loaded cluster. Also 1ms lower bound for the delay is as good as zero but as long as we have a thread count limit I am okay.&lt;/p&gt;

&lt;p&gt;Minor points that don&apos;t need to hold up the checkin:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;The test looks like a stress test, i.e. we are hoping that some of the hedged requests will complete before the primary requests. We can create a separate Jira to write a deterministic unit test and it&#8217;s fine if someone else picks that up later.&lt;/li&gt;
	&lt;li&gt;A couple of points from my initial feedback (#10, #12) were missed but again not worth holding the checkin.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Other than clarifying the loop behavior the v9 patch looks fine to me.&lt;/p&gt;

&lt;p&gt;Thanks again for working with the feedback Liang, this is a nice capability to have in HDFS.&lt;/p&gt;</comment>
                            <comment id="13883717" author="stack" created="Tue, 28 Jan 2014 04:01:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt; Would v10 be palatable?  You say OK to v9 above but Colin review would favor v10?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; Can you take care of the other nits raised by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Good stuff.&lt;/p&gt;</comment>
                            <comment id="13883746" author="hadoopqa" created="Tue, 28 Jan 2014 04:44:07 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625502/HDFS-5776-v10.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625502/HDFS-5776-v10.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5957//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5957//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5957//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5957//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13883823" author="xieliang007" created="Tue, 28 Jan 2014 06:48:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;Isn&apos;t the call to actualGetFromOneDataNode wrapped in a loop itself? I am talking about the while loop in fetchBlockByteRange. Will that not change the behavior? Maybe it is harmless, I am not sure. I just want us to be clear either way.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, it doesn&apos;t change the whole behavior and harmless, in deed, it&apos;s safer than before.&lt;br/&gt;
In the old impl, the refetchToken/refetchEncryptionKey are shared by all nodes from chooseDataNode once key/token exception happened. that means if the first node consumed this retry quota, then if the second or third node hit the key/token exception,  clearDataEncryptionKey/fetchBlockAt opeerations will not be called, it&apos;s a little unfair&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
In the new impl/patch, we make the second or later node have a similar retry quota as the first node, it&apos;s more fair to me.&lt;br/&gt;
Anyway, it doesn&apos;t change the normal path, just safer/fair to the security-enabled scenario.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The test looks like a stress test, i.e. we are hoping that some of the hedged requests will complete before the primary requests. We can create a separate Jira to write a deterministic unit test and it&#8217;s fine if someone else picks that up later.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ok, I can track it later.&lt;/p&gt;

&lt;p&gt;For patch v9 or v10, both are OK with me(though our internal branch use the style without limit), since my original wish is to reduce the HBase&apos;s P99 and P99.9 latency, not any difference on this point. V9 is safer but probably need to modify HDFS source code again if hit the hardcode limit(It&apos;s difficult to a normal end user).  IMHO, the actual/final committer who will commit this JIRA can pick one up. It&apos;ll be a pity if lots of guys continue to argue this style and hold on the progress, that doesn&apos;t help the downstream HBase project at all.&lt;/p&gt;</comment>
                            <comment id="13883928" author="jingzhao" created="Tue, 28 Jan 2014 09:07:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;it&apos;s more flexible if we provide instance level disable/enable APIs, so we can archive to use the hbase shell script to control the switch per dfs client instance, that&apos;ll be cooler&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I still have some concern about the current implementation: &lt;br/&gt;
1) we do not check threadpool in enableHedgedReads. This makes it possible that isHedgedReadsEnabled() returns true while hedged read is actually not enabled.&lt;br/&gt;
2) DFSClient#setThreadsNumForHedgedReads allows users to keep changing the size of the thread pool.&lt;br/&gt;
To provide instance level disable/enable APIs, I think maybe we can do the following:&lt;br/&gt;
1) Read the thread pool size configuration only when initializing the thread pool, and the size should be &amp;gt;0 and cannot be changed.&lt;br/&gt;
2) Add an &quot;Allow-Hedged-Reads&quot; configuration. Each DFSClient instance reads this configuration, and if it is true, checks and initializes the thread pool if necessary. Users can turn on/off the switch using the enable/disable methods. In the enable method, we check and initialize the thread pool if necessary.&lt;/p&gt;

&lt;p&gt;What do you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13883940" author="jingzhao" created="Tue, 28 Jan 2014 09:23:02 +0000"  >&lt;p&gt;Another thing for enoughNodesForHedgedRead. The current patch checks enoughNodesForHedgedRead before calling hedgedFetchBlockByteRange. Since the deadnodes keeps being updated while reading, we may still hit the issue where we could not easily find the second DN for reading. I think a better way is to add this check in chooseDataNode: if chooseDataNode finds that this is for seeking the second DN (if ignored is not null), and it could not immediately/easily find a DN, the chooseDataNode should skip retrying and we may want to fall back to the normal read.&lt;/p&gt;</comment>
                            <comment id="13883944" author="xieliang007" created="Tue, 28 Jan 2014 09:31:15 +0000"  >&lt;p&gt;Could we create another JIRA to track those disagreement? I have said more than three times: the default pool size is 0, so no hurt for all of existing applications by default. I guess it&apos;s possible cost one week, one month even one year to argue them...&lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="13884351" author="arpitagarwal" created="Tue, 28 Jan 2014 17:35:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; I am basically +1 on the v9 patch at this point but v10 is a step back. We need a throttle on unbounded thread growth and threadpool size is the most trivial to add. We can file a separate Jira to replace the thread pool limit with something more sophisticated e.g. the client can keep a dynamic estimate of the 95th percentile latency and use that instead of a fixed value from configuration.&lt;/p&gt;

&lt;p&gt;Jing mentioned some issues that look fairly easy to address.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In the old impl, the refetchToken/refetchEncryptionKey are shared by all nodes from chooseDataNode once key/token exception happened. that means if the first node consumed this retry quota, then if the second or third node hit the key/token exception, clearDataEncryptionKey/fetchBlockAt opeerations will not be called, it&apos;s a little unfair&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; That makes sense, thanks for the clarification.&lt;/p&gt;</comment>
                            <comment id="13884361" author="sureshms" created="Tue, 28 Jan 2014 17:51:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;Could we create another JIRA to track those disagreement? I have said more than three times: the default pool size is 0, so no hurt for all of existing applications by default.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The fact that the issue is brought up many times means that there is an issue that needs to be discussed and resolved.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I guess it&apos;s possible cost one week, one month even one year to argue them...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If takes more time, so be it. There are many committers who have spent time reviewing and commenting. I understand this is an important feature and the need to get it done sooner. But the core issues must be solved in this jira instead of pushing it to another jira.&lt;/p&gt;</comment>
                            <comment id="13884554" author="cmccabe" created="Tue, 28 Jan 2014 20:24:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt; : if I understand your comments correctly, you are concerned that hedged reads may spawn too many threads.  But that&apos;s why &lt;tt&gt;dfs.client.hedged.read.threadpool.size&lt;/tt&gt; exists.  The &lt;tt&gt;DFSClient&lt;/tt&gt; will not create more threads than this.&lt;/p&gt;

&lt;p&gt;We do not check other configuration settings to see if they are &quot;reasonable.&quot;  For example, if someone wants to set &lt;tt&gt;dfs.balancer.dispatcherThreads&lt;/tt&gt;, &lt;tt&gt;dfs.balancer.moverThreads&lt;/tt&gt;, or &lt;tt&gt;dfs.datanode.max.transfer.threads&lt;/tt&gt; to a zillion, we don&apos;t complain.  If we tried to set hard limits everywhere, people with different needs would have to recompile hadoop to meet those needs.&lt;/p&gt;

&lt;p&gt;Please remember that, if the client wants to, he/she can sit in a loop and call &lt;tt&gt;new Thread(...)&lt;/tt&gt;.  It&apos;s not like by giving users the ability to control the number of threads they use, we are opening up some new world of security vulnerabilities.  The ability for the client to create any number of threads already exists.  And it only inconveniences one person: the client themselves.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sureshms&quot; class=&quot;user-hover&quot; rel=&quot;sureshms&quot;&gt;Suresh Srinivas&lt;/a&gt;: I agree that we should figure out the configuration issues here rather than changing the configuration in an incompatible way later.  Jing suggested adding &quot;an Allow-Hedged-Reads configuration&quot; boolean.  That certainly seems to solve the problem of having different threads use different settings.  Is there any objection, besides the inelegance of having two configs rather than one?&lt;/p&gt;</comment>
                            <comment id="13884573" author="sureshms" created="Tue, 28 Jan 2014 20:40:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;We do not check other configuration settings to see if they are &quot;reasonable.&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;Colin Patrick McCabe&lt;/a&gt;, I agree with the points you have made. Checking for reasonable value for the new config does not seem necessary.&lt;/p&gt;</comment>
                            <comment id="13884694" author="stack" created="Tue, 28 Jan 2014 21:16:39 +0000"  >&lt;p&gt;Thanks lads.  We are almost there.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; It is better if we work through the issues here before the patch goes in especially while you have the attention of quality reviewers.  From your POV, I&apos;m sure it a little frustrating trying to drive the patch home between differing opinions (The time difference doesn&apos;t help either &amp;#8211; smile).  Try to salve any annoyance with the thought that, though it may appear otherwise, folks here are trying to work together to help get the best patch in.  Good on you Liang.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; I&apos;d agree with the last few &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt; review comments.  What you think?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arpitagarwal&quot; class=&quot;user-hover&quot; rel=&quot;arpitagarwal&quot;&gt;Arpit Agarwal&lt;/a&gt; Do you buy &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;Colin Patrick McCabe&lt;/a&gt;&apos;s argument?  It is good by me. If you agree, lets shift the focus to v10 and leave the v9 style behind.&lt;/p&gt;

&lt;p&gt;Good stuff&lt;/p&gt;</comment>
                            <comment id="13884710" author="arpitagarwal" created="Tue, 28 Jan 2014 21:23:54 +0000"  >&lt;p&gt;I&apos;ve stated my concerns but if there is broad consensus we don&apos;t need caps I won&apos;t hold up the checkin.&lt;/p&gt;</comment>
                            <comment id="13885083" author="xieliang007" created="Wed, 29 Jan 2014 06:59:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;we do not check threadpool in enableHedgedReads. This makes it possible that isHedgedReadsEnabled() returns true while hedged read is actually not enabled.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;i can change to sth like those if you gys want:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; allowHedgedReads &amp;amp;&amp;amp; (HEDGED_READ_THREAD_POOL != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) &amp;amp;&amp;amp; HEDGED_READ_THREAD_POOL.getMaximumPoolSize() &amp;gt; 0;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;what do you think ?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;DFSClient#setThreadsNumForHedgedReads allows users to keep changing the size of the thread pool.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;we definitely need the ability to modify the pool size on the fly, especially for HBase ops.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Read the thread pool size configuration only when initializing the thread pool, and the size should be &amp;gt;0 and cannot be changed&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Here is the same disagreement, if you guys all still insist on making the pool size readonly, i can reupload a new patch. Per my few previous operation experience, it&apos;s absolutely inconvenienced to an system ops/admin.&lt;/p&gt;</comment>
                            <comment id="13885091" author="xieliang007" created="Wed, 29 Jan 2014 07:12:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think a better way is to add this check in chooseDataNode: if chooseDataNode finds that this is for seeking the second DN (if ignored is not null), and it could not immediately/easily find a DN, the chooseDataNode should skip retrying and we may want to fall back to the normal read.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yeh, sound reasonable. will look into it later once get chance.&lt;br/&gt;
P.S. i am taking a 8+ days long holiday(China Spring Festival) and probably can not reply or make patch timely, sorry.&lt;/p&gt;

&lt;p&gt;Happy Holiday to all guys, thanks for looking at this JIRA !!!&lt;/p&gt;</comment>
                            <comment id="13885092" author="stack" created="Wed, 29 Jan 2014 07:13:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;what do you think ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That looks good to me &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...making the pool size readonly, i can reupload a new patch.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We can add back the flexibility in a later issue &amp;#8211; i.e. being able to adjust pool size on the fly.  I suggest posting a patch where the pool size is read from the configuration and is read-only post construction.  It would address an above reviewers concern and I believe address all outstanding concerns.&lt;/p&gt;

&lt;p&gt;Base your revision on v10 if you don&apos;t mind.&lt;/p&gt;



</comment>
                            <comment id="13885382" author="xieliang007" created="Wed, 29 Jan 2014 14:30:07 +0000"  >&lt;p&gt;Attached v11:&lt;br/&gt;
1) modify isHedgedReadsEnabled() to consider pool size as well&lt;br/&gt;
2) modify setThreadsNumForHedgedReads to &quot;private&quot; so can not change the thread number from client side dynamically, and remove &quot; synchronized&quot; also.&lt;/p&gt;</comment>
                            <comment id="13885512" author="hadoopqa" created="Wed, 29 Jan 2014 16:47:43 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625869/HDFS-5776-v11.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625869/HDFS-5776-v11.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5977//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5977//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5977//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5977//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5977//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5977//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13885633" author="stack" created="Wed, 29 Jan 2014 18:37:50 +0000"  >&lt;p&gt;Address the findbugs warning.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt; Does this patch address your concerns?  (Thanks for the review)&lt;/p&gt;</comment>
                            <comment id="13885813" author="hadoopqa" created="Wed, 29 Jan 2014 21:04:42 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625915/HDFS-5776-v12.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625915/HDFS-5776-v12.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5979//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5979//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5979//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5979//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13885902" author="stack" created="Wed, 29 Jan 2014 22:17:12 +0000"  >&lt;p&gt;Failure seems unrelated.  Let me try again to be sure.&lt;/p&gt;</comment>
                            <comment id="13886072" author="jingzhao" created="Thu, 30 Jan 2014 00:23:18 +0000"  >&lt;p&gt;Thanks for updating the patch, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, so the latest patch changes setThreadsNumForHedgedReads to private and aims to make users unable to &quot;change the thread number from client side dynamically&quot;. However, users can still create their own configuration object, change the configuration for thread pool size, create an DFSClient instance, and change the thread number? So I think we may want to make it more clean here. Specifically,&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;the first DFSClient who tries to enable the hedged read will initialize the thread pool (in the DFSClient constructor or in the enable method), so that the enable can be a real enable&lt;/li&gt;
	&lt;li&gt;changing of the thread pool size (if it is necessary) should still go through a setThreadsNumForHedgedReads method (instead of the constructor of DFSClient), so that a client cannot silently change the size of the thread pool&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Besides, the current patch has not addressed the comment for enoughNodesForHedgedRead/chooseDataNode.&lt;/p&gt;</comment>
                            <comment id="13886107" author="stack" created="Thu, 30 Jan 2014 00:56:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt; Thanks for the new input.  Please help me better understand what you mean by making more clean so we can adjust the patch accordingly.&lt;/p&gt;

&lt;p&gt;Hedged reads are set on or off in the client configuration xml and per DFSClient instance can be enabled/disabled as you go.  Yes, you could read code and figure that it is possible to do some heavyweight gymnastics creating your own Configuration &amp;#8211; expensive &amp;#8211; and a new DFSClient &amp;#8211; ditto &amp;#8211; if you wanted to work around whatever is out in the configuration xml.  That seems fine by me especially as there is no real means of shutting down this access route.&lt;/p&gt;

&lt;p&gt;Pardon me but I do not follow what you are asking for in 1.  Maybe you are referring to a &apos;hole&apos; where if the thread count is &amp;lt;= 0 on construction, the enable will have no effect &amp;#8211; and you want it to have an &apos;effect&apos; post construction?&lt;/p&gt;

&lt;p&gt;For 2., you are suggesting that setThreadsNumForHedgedReads not be private but be available API for the DFSClient to toggle as it sees fit?&lt;/p&gt;

&lt;p&gt;I&apos;ll let @liang xie address your enoughNodesForHedgedRead comment.&lt;/p&gt;

&lt;p&gt;Thanks for checking back.&lt;/p&gt;</comment>
                            <comment id="13886142" author="hadoopqa" created="Thu, 30 Jan 2014 01:32:11 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12625990/HDFS-5776-v12.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12625990/HDFS-5776-v12.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5984//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5984//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5984//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5984//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13886172" author="jingzhao" created="Thu, 30 Jan 2014 02:01:33 +0000"  >&lt;p&gt;Thanks for the feedback &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;My first question is, how will HBase use these enable/disable/setThreadsNumForHedgedReads APIs defined in DFSClient? DFSClient&apos;s interface audience is private, and DistributedFileSystem#getClient is also private in HDFS. I have not seen these APIs defined in the DistributedFileSystem/FileContext in the current patch, which means these will be added in a separate jira? In that case, actually we can remove all these API from the current patch and discuss how to define them in that new jira?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the enable will have no effect&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, if the size of the thread pool is still 0, after the enableHedgedRead is called, the hedged read will not be really enabled right? This makes this API really confusing. Or we can add a javadoc for this method saying &quot;note: this method may not really enable the hedged read, you still need to check the number of the thread pool...&quot;?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;do some heavyweight gymnastics creating your own Configuration &#8211; expensive &#8211; and a new DFSClient &#8211; ditto&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I assume we can have multiple DFSClient instances here since we want to do enable/disable per DFSClient instance? And calling the Configuration#set method to programmatically change the setting of the thread pool size may not be some heavyweight gymnastics. Thus while we aim to disallow users to change the thread number from client side dynamically, users can easily change the thread pool setting in an existing configuration object and use it when creating the next DFSClient instance?&lt;/p&gt;

&lt;p&gt;For 2, actually I do not quite understand the necessity of changing the thread pool size on the fly. I think we should rename setThreadsNumForHedgedReads  to initializeThreadPoolForHedgedReads, and remove the &quot;else&quot; section from that method. But if it is really necessary to support this functionality, let&apos;s define a clear setThreadsNumForHedgedReads method instead of silently changing the thread pool size in the constructor of DFSClient.&lt;/p&gt;


</comment>
                            <comment id="13887039" author="stack" created="Thu, 30 Jan 2014 21:02:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jingzhao&quot; class=&quot;user-hover&quot; rel=&quot;jingzhao&quot;&gt;Jing Zhao&lt;/a&gt; Thanks for taking the time to look and the great feedback.  On the APIs, you make a good point.  I can imagine that the notion is that clients such as HBase would selectively enable this feature given there is an associated &apos;cost&apos;.  An approach where we&apos;d enable it on creation only by jiggering the Configuration we pass seems fine for a first cut at least but would imply unhinging threads == 0 as an indicator of enabledness.   &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xieliang007&quot; class=&quot;user-hover&quot; rel=&quot;xieliang007&quot;&gt;Liang Xie&lt;/a&gt; What you reckon boss?   I could cast a patch this way if you are busy.  Would it work for your case?  Thanks.&lt;/p&gt;</comment>
                            <comment id="13887329" author="xieliang007" created="Fri, 31 Jan 2014 01:01:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saint.ack%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;saint.ack@gmail.com&quot;&gt;Stack&lt;/a&gt;, yeh, i need your help, thanks! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  i am really inconvenient to make new patch these two or three days. In the first cut, it should be ok for us HBase.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12626380">HBASE-7509</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625502" name="HDFS-5776-v10.txt" size="31308" author="xieliang007" created="Tue, 28 Jan 2014 02:14:46 +0000"/>
                            <attachment id="12625869" name="HDFS-5776-v11.txt" size="31406" author="xieliang007" created="Wed, 29 Jan 2014 14:30:07 +0000"/>
                            <attachment id="12625990" name="HDFS-5776-v12.txt" size="31419" author="stack" created="Wed, 29 Jan 2014 22:17:12 +0000"/>
                            <attachment id="12625915" name="HDFS-5776-v12.txt" size="31419" author="stack" created="Wed, 29 Jan 2014 18:37:50 +0000"/>
                            <attachment id="12623601" name="HDFS-5776-v2.txt" size="30172" author="xieliang007" created="Fri, 17 Jan 2014 07:41:49 +0000"/>
                            <attachment id="12623929" name="HDFS-5776-v3.txt" size="30463" author="xieliang007" created="Mon, 20 Jan 2014 09:47:42 +0000"/>
                            <attachment id="12624084" name="HDFS-5776-v4.txt" size="30702" author="xieliang007" created="Tue, 21 Jan 2014 06:39:47 +0000"/>
                            <attachment id="12624294" name="HDFS-5776-v5.txt" size="30152" author="xieliang007" created="Wed, 22 Jan 2014 07:46:15 +0000"/>
                            <attachment id="12624777" name="HDFS-5776-v6.txt" size="30291" author="xieliang007" created="Thu, 23 Jan 2014 10:37:14 +0000"/>
                            <attachment id="12624997" name="HDFS-5776-v7.txt" size="30108" author="xieliang007" created="Fri, 24 Jan 2014 06:16:06 +0000"/>
                            <attachment id="12625003" name="HDFS-5776-v8.txt" size="31075" author="xieliang007" created="Fri, 24 Jan 2014 07:16:07 +0000"/>
                            <attachment id="12625329" name="HDFS-5776-v9.txt" size="31926" author="xieliang007" created="Mon, 27 Jan 2014 06:56:52 +0000"/>
                            <attachment id="12623328" name="HDFS-5776.txt" size="29872" author="xieliang007" created="Thu, 16 Jan 2014 07:52:28 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>13.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 Jan 2014 05:11:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367902</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367904</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5775] Consolidate the code for serialization in CacheManager</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5775</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This jira proposes to consolidate the code that is responsible for serializing / deserializing cache manager state into a separate class, so that it is easier to introduce new code path to serialize the data using protobuf.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688904">HDFS-5775</key>
            <summary>Consolidate the code for serialization in CacheManager</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Jan 2014 00:53:32 +0000</created>
                <updated>Thu, 16 Jan 2014 13:41:37 +0000</updated>
                            <resolved>Wed, 15 Jan 2014 23:15:58 +0000</resolved>
                                    <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13871466" author="wheat9" created="Wed, 15 Jan 2014 01:05:49 +0000"  >&lt;p&gt;This patch also applies to trunk. Submit it to jenkins.&lt;/p&gt;</comment>
                            <comment id="13871656" author="hadoopqa" created="Wed, 15 Jan 2014 05:12:26 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12623036/HDFS-5775.000.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12623036/HDFS-5775.000.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5877//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5877//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/5877//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/5877//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13872758" author="brandonli" created="Wed, 15 Jan 2014 23:03:40 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13872772" author="brandonli" created="Wed, 15 Jan 2014 23:15:43 +0000"  >&lt;p&gt;I&apos;ve committed the patch. Thank you, Haohui, for the contribution!&lt;/p&gt;</comment>
                            <comment id="13872784" author="hudson" created="Wed, 15 Jan 2014 23:24:35 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #5006 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5006/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5006/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5775&quot; title=&quot;Consolidate the code for serialization in CacheManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5775&quot;&gt;&lt;del&gt;HDFS-5775&lt;/del&gt;&lt;/a&gt;. Consolidate the code for serialization in CacheManager. Contributed by Haohui Mai (brandonli: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873274" author="hudson" created="Thu, 16 Jan 2014 11:10:20 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #454 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/454/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/454/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5775&quot; title=&quot;Consolidate the code for serialization in CacheManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5775&quot;&gt;&lt;del&gt;HDFS-5775&lt;/del&gt;&lt;/a&gt;. Consolidate the code for serialization in CacheManager. Contributed by Haohui Mai (brandonli: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873365" author="hudson" created="Thu, 16 Jan 2014 13:27:07 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1671 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1671/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1671/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5775&quot; title=&quot;Consolidate the code for serialization in CacheManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5775&quot;&gt;&lt;del&gt;HDFS-5775&lt;/del&gt;&lt;/a&gt;. Consolidate the code for serialization in CacheManager. Contributed by Haohui Mai (brandonli: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873387" author="hudson" created="Thu, 16 Jan 2014 13:41:37 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1646 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1646/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1646/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5775&quot; title=&quot;Consolidate the code for serialization in CacheManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5775&quot;&gt;&lt;del&gt;HDFS-5775&lt;/del&gt;&lt;/a&gt;. Consolidate the code for serialization in CacheManager. Contributed by Haohui Mai (brandonli: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1558599&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623036" name="HDFS-5775.000.patch" size="11475" author="wheat9" created="Wed, 15 Jan 2014 01:05:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 Jan 2014 05:12:26 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367876</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367878</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5774] Serialize CachePool directives in protobuf</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5774</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This jira proposes to implement serialize cache pool directives in protobuf.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688887">HDFS-5774</key>
            <summary>Serialize CachePool directives in protobuf</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 23:39:55 +0000</created>
                <updated>Tue, 21 Jan 2014 01:18:40 +0000</updated>
                            <resolved>Tue, 21 Jan 2014 01:18:09 +0000</resolved>
                                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13875502" author="wheat9" created="Sat, 18 Jan 2014 02:47:10 +0000"  >&lt;p&gt;Rebase&lt;/p&gt;</comment>
                            <comment id="13876741" author="cmccabe" created="Mon, 20 Jan 2014 19:19:15 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+message CacheManagerSection {
+  optional uint64 nextDirectiveId = 1;
+  optional uint32 numPools        = 2;
+  optional uint32 numDirectives   = 3;
+  &lt;span class=&quot;code-comment&quot;&gt;// repeated CachePoolInfoProto pools
&lt;/span&gt;+  &lt;span class=&quot;code-comment&quot;&gt;// repeated CacheDirectiveInfoProto directives
&lt;/span&gt;+}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Shouldn&apos;t these fields be required?&lt;/p&gt;</comment>
                            <comment id="13876856" author="wheat9" created="Mon, 20 Jan 2014 21:08:24 +0000"  >&lt;p&gt;The language guide of protobuf suggests that marking all fields as optional to improve compatibility.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://developers.google.com/protocol-buffers/docs/proto&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Both approach have the exact wire format, in my opinion either approach can do the job.&lt;/p&gt;</comment>
                            <comment id="13876930" author="cmccabe" created="Mon, 20 Jan 2014 22:31:19 +0000"  >&lt;p&gt;Maybe I&apos;m missing something, but I don&apos;t see how making these fields optional improves compatibility.  We can&apos;t construct the cache manager without these fields, and there are no older versions of the software that didn&apos;t have them.&lt;/p&gt;</comment>
                            <comment id="13877043" author="wheat9" created="Tue, 21 Jan 2014 00:55:15 +0000"  >&lt;p&gt;Changing the optional fields into required based on Colin&apos;s comments.&lt;/p&gt;

&lt;p&gt;The patch is based on the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5743&quot; title=&quot;Use protobuf to serialize snapshot information&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5743&quot;&gt;&lt;del&gt;HDFS-5743&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13877062" author="jingzhao" created="Tue, 21 Jan 2014 01:13:21 +0000"  >&lt;p&gt;+1 Patch looks good.&lt;/p&gt;</comment>
                            <comment id="13877063" author="cmccabe" created="Tue, 21 Jan 2014 01:15:02 +0000"  >&lt;p&gt;Thanks, Haohui.  +1.&lt;/p&gt;</comment>
                            <comment id="13877066" author="jingzhao" created="Tue, 21 Jan 2014 01:18:09 +0000"  >&lt;p&gt;I&apos;ve committed this. Thanks to Haohui for the patch and thanks to Colin for review.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623203" name="HDFS-5774.000.patch" size="13709" author="wheat9" created="Wed, 15 Jan 2014 19:46:55 +0000"/>
                            <attachment id="12623769" name="HDFS-5774.001.patch" size="13541" author="wheat9" created="Sat, 18 Jan 2014 02:47:10 +0000"/>
                            <attachment id="12624048" name="HDFS-5774.002.patch" size="14783" author="wheat9" created="Tue, 21 Jan 2014 00:55:15 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 20 Jan 2014 19:19:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367859</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367861</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5773] NN may reject formerly dead DNs</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5773</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;If the heartbeat monitor declares a node dead, it may never allow a DN to rejoin.  The NN will generate messages like &quot;Got blockReceivedDeleted message from unregistered or dead node&quot;.&lt;/p&gt;

&lt;p&gt;There appears to be a bug where the the isAlive flag is not set to true when a formerly known DN attempts to rejoin.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688881">HDFS-5773</key>
            <summary>NN may reject formerly dead DNs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="daryn">Daryn Sharp</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 23:08:39 +0000</created>
                <updated>Tue, 14 Jan 2014 23:45:46 +0000</updated>
                                            <version>2.0.0-alpha</version>
                    <version>3.0.0</version>
                    <version>0.23.10</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13871385" author="daryn" created="Tue, 14 Jan 2014 23:45:46 +0000"  >&lt;p&gt;Issue was seen on 0.23 and believed to be 2.x but is not confirmed.  After a flow control issue described in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10233&quot; title=&quot;RPC lacks output flow control&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10233&quot;&gt;&lt;del&gt;HADOOP-10233&lt;/del&gt;&lt;/a&gt;, the NN&apos;s heartbeat manager over the course of an hour marked all the DNs dead after waking up from lengthy GC pauses.&lt;/p&gt;

&lt;p&gt;The nodes do not appear to have attempted re-registeration between re-sending blockReceivedDeleted messages.  The replication monitor went crazy as the nodes died off, possibly eliciting the blockReceivedDeleted messages (that were rejected) from the &quot;dead&quot; nodes.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367853</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367855</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12320353</customfieldvalue>
    <customfieldvalue>12320356</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>

<item>
            <title>[HDFS-5772] Serialize under-construction file information in FSImage</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5772</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;This jira defines FileUnderConstruction information in protobuf and adds functionality to saving/loading the information.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688878">HDFS-5772</key>
            <summary>Serialize under-construction file information in FSImage</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jingzhao">Jing Zhao</assignee>
                                    <reporter username="jingzhao">Jing Zhao</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 23:01:10 +0000</created>
                <updated>Wed, 15 Jan 2014 00:05:15 +0000</updated>
                            <resolved>Wed, 15 Jan 2014 00:05:15 +0000</resolved>
                                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13871377" author="wheat9" created="Tue, 14 Jan 2014 23:38:43 +0000"  >&lt;p&gt;The patch looks good to me.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  message FileUnderConstructionEntry {
+    required uint64 file = 1;
+    required string fullPath = 2;
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The protobuf fields should be optional, and it might make more sense to rename &lt;tt&gt;file&lt;/tt&gt; intoto &lt;tt&gt;inodeId&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="13871403" author="jingzhao" created="Wed, 15 Jan 2014 00:00:22 +0000"  >&lt;p&gt;Thanks for the review, Haohui! Update the patch to address your comments.&lt;/p&gt;</comment>
                            <comment id="13871404" author="wheat9" created="Wed, 15 Jan 2014 00:03:08 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13871408" author="jingzhao" created="Wed, 15 Jan 2014 00:05:15 +0000"  >&lt;p&gt;I&apos;ve committed this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12623010" name="HDFS-5772.000.patch" size="16805" author="jingzhao" created="Tue, 14 Jan 2014 23:02:47 +0000"/>
                            <attachment id="12623019" name="HDFS-5772.001.patch" size="17838" author="jingzhao" created="Wed, 15 Jan 2014 00:00:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 14 Jan 2014 23:38:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367850</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367852</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5771] Track progress when loading fsimage</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5771</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;The old code that loads the fsimage tracks the progress during loading. This jira proposes to implement the same functionality in the new code which serializes the fsimage using protobuf..&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688863">HDFS-5771</key>
            <summary>Track progress when loading fsimage</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12686210">HDFS-5698</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wheat9">Haohui Mai</assignee>
                                    <reporter username="wheat9">Haohui Mai</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 21:29:07 +0000</created>
                <updated>Wed, 29 Jan 2014 22:41:36 +0000</updated>
                            <resolved>Wed, 29 Jan 2014 22:41:36 +0000</resolved>
                                    <version>HDFS-5698 (FSImage in protobuf)</version>
                                    <fixVersion>HDFS-5698 (FSImage in protobuf)</fixVersion>
                                    <component>namenode</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13881285" author="wheat9" created="Fri, 24 Jan 2014 18:40:46 +0000"  >&lt;p&gt;Rebased&lt;/p&gt;</comment>
                            <comment id="13884810" author="cnauroth" created="Tue, 28 Jan 2014 22:48:05 +0000"  >&lt;p&gt;Hi, Haohui.  A couple of notes:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;I see there are multiple sections that do &lt;tt&gt;beginStep&lt;/tt&gt;/&lt;tt&gt;endStep&lt;/tt&gt; for &lt;tt&gt;StepType#INODES&lt;/tt&gt;.  Considering the way the &lt;tt&gt;StartupProgress&lt;/tt&gt; class works, the effect of this will be that progress jumps to 100% complete the first time &lt;tt&gt;endStep&lt;/tt&gt; gets called.  After that, the subsequent calls to &lt;tt&gt;beginStep&lt;/tt&gt;/&lt;tt&gt;endStep&lt;/tt&gt; are no-ops.  Are all of the various inode sections serialized sequentially in the new format?  If so, then would it be possible to do the &lt;tt&gt;beginStep&lt;/tt&gt; call for &lt;tt&gt;StepType#INODES&lt;/tt&gt; before the first inode section, and then do the &lt;tt&gt;endStep&lt;/tt&gt; after the last inode section?&lt;/li&gt;
	&lt;li&gt;There is a similar situation with &lt;tt&gt;saveInodes&lt;/tt&gt; and &lt;tt&gt;saveSnapshots&lt;/tt&gt; trying to begin/end the same step.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="13885679" author="wheat9" created="Wed, 29 Jan 2014 19:19:24 +0000"  >&lt;p&gt;Thanks Chris for the review. The v2 patch makes sure that &lt;tt&gt;beginStep()&lt;/tt&gt; and &lt;tt&gt;endStep()&lt;/tt&gt; are called exactly once for each step.&lt;/p&gt;

&lt;p&gt;It also records the storage path in the step.&lt;/p&gt;</comment>
                            <comment id="13885719" author="wheat9" created="Wed, 29 Jan 2014 19:53:01 +0000"  >&lt;p&gt;The v3 patch places the &lt;tt&gt;currentStep&lt;/tt&gt; variable correctly.&lt;/p&gt;</comment>
                            <comment id="13885910" author="cnauroth" created="Wed, 29 Jan 2014 22:24:13 +0000"  >&lt;p&gt;+1 for the v3 patch.  Thanks for incorporating those changes, Haohui.&lt;/p&gt;</comment>
                            <comment id="13885932" author="cnauroth" created="Wed, 29 Jan 2014 22:41:36 +0000"  >&lt;p&gt;I committed the patch to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5698&quot; title=&quot;Use protobuf to serialize / deserialize FSImage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5698&quot;&gt;HDFS-5698&lt;/a&gt; feature branch.  Thanks again, Haohui.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12624050" name="HDFS-5771.000.patch" size="12852" author="wheat9" created="Tue, 21 Jan 2014 01:01:15 +0000"/>
                            <attachment id="12625084" name="HDFS-5771.001.patch" size="12530" author="wheat9" created="Fri, 24 Jan 2014 18:40:46 +0000"/>
                            <attachment id="12625933" name="HDFS-5771.002.patch" size="11495" author="wheat9" created="Wed, 29 Jan 2014 19:19:24 +0000"/>
                            <attachment id="12625943" name="HDFS-5771.003.patch" size="11483" author="wheat9" created="Wed, 29 Jan 2014 19:53:01 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jan 2014 22:48:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367835</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367837</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12325854</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>

<item>
            <title>[HDFS-5770] Exception hit in TestPersistBlocks</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5770</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;Hit the following exception in &lt;tt&gt;TestPersistBlocks&lt;/tt&gt; after running a few hundred iterations of the test in a loop.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.io.IOException: Failed on local exception: java.io.EOFException; Host Details : local host is: &lt;span class=&quot;code-quote&quot;&gt;&quot;Arpit-MB-Pro.local/192.168.0.103&quot;&lt;/span&gt;; destination host is: &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost&quot;&lt;/span&gt;:57470;
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
        at org.apache.hadoop.ipc.Client.call(Client.java:1410)
        at org.apache.hadoop.ipc.Client.call(Client.java:1359)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at com.sun.proxy.$Proxy12.addBlock(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:185)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:101)
        at com.sun.proxy.$Proxy12.addBlock(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:348)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1259)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1107)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:515)
Caused by: java.io.EOFException: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        at java.io.DataInputStream.readInt(DataInputStream.java:375)
        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1050)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:945)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12688862">HDFS-5770</key>
            <summary>Exception hit in TestPersistBlocks</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="arpitagarwal">Arpit Agarwal</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 21:25:56 +0000</created>
                <updated>Tue, 14 Jan 2014 21:26:16 +0000</updated>
                                            <version>3.0.0</version>
                                                    <component>test</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12688084">HDFS-5747</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367834</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367836</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>

<item>
            <title>[HDFS-5769] Bootstrap a write pipeline from read-only replicas</title>
                <link>https://issues.apache.org/jira/browse/HDFS-5769</link>
                <project id="12310942" key="HDFS">Hadoop HDFS</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-1606&quot; title=&quot;Provide a stronger data guarantee in the write pipeline&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-1606&quot;&gt;&lt;del&gt;HDFS-1606&lt;/del&gt;&lt;/a&gt; added the capability for the &lt;tt&gt;DFSClient&lt;/tt&gt; to add DataNodes to an existing write pipeline.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2832&quot; title=&quot;Enable support for heterogeneous storages in HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2832&quot;&gt;HDFS-2832&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5318&quot; title=&quot;Support read-only and read-write paths to shared replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5318&quot;&gt;HDFS-5318&lt;/a&gt; introduce read-only replicas to HDFS.  This JIRA proposes using the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-1606&quot; title=&quot;Provide a stronger data guarantee in the write pipeline&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-1606&quot;&gt;&lt;del&gt;HDFS-1606&lt;/del&gt;&lt;/a&gt; &lt;tt&gt;addDatanode2ExistingPipeline()&lt;/tt&gt; capability to enable recovering in scenarios where only read-only replicas are available (i.e. all read-write replicas are offline).&lt;/p&gt;

&lt;p&gt;The following scenarios should be supported:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;&lt;em&gt;Recovering&lt;/em&gt; an initial write pipeline with repcount=1 (see &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-5434&quot; title=&quot;Write resiliency for replica count 1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-5434&quot;&gt;&lt;del&gt;HDFS-5434&lt;/del&gt;&lt;/a&gt;) when the datanode hosting the r/w replica fails (but r/o replicas are available)&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;Constructing&lt;/em&gt; an append pipeline for a block where the r/w replica is offline (but r/o replicas are available)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In both cases, a pipeline of length 0 can be &quot;bootstrapped&quot; to a pipeline of length 1 using available r/o replicas.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12688856">HDFS-5769</key>
            <summary>Bootstrap a write pipeline from read-only replicas</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png">Open</status>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="sirianni">Eric Sirianni</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Jan 2014 21:19:05 +0000</created>
                <updated>Tue, 28 Jan 2014 23:36:30 +0000</updated>
                                            <version>2.3.0</version>
                                                    <component>hdfs-client</component>
                    <component>namenode</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>4</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367828</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>367830</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>